{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T01:42:43.378639Z",
     "start_time": "2022-01-24T01:42:41.159378Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import Input,Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D, concatenate, Activation,Conv2DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization,add,Add,multiply,Lambda\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, History, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from keras_unet_collection import models, base, utils,losses\n",
    "# from tensorflow.keras.utils.multi_gpu_utils import multi_gpu_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "# config = tf.ConfigProto()\n",
    "# # config.gpu_options.per_process_gpu_memory_fraction=0.25\n",
    "# config.gpu_options.allow_growth=True\n",
    "# K.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 15:04:35.182489: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-25 15:04:35.732859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22325 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:86:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T01:42:47.822057Z",
     "start_time": "2022-01-24T01:42:47.807066Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(npy_path):\n",
    "    print('-'*30)\n",
    "    print('load images...')\n",
    "    print('-'*30)\n",
    "    \n",
    "    for i, path in enumerate(npy_path):\n",
    "#         print(path)\n",
    "        mask_npy_path = path.replace('_HE','_mask')\n",
    "        train_npy_path = path\n",
    "    \n",
    "        imgs_tmp = [cv2.imread(train_npy_path)]\n",
    "        imgs_mask_tmp = [cv2.imread(mask_npy_path,0)]\n",
    "#         print(imgs_tmp.shape, imgs_mask_tmp.shape)\n",
    "        \n",
    "        if i==0:\n",
    "            imgs = imgs_tmp\n",
    "            imgs_mask = imgs_mask_tmp\n",
    "            \n",
    "        else:\n",
    "            imgs = np.append(imgs, imgs_tmp,axis=0)\n",
    "            imgs_mask = np.append(imgs_mask, imgs_mask_tmp,axis=0)\n",
    "    imgs_tmp,imgs_mask_tmp = 0,0\n",
    "    print('-'*30)\n",
    "    print('imgs : {} \\nmasks : {}'.format(imgs.shape, imgs_mask.shape))    \n",
    "    print('-'*30)\n",
    "    imgs = imgs.astype('float32')\n",
    "    imgs_mask = imgs_mask.astype('float32')\n",
    "    print('img : ', imgs.max())\n",
    "    print('mask : ',imgs_mask.max())\n",
    "\n",
    "    print('-'*30)\n",
    "    print('normalization start...')\n",
    "    print('-'*30)\n",
    "    \n",
    "    imgs = cv2.normalize(imgs, None, 0, 1, cv2.NORM_MINMAX)\n",
    "\n",
    "    imgs_mask[imgs_mask<= 127] = 0\n",
    "    imgs_mask[imgs_mask > 127] = 1\n",
    "\n",
    "    print('img : ',imgs.max())\n",
    "    print('mask : ',imgs_mask.max())\n",
    "\n",
    "    return imgs, imgs_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T01:42:48.261578Z",
     "start_time": "2022-01-24T01:42:48.225789Z"
    }
   },
   "outputs": [],
   "source": [
    "def mkfolder(folder):\n",
    "    if not os.path.lexists(folder):\n",
    "        os.makedirs(folder)\n",
    "@jit\n",
    "def AttnBlock2D(x, g, inter_channel, data_format='channels_last'):\n",
    "\n",
    "    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(x)\n",
    "\n",
    "    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(g)\n",
    "\n",
    "    f = Activation('relu')(add([theta_x, phi_g]))\n",
    "\n",
    "    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format=data_format)(f)\n",
    "\n",
    "    rate = Activation('sigmoid')(psi_f)\n",
    "\n",
    "    att_x = multiply([x, rate])\n",
    "\n",
    "    return att_x\n",
    "\n",
    "def attention_up_and_concate(down_layer, layer, data_format='channels_last'):\n",
    "    \n",
    "    if data_format == 'channels_first':\n",
    "        in_channel = down_layer.get_shape().as_list()[1]\n",
    "    else:\n",
    "        in_channel = down_layer.get_shape().as_list()[3]\n",
    "    \n",
    "    up = UpSampling2D(size=(2,2), data_format=data_format)(down_layer)\n",
    "    layer = AttnBlock2D(x=layer, g=up, inter_channel=in_channel // 4, data_format=data_format)\n",
    "\n",
    "    if data_format == 'channels_first':\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n",
    "    else:\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "    \n",
    "    concate = my_concat([up, layer])\n",
    "    return concate\n",
    "@jit\n",
    "def get_att_unet(img_rows, img_cols):\n",
    "    inputs = Input((img_rows, img_cols,3))\n",
    "    conv1 = Conv2D(32, (3, 3), activation=None, padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation=None, padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation=None, padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation=None, padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation=None, padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation=None, padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation=None, padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation=None, padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation=None, padding='same')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "    conv5 = Conv2D(512, (3, 3), activation=None, padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "\n",
    "    up6 = attention_up_and_concate(conv5, conv4)\n",
    "    conv6 = Conv2D(256, (3, 3), activation=None, padding='same')(up6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Activation('relu')(conv6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation=None, padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Activation('relu')(conv6)\n",
    "\n",
    "    up7 = attention_up_and_concate(conv6, conv3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation=None, padding='same')(up7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Activation('relu')(conv7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation=None, padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Activation('relu')(conv7)\n",
    "\n",
    "    up8 = attention_up_and_concate(conv7, conv2)\n",
    "    conv8 = Conv2D(64, (3, 3), activation=None, padding='same')(up8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Activation('relu')(conv8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation=None, padding='same')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Activation('relu')(conv8)\n",
    "\n",
    "    up9 = attention_up_and_concate(conv8, conv1)\n",
    "    conv9 = Conv2D(32, (3, 3), activation=None, padding='same')(up9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Activation('relu')(conv9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation=None, padding='same')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Activation('relu')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T01:42:48.451019Z",
     "start_time": "2022-01-24T01:42:48.439717Z"
    }
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_true_yn = K.round(K.clip(y_true, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_true_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_true_yn)\n",
    "\n",
    "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T01:42:49.297436Z",
     "start_time": "2022-01-24T01:42:49.288213Z"
    }
   },
   "outputs": [],
   "source": [
    "img_path = 'ROI/New/'\n",
    "all_patient = np.array([i.replace('_HE.png', '') for i in os.listdir(img_path) if '_HE.png' in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['248', '357', '89', ..., '540', '541', '542'], dtype='<U10')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T05:57:17.113364Z",
     "start_time": "2022-01-24T05:57:17.095258Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_patient = ['2120737','2091197','2181633','2219487','2013713','2202545','2169164','2228384','2204600','2167546','2097782','2213245','2205867','2195929','2108941','2197912','2232197','2091069','0867365','2172317']\n",
    "# val_patient = ['2098098','2132226','2022898','2090880','2213752']\n",
    "# test_patient = ['0790305','2200290','2103280','2192712','2193810','2075521','2206976']\n",
    "# add2_patient = ['2120737','2091197','2181633','2219487','2013713','2202545','2169164','2228384','2204600','2167546','2097782','2213245','2205867','2195929','2108941','2197912','2232197','2091069','0867365','2172317','2193810','2075521','2206976']\n",
    "kf = KFold(n_splits=5, random_state=5, shuffle=True)\n",
    "fold = []\n",
    "for train_index, test_index in kf.split(all_patient):\n",
    "    train_patient, test_patient = all_patient[train_index.astype(int)], all_patient[test_index.astype(int)]    \n",
    "    \n",
    "    testset = [img_path+'{}_HE.png'.format(p) for p in test_patient]\n",
    "    trainset = [img_path+'{}_HE.png'.format(p) for p in train_patient]\n",
    "\n",
    "    fold.append([trainset, testset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['ROI/New/248_HE.png',\n",
       "   'ROI/New/357_HE.png',\n",
       "   'ROI/New/89_HE.png',\n",
       "   'ROI/New/1013_HE.png',\n",
       "   'ROI/New/269_HE.png',\n",
       "   'ROI/New/620_HE.png',\n",
       "   'ROI/New/1075_HE.png',\n",
       "   'ROI/New/1043_HE.png',\n",
       "   'ROI/New/191_HE.png',\n",
       "   'ROI/New/1125_HE.png',\n",
       "   'ROI/New/1161_HE.png',\n",
       "   'ROI/New/845_HE.png',\n",
       "   'ROI/New/622_HE.png',\n",
       "   'ROI/New/650_HE.png',\n",
       "   'ROI/New/228_HE.png',\n",
       "   'ROI/New/225_HE.png',\n",
       "   'ROI/New/246_HE.png',\n",
       "   'ROI/New/242_HE.png',\n",
       "   'ROI/New/259_HE.png',\n",
       "   'ROI/New/261_HE.png',\n",
       "   'ROI/New/268_HE.png',\n",
       "   'ROI/New/275_HE.png',\n",
       "   'ROI/New/266_HE.png',\n",
       "   'ROI/New/288_HE.png',\n",
       "   'ROI/New/297_HE.png',\n",
       "   'ROI/New/353_HE.png',\n",
       "   'ROI/New/369_HE.png',\n",
       "   'ROI/New/389_HE.png',\n",
       "   'ROI/New/398_HE.png',\n",
       "   'ROI/New/35_HE.png',\n",
       "   'ROI/New/31_HE.png',\n",
       "   'ROI/New/67_HE.png',\n",
       "   'ROI/New/61_HE.png',\n",
       "   'ROI/New/80_HE.png',\n",
       "   'ROI/New/143_HE.png',\n",
       "   'ROI/New/149_HE.png',\n",
       "   'ROI/New/179_HE.png',\n",
       "   'ROI/New/165_HE.png',\n",
       "   'ROI/New/902_HE.png',\n",
       "   'ROI/New/1580000_HE.png',\n",
       "   'ROI/New/790000_HE.png',\n",
       "   'ROI/New/730000_HE.png',\n",
       "   'ROI/New/2270000_HE.png',\n",
       "   'ROI/New/440000_HE.png',\n",
       "   'ROI/New/2290000_HE.png',\n",
       "   'ROI/New/360000_HE.png',\n",
       "   'ROI/New/10900000_HE.png',\n",
       "   'ROI/New/340000_HE.png',\n",
       "   'ROI/New/940000_HE.png',\n",
       "   'ROI/New/830000_HE.png',\n",
       "   'ROI/New/1440000_HE.png',\n",
       "   'ROI/New/1040000_HE.png',\n",
       "   'ROI/New/1070000_HE.png',\n",
       "   'ROI/New/330000_HE.png',\n",
       "   'ROI/New/1320000_HE.png',\n",
       "   'ROI/New/1590000_HE.png',\n",
       "   'ROI/New/1050000_HE.png',\n",
       "   'ROI/New/1310000_HE.png',\n",
       "   'ROI/New/820000_HE.png',\n",
       "   'ROI/New/202020000_HE.png',\n",
       "   'ROI/New/9700000_HE.png',\n",
       "   'ROI/New/2022160000_HE.png',\n",
       "   'ROI/New/2230000_HE.png',\n",
       "   'ROI/New/490000_HE.png',\n",
       "   'ROI/New/15200000_HE.png',\n",
       "   'ROI/New/1470000_HE.png',\n",
       "   'ROI/New/390000_HE.png',\n",
       "   'ROI/New/9500000_HE.png',\n",
       "   'ROI/New/2022110000_HE.png',\n",
       "   'ROI/New/650000_HE.png',\n",
       "   'ROI/New/1000000_HE.png',\n",
       "   'ROI/New/2220000_HE.png',\n",
       "   'ROI/New/370000_HE.png',\n",
       "   'ROI/New/970000_HE.png',\n",
       "   'ROI/New/950000_HE.png',\n",
       "   'ROI/New/460000_HE.png',\n",
       "   'ROI/New/310000_HE.png',\n",
       "   'ROI/New/530000_HE.png',\n",
       "   'ROI/New/2022140000_HE.png',\n",
       "   'ROI/New/2022190000_HE.png',\n",
       "   'ROI/New/1290000_HE.png',\n",
       "   'ROI/New/640000_HE.png',\n",
       "   'ROI/New/2016120000_HE.png',\n",
       "   'ROI/New/201620000_HE.png',\n",
       "   'ROI/New/1510000_HE.png',\n",
       "   'ROI/New/2017160000_HE.png',\n",
       "   'ROI/New/2017110000_HE.png',\n",
       "   'ROI/New/450000_HE.png',\n",
       "   'ROI/New/1060000_HE.png',\n",
       "   'ROI/New/2019180000_HE.png',\n",
       "   'ROI/New/3010000_HE.png',\n",
       "   'ROI/New/1020000_HE.png',\n",
       "   'ROI/New/1570000_HE.png',\n",
       "   'ROI/New/1090000_HE.png',\n",
       "   'ROI/New/202050000_HE.png',\n",
       "   'ROI/New/1230000_HE.png',\n",
       "   'ROI/New/100000_HE.png',\n",
       "   'ROI/New/110000_HE.png',\n",
       "   'ROI/New/300000_HE.png',\n",
       "   'ROI/New/840000_HE.png',\n",
       "   'ROI/New/880000_HE.png',\n",
       "   'ROI/New/890000_HE.png',\n",
       "   'ROI/New/930000_HE.png',\n",
       "   'ROI/New/1080000_HE.png',\n",
       "   'ROI/New/1650000_HE.png',\n",
       "   'ROI/New/1920000_HE.png',\n",
       "   'ROI/New/2010000_HE.png',\n",
       "   'ROI/New/670000_HE.png',\n",
       "   'ROI/New/810000_HE.png',\n",
       "   'ROI/New/1140000_HE.png',\n",
       "   'ROI/New/1150000_HE.png',\n",
       "   'ROI/New/1400000_HE.png',\n",
       "   'ROI/New/14700000_HE.png',\n",
       "   'ROI/New/1860000_HE.png',\n",
       "   'ROI/New/1870000_HE.png',\n",
       "   'ROI/New/2510000_HE.png',\n",
       "   'ROI/New/120000_HE.png',\n",
       "   'ROI/New/16000000_HE.png',\n",
       "   'ROI/New/200000_HE.png',\n",
       "   'ROI/New/470000_HE.png',\n",
       "   'ROI/New/630000_HE.png',\n",
       "   'ROI/New/740000_HE.png',\n",
       "   'ROI/New/8400000_HE.png',\n",
       "   'ROI/New/2017100000_HE.png',\n",
       "   'ROI/New/2016100000_HE.png',\n",
       "   'ROI/New/544_HE.png',\n",
       "   'ROI/New/545_HE.png',\n",
       "   'ROI/New/546_HE.png',\n",
       "   'ROI/New/547_HE.png',\n",
       "   'ROI/New/548_HE.png',\n",
       "   'ROI/New/550_HE.png',\n",
       "   'ROI/New/553_HE.png',\n",
       "   'ROI/New/554_HE.png',\n",
       "   'ROI/New/558_HE.png',\n",
       "   'ROI/New/559_HE.png',\n",
       "   'ROI/New/561_HE.png',\n",
       "   'ROI/New/562_HE.png',\n",
       "   'ROI/New/566_HE.png',\n",
       "   'ROI/New/567_HE.png',\n",
       "   'ROI/New/568_HE.png',\n",
       "   'ROI/New/569_HE.png',\n",
       "   'ROI/New/570_HE.png',\n",
       "   'ROI/New/571_HE.png',\n",
       "   'ROI/New/572_HE.png',\n",
       "   'ROI/New/574_HE.png',\n",
       "   'ROI/New/575_HE.png',\n",
       "   'ROI/New/577_HE.png',\n",
       "   'ROI/New/579_HE.png',\n",
       "   'ROI/New/580_HE.png',\n",
       "   'ROI/New/581_HE.png',\n",
       "   'ROI/New/582_HE.png',\n",
       "   'ROI/New/583_HE.png',\n",
       "   'ROI/New/584_HE.png',\n",
       "   'ROI/New/585_HE.png',\n",
       "   'ROI/New/586_HE.png',\n",
       "   'ROI/New/587_HE.png',\n",
       "   'ROI/New/588_HE.png',\n",
       "   'ROI/New/589_HE.png',\n",
       "   'ROI/New/590_HE.png',\n",
       "   'ROI/New/591_HE.png',\n",
       "   'ROI/New/592_HE.png',\n",
       "   'ROI/New/593_HE.png',\n",
       "   'ROI/New/594_HE.png',\n",
       "   'ROI/New/596_HE.png',\n",
       "   'ROI/New/597_HE.png',\n",
       "   'ROI/New/599_HE.png',\n",
       "   'ROI/New/600_HE.png',\n",
       "   'ROI/New/602_HE.png',\n",
       "   'ROI/New/604_HE.png',\n",
       "   'ROI/New/605_HE.png',\n",
       "   'ROI/New/606_HE.png',\n",
       "   'ROI/New/607_HE.png',\n",
       "   'ROI/New/608_HE.png',\n",
       "   'ROI/New/611_HE.png',\n",
       "   'ROI/New/612_HE.png',\n",
       "   'ROI/New/613_HE.png',\n",
       "   'ROI/New/614_HE.png',\n",
       "   'ROI/New/615_HE.png',\n",
       "   'ROI/New/616_HE.png',\n",
       "   'ROI/New/617_HE.png',\n",
       "   'ROI/New/618_HE.png',\n",
       "   'ROI/New/621_HE.png',\n",
       "   'ROI/New/623_HE.png',\n",
       "   'ROI/New/625_HE.png',\n",
       "   'ROI/New/629_HE.png',\n",
       "   'ROI/New/630_HE.png',\n",
       "   'ROI/New/633_HE.png',\n",
       "   'ROI/New/635_HE.png',\n",
       "   'ROI/New/636_HE.png',\n",
       "   'ROI/New/637_HE.png',\n",
       "   'ROI/New/638_HE.png',\n",
       "   'ROI/New/639_HE.png',\n",
       "   'ROI/New/640_HE.png',\n",
       "   'ROI/New/643_HE.png',\n",
       "   'ROI/New/645_HE.png',\n",
       "   'ROI/New/646_HE.png',\n",
       "   'ROI/New/647_HE.png',\n",
       "   'ROI/New/651_HE.png',\n",
       "   'ROI/New/652_HE.png',\n",
       "   'ROI/New/654_HE.png',\n",
       "   'ROI/New/655_HE.png',\n",
       "   'ROI/New/656_HE.png',\n",
       "   'ROI/New/657_HE.png',\n",
       "   'ROI/New/658_HE.png',\n",
       "   'ROI/New/659_HE.png',\n",
       "   'ROI/New/660_HE.png',\n",
       "   'ROI/New/662_HE.png',\n",
       "   'ROI/New/664_HE.png',\n",
       "   'ROI/New/665_HE.png',\n",
       "   'ROI/New/667_HE.png',\n",
       "   'ROI/New/668_HE.png',\n",
       "   'ROI/New/669_HE.png',\n",
       "   'ROI/New/671_HE.png',\n",
       "   'ROI/New/674_HE.png',\n",
       "   'ROI/New/675_HE.png',\n",
       "   'ROI/New/677_HE.png',\n",
       "   'ROI/New/679_HE.png',\n",
       "   'ROI/New/680_HE.png',\n",
       "   'ROI/New/682_HE.png',\n",
       "   'ROI/New/684_HE.png',\n",
       "   'ROI/New/685_HE.png',\n",
       "   'ROI/New/686_HE.png',\n",
       "   'ROI/New/687_HE.png',\n",
       "   'ROI/New/690_HE.png',\n",
       "   'ROI/New/693_HE.png',\n",
       "   'ROI/New/694_HE.png',\n",
       "   'ROI/New/695_HE.png',\n",
       "   'ROI/New/698_HE.png',\n",
       "   'ROI/New/699_HE.png',\n",
       "   'ROI/New/700_HE.png',\n",
       "   'ROI/New/701_HE.png',\n",
       "   'ROI/New/702_HE.png',\n",
       "   'ROI/New/703_HE.png',\n",
       "   'ROI/New/705_HE.png',\n",
       "   'ROI/New/707_HE.png',\n",
       "   'ROI/New/708_HE.png',\n",
       "   'ROI/New/712_HE.png',\n",
       "   'ROI/New/713_HE.png',\n",
       "   'ROI/New/715_HE.png',\n",
       "   'ROI/New/716_HE.png',\n",
       "   'ROI/New/717_HE.png',\n",
       "   'ROI/New/718_HE.png',\n",
       "   'ROI/New/720_HE.png',\n",
       "   'ROI/New/721_HE.png',\n",
       "   'ROI/New/723_HE.png',\n",
       "   'ROI/New/725_HE.png',\n",
       "   'ROI/New/727_HE.png',\n",
       "   'ROI/New/728_HE.png',\n",
       "   'ROI/New/731_HE.png',\n",
       "   'ROI/New/732_HE.png',\n",
       "   'ROI/New/733_HE.png',\n",
       "   'ROI/New/734_HE.png',\n",
       "   'ROI/New/736_HE.png',\n",
       "   'ROI/New/737_HE.png',\n",
       "   'ROI/New/741_HE.png',\n",
       "   'ROI/New/742_HE.png',\n",
       "   'ROI/New/743_HE.png',\n",
       "   'ROI/New/746_HE.png',\n",
       "   'ROI/New/747_HE.png',\n",
       "   'ROI/New/749_HE.png',\n",
       "   'ROI/New/754_HE.png',\n",
       "   'ROI/New/756_HE.png',\n",
       "   'ROI/New/757_HE.png',\n",
       "   'ROI/New/758_HE.png',\n",
       "   'ROI/New/759_HE.png',\n",
       "   'ROI/New/760_HE.png',\n",
       "   'ROI/New/761_HE.png',\n",
       "   'ROI/New/763_HE.png',\n",
       "   'ROI/New/764_HE.png',\n",
       "   'ROI/New/765_HE.png',\n",
       "   'ROI/New/766_HE.png',\n",
       "   'ROI/New/768_HE.png',\n",
       "   'ROI/New/769_HE.png',\n",
       "   'ROI/New/771_HE.png',\n",
       "   'ROI/New/772_HE.png',\n",
       "   'ROI/New/774_HE.png',\n",
       "   'ROI/New/776_HE.png',\n",
       "   'ROI/New/777_HE.png',\n",
       "   'ROI/New/778_HE.png',\n",
       "   'ROI/New/781_HE.png',\n",
       "   'ROI/New/785_HE.png',\n",
       "   'ROI/New/786_HE.png',\n",
       "   'ROI/New/787_HE.png',\n",
       "   'ROI/New/788_HE.png',\n",
       "   'ROI/New/792_HE.png',\n",
       "   'ROI/New/793_HE.png',\n",
       "   'ROI/New/799_HE.png',\n",
       "   'ROI/New/800_HE.png',\n",
       "   'ROI/New/803_HE.png',\n",
       "   'ROI/New/804_HE.png',\n",
       "   'ROI/New/808_HE.png',\n",
       "   'ROI/New/809_HE.png',\n",
       "   'ROI/New/810_HE.png',\n",
       "   'ROI/New/811_HE.png',\n",
       "   'ROI/New/812_HE.png',\n",
       "   'ROI/New/813_HE.png',\n",
       "   'ROI/New/814_HE.png',\n",
       "   'ROI/New/815_HE.png',\n",
       "   'ROI/New/816_HE.png',\n",
       "   'ROI/New/818_HE.png',\n",
       "   'ROI/New/819_HE.png',\n",
       "   'ROI/New/820_HE.png',\n",
       "   'ROI/New/822_HE.png',\n",
       "   'ROI/New/823_HE.png',\n",
       "   'ROI/New/824_HE.png',\n",
       "   'ROI/New/825_HE.png',\n",
       "   'ROI/New/826_HE.png',\n",
       "   'ROI/New/827_HE.png',\n",
       "   'ROI/New/828_HE.png',\n",
       "   'ROI/New/829_HE.png',\n",
       "   'ROI/New/830_HE.png',\n",
       "   'ROI/New/832_HE.png',\n",
       "   'ROI/New/833_HE.png',\n",
       "   'ROI/New/836_HE.png',\n",
       "   'ROI/New/837_HE.png',\n",
       "   'ROI/New/838_HE.png',\n",
       "   'ROI/New/841_HE.png',\n",
       "   'ROI/New/842_HE.png',\n",
       "   'ROI/New/847_HE.png',\n",
       "   'ROI/New/848_HE.png',\n",
       "   'ROI/New/849_HE.png',\n",
       "   'ROI/New/850_HE.png',\n",
       "   'ROI/New/852_HE.png',\n",
       "   'ROI/New/854_HE.png',\n",
       "   'ROI/New/855_HE.png',\n",
       "   'ROI/New/857_HE.png',\n",
       "   'ROI/New/858_HE.png',\n",
       "   'ROI/New/859_HE.png',\n",
       "   'ROI/New/860_HE.png',\n",
       "   'ROI/New/862_HE.png',\n",
       "   'ROI/New/863_HE.png',\n",
       "   'ROI/New/864_HE.png',\n",
       "   'ROI/New/865_HE.png',\n",
       "   'ROI/New/866_HE.png',\n",
       "   'ROI/New/867_HE.png',\n",
       "   'ROI/New/868_HE.png',\n",
       "   'ROI/New/869_HE.png',\n",
       "   'ROI/New/870_HE.png',\n",
       "   'ROI/New/872_HE.png',\n",
       "   'ROI/New/873_HE.png',\n",
       "   'ROI/New/874_HE.png',\n",
       "   'ROI/New/876_HE.png',\n",
       "   'ROI/New/878_HE.png',\n",
       "   'ROI/New/879_HE.png',\n",
       "   'ROI/New/880_HE.png',\n",
       "   'ROI/New/881_HE.png',\n",
       "   'ROI/New/882_HE.png',\n",
       "   'ROI/New/883_HE.png',\n",
       "   'ROI/New/884_HE.png',\n",
       "   'ROI/New/885_HE.png',\n",
       "   'ROI/New/886_HE.png',\n",
       "   'ROI/New/887_HE.png',\n",
       "   'ROI/New/888_HE.png',\n",
       "   'ROI/New/891_HE.png',\n",
       "   'ROI/New/892_HE.png',\n",
       "   'ROI/New/893_HE.png',\n",
       "   'ROI/New/899_HE.png',\n",
       "   'ROI/New/900_HE.png',\n",
       "   'ROI/New/903_HE.png',\n",
       "   'ROI/New/905_HE.png',\n",
       "   'ROI/New/906_HE.png',\n",
       "   'ROI/New/907_HE.png',\n",
       "   'ROI/New/909_HE.png',\n",
       "   'ROI/New/910_HE.png',\n",
       "   'ROI/New/919_HE.png',\n",
       "   'ROI/New/922_HE.png',\n",
       "   'ROI/New/925_HE.png',\n",
       "   'ROI/New/927_HE.png',\n",
       "   'ROI/New/928_HE.png',\n",
       "   'ROI/New/929_HE.png',\n",
       "   'ROI/New/930_HE.png',\n",
       "   'ROI/New/931_HE.png',\n",
       "   'ROI/New/932_HE.png',\n",
       "   'ROI/New/933_HE.png',\n",
       "   'ROI/New/934_HE.png',\n",
       "   'ROI/New/936_HE.png',\n",
       "   'ROI/New/937_HE.png',\n",
       "   'ROI/New/938_HE.png',\n",
       "   'ROI/New/939_HE.png',\n",
       "   'ROI/New/940_HE.png',\n",
       "   'ROI/New/942_HE.png',\n",
       "   'ROI/New/943_HE.png',\n",
       "   'ROI/New/944_HE.png',\n",
       "   'ROI/New/947_HE.png',\n",
       "   'ROI/New/948_HE.png',\n",
       "   'ROI/New/949_HE.png',\n",
       "   'ROI/New/950_HE.png',\n",
       "   'ROI/New/951_HE.png',\n",
       "   'ROI/New/952_HE.png',\n",
       "   'ROI/New/953_HE.png',\n",
       "   'ROI/New/954_HE.png',\n",
       "   'ROI/New/957_HE.png',\n",
       "   'ROI/New/959_HE.png',\n",
       "   'ROI/New/960_HE.png',\n",
       "   'ROI/New/961_HE.png',\n",
       "   'ROI/New/962_HE.png',\n",
       "   'ROI/New/963_HE.png',\n",
       "   'ROI/New/964_HE.png',\n",
       "   'ROI/New/966_HE.png',\n",
       "   'ROI/New/967_HE.png',\n",
       "   'ROI/New/968_HE.png',\n",
       "   'ROI/New/970_HE.png',\n",
       "   'ROI/New/971_HE.png',\n",
       "   'ROI/New/973_HE.png',\n",
       "   'ROI/New/975_HE.png',\n",
       "   'ROI/New/977_HE.png',\n",
       "   'ROI/New/978_HE.png',\n",
       "   'ROI/New/979_HE.png',\n",
       "   'ROI/New/980_HE.png',\n",
       "   'ROI/New/981_HE.png',\n",
       "   'ROI/New/984_HE.png',\n",
       "   'ROI/New/985_HE.png',\n",
       "   'ROI/New/987_HE.png',\n",
       "   'ROI/New/988_HE.png',\n",
       "   'ROI/New/989_HE.png',\n",
       "   'ROI/New/991_HE.png',\n",
       "   'ROI/New/992_HE.png',\n",
       "   'ROI/New/993_HE.png',\n",
       "   'ROI/New/995_HE.png',\n",
       "   'ROI/New/996_HE.png',\n",
       "   'ROI/New/997_HE.png',\n",
       "   'ROI/New/999_HE.png',\n",
       "   'ROI/New/1003_HE.png',\n",
       "   'ROI/New/1005_HE.png',\n",
       "   'ROI/New/1007_HE.png',\n",
       "   'ROI/New/1008_HE.png',\n",
       "   'ROI/New/1009_HE.png',\n",
       "   'ROI/New/1010_HE.png',\n",
       "   'ROI/New/1012_HE.png',\n",
       "   'ROI/New/1014_HE.png',\n",
       "   'ROI/New/1015_HE.png',\n",
       "   'ROI/New/1016_HE.png',\n",
       "   'ROI/New/1018_HE.png',\n",
       "   'ROI/New/1022_HE.png',\n",
       "   'ROI/New/1024_HE.png',\n",
       "   'ROI/New/1026_HE.png',\n",
       "   'ROI/New/1028_HE.png',\n",
       "   'ROI/New/1031_HE.png',\n",
       "   'ROI/New/1032_HE.png',\n",
       "   'ROI/New/1035_HE.png',\n",
       "   'ROI/New/1036_HE.png',\n",
       "   'ROI/New/1037_HE.png',\n",
       "   'ROI/New/1039_HE.png',\n",
       "   'ROI/New/1044_HE.png',\n",
       "   'ROI/New/1047_HE.png',\n",
       "   'ROI/New/1048_HE.png',\n",
       "   'ROI/New/1049_HE.png',\n",
       "   'ROI/New/1056_HE.png',\n",
       "   'ROI/New/1058_HE.png',\n",
       "   'ROI/New/1060_HE.png',\n",
       "   'ROI/New/1062_HE.png',\n",
       "   'ROI/New/1063_HE.png',\n",
       "   'ROI/New/1065_HE.png',\n",
       "   'ROI/New/1068_HE.png',\n",
       "   'ROI/New/1071_HE.png',\n",
       "   'ROI/New/1072_HE.png',\n",
       "   'ROI/New/1073_HE.png',\n",
       "   'ROI/New/1074_HE.png',\n",
       "   'ROI/New/1076_HE.png',\n",
       "   'ROI/New/1078_HE.png',\n",
       "   'ROI/New/1079_HE.png',\n",
       "   'ROI/New/1082_HE.png',\n",
       "   'ROI/New/1083_HE.png',\n",
       "   'ROI/New/1084_HE.png',\n",
       "   'ROI/New/1085_HE.png',\n",
       "   'ROI/New/1086_HE.png',\n",
       "   'ROI/New/1088_HE.png',\n",
       "   'ROI/New/1089_HE.png',\n",
       "   'ROI/New/1091_HE.png',\n",
       "   'ROI/New/1096_HE.png',\n",
       "   'ROI/New/1097_HE.png',\n",
       "   'ROI/New/1099_HE.png',\n",
       "   'ROI/New/1100_HE.png',\n",
       "   'ROI/New/1102_HE.png',\n",
       "   'ROI/New/1103_HE.png',\n",
       "   'ROI/New/1104_HE.png',\n",
       "   'ROI/New/1105_HE.png',\n",
       "   'ROI/New/1106_HE.png',\n",
       "   'ROI/New/1107_HE.png',\n",
       "   'ROI/New/1109_HE.png',\n",
       "   'ROI/New/1111_HE.png',\n",
       "   'ROI/New/1112_HE.png',\n",
       "   'ROI/New/1116_HE.png',\n",
       "   'ROI/New/1117_HE.png',\n",
       "   'ROI/New/1123_HE.png',\n",
       "   'ROI/New/1124_HE.png',\n",
       "   'ROI/New/1126_HE.png',\n",
       "   'ROI/New/1129_HE.png',\n",
       "   'ROI/New/1131_HE.png',\n",
       "   'ROI/New/1135_HE.png',\n",
       "   'ROI/New/1136_HE.png',\n",
       "   'ROI/New/1139_HE.png',\n",
       "   'ROI/New/1142_HE.png',\n",
       "   'ROI/New/1144_HE.png',\n",
       "   'ROI/New/1145_HE.png',\n",
       "   'ROI/New/1148_HE.png',\n",
       "   'ROI/New/1152_HE.png',\n",
       "   'ROI/New/1154_HE.png',\n",
       "   'ROI/New/1156_HE.png',\n",
       "   'ROI/New/1157_HE.png',\n",
       "   'ROI/New/1159_HE.png',\n",
       "   'ROI/New/1160_HE.png',\n",
       "   'ROI/New/1162_HE.png',\n",
       "   'ROI/New/1164_HE.png',\n",
       "   'ROI/New/1165_HE.png',\n",
       "   'ROI/New/1168_HE.png',\n",
       "   'ROI/New/1169_HE.png',\n",
       "   'ROI/New/1171_HE.png',\n",
       "   'ROI/New/1172_HE.png',\n",
       "   'ROI/New/1173_HE.png',\n",
       "   'ROI/New/1174_HE.png',\n",
       "   'ROI/New/1175_HE.png',\n",
       "   'ROI/New/1180_HE.png',\n",
       "   'ROI/New/1181_HE.png',\n",
       "   'ROI/New/1182_HE.png',\n",
       "   'ROI/New/1183_HE.png',\n",
       "   'ROI/New/1184_HE.png',\n",
       "   'ROI/New/1186_HE.png',\n",
       "   'ROI/New/1187_HE.png',\n",
       "   'ROI/New/1188_HE.png',\n",
       "   'ROI/New/1189_HE.png',\n",
       "   'ROI/New/1190_HE.png',\n",
       "   'ROI/New/1191_HE.png',\n",
       "   'ROI/New/1192_HE.png',\n",
       "   'ROI/New/150000_HE.png',\n",
       "   'ROI/New/160000_HE.png',\n",
       "   'ROI/New/280000_HE.png',\n",
       "   'ROI/New/290000_HE.png',\n",
       "   'ROI/New/1600000_HE.png',\n",
       "   'ROI/New/1620000_HE.png',\n",
       "   'ROI/New/1660000_HE.png',\n",
       "   'ROI/New/1670000_HE.png',\n",
       "   'ROI/New/1950000_HE.png',\n",
       "   'ROI/New/1970000_HE.png',\n",
       "   'ROI/New/2110000_HE.png',\n",
       "   'ROI/New/2190000_HE.png',\n",
       "   'ROI/New/2250000_HE.png',\n",
       "   'ROI/New/2300000_HE.png',\n",
       "   'ROI/New/2340000_HE.png',\n",
       "   'ROI/New/2450000_HE.png',\n",
       "   'ROI/New/20200000_HE.png',\n",
       "   'ROI/New/201610000_HE.png',\n",
       "   'ROI/New/201640000_HE.png',\n",
       "   'ROI/New/201670000_HE.png',\n",
       "   'ROI/New/201680000_HE.png',\n",
       "   'ROI/New/201690000_HE.png',\n",
       "   'ROI/New/201710000_HE.png',\n",
       "   'ROI/New/201720000_HE.png',\n",
       "   'ROI/New/201730000_HE.png',\n",
       "   'ROI/New/201740000_HE.png',\n",
       "   'ROI/New/201790000_HE.png',\n",
       "   'ROI/New/201820000_HE.png',\n",
       "   'ROI/New/201840000_HE.png',\n",
       "   'ROI/New/201850000_HE.png',\n",
       "   'ROI/New/201860000_HE.png',\n",
       "   'ROI/New/201870000_HE.png',\n",
       "   'ROI/New/201880000_HE.png',\n",
       "   'ROI/New/201890000_HE.png',\n",
       "   'ROI/New/201910000_HE.png',\n",
       "   'ROI/New/201930000_HE.png',\n",
       "   'ROI/New/201940000_HE.png',\n",
       "   'ROI/New/201970000_HE.png',\n",
       "   'ROI/New/202010000_HE.png',\n",
       "   'ROI/New/202040000_HE.png',\n",
       "   'ROI/New/202210000_HE.png',\n",
       "   'ROI/New/202220000_HE.png',\n",
       "   'ROI/New/202230000_HE.png',\n",
       "   'ROI/New/202240000_HE.png',\n",
       "   'ROI/New/202260000_HE.png',\n",
       "   'ROI/New/202270000_HE.png',\n",
       "   'ROI/New/202280000_HE.png',\n",
       "   'ROI/New/202290000_HE.png',\n",
       "   'ROI/New/2017120000_HE.png',\n",
       "   'ROI/New/2017130000_HE.png',\n",
       "   'ROI/New/2017140000_HE.png',\n",
       "   'ROI/New/2017170000_HE.png',\n",
       "   'ROI/New/2018100000_HE.png',\n",
       "   'ROI/New/2018120000_HE.png',\n",
       "   'ROI/New/2018130000_HE.png',\n",
       "   'ROI/New/2018140000_HE.png',\n",
       "   'ROI/New/2018150000_HE.png',\n",
       "   'ROI/New/2018160000_HE.png',\n",
       "   'ROI/New/2018170000_HE.png',\n",
       "   'ROI/New/2019100000_HE.png',\n",
       "   'ROI/New/2019110000_HE.png',\n",
       "   'ROI/New/2019120000_HE.png',\n",
       "   'ROI/New/2019130000_HE.png',\n",
       "   'ROI/New/2019150000_HE.png',\n",
       "   'ROI/New/2019190000_HE.png',\n",
       "   'ROI/New/2022120000_HE.png',\n",
       "   'ROI/New/2022130000_HE.png',\n",
       "   'ROI/New/2022150000_HE.png',\n",
       "   'ROI/New/2022170000_HE.png',\n",
       "   'ROI/New/2022180000_HE.png',\n",
       "   'ROI/New/2022210000_HE.png',\n",
       "   'ROI/New/2022220000_HE.png',\n",
       "   'ROI/New/2022230000_HE.png',\n",
       "   'ROI/New/2_HE.png',\n",
       "   'ROI/New/3_HE.png',\n",
       "   'ROI/New/4_HE.png',\n",
       "   'ROI/New/5_HE.png',\n",
       "   'ROI/New/6_HE.png',\n",
       "   'ROI/New/10_HE.png',\n",
       "   'ROI/New/11_HE.png',\n",
       "   'ROI/New/12_HE.png',\n",
       "   'ROI/New/13_HE.png',\n",
       "   'ROI/New/14_HE.png',\n",
       "   'ROI/New/15_HE.png',\n",
       "   'ROI/New/17_HE.png',\n",
       "   'ROI/New/18_HE.png',\n",
       "   'ROI/New/20_HE.png',\n",
       "   'ROI/New/21_HE.png',\n",
       "   'ROI/New/22_HE.png',\n",
       "   'ROI/New/23_HE.png',\n",
       "   'ROI/New/25_HE.png',\n",
       "   'ROI/New/26_HE.png',\n",
       "   'ROI/New/27_HE.png',\n",
       "   'ROI/New/28_HE.png',\n",
       "   'ROI/New/29_HE.png',\n",
       "   'ROI/New/33_HE.png',\n",
       "   'ROI/New/34_HE.png',\n",
       "   'ROI/New/36_HE.png',\n",
       "   'ROI/New/37_HE.png',\n",
       "   'ROI/New/39_HE.png',\n",
       "   'ROI/New/40_HE.png',\n",
       "   'ROI/New/41_HE.png',\n",
       "   'ROI/New/43_HE.png',\n",
       "   'ROI/New/45_HE.png',\n",
       "   'ROI/New/46_HE.png',\n",
       "   'ROI/New/47_HE.png',\n",
       "   'ROI/New/49_HE.png',\n",
       "   'ROI/New/51_HE.png',\n",
       "   'ROI/New/52_HE.png',\n",
       "   'ROI/New/54_HE.png',\n",
       "   'ROI/New/55_HE.png',\n",
       "   'ROI/New/56_HE.png',\n",
       "   'ROI/New/57_HE.png',\n",
       "   'ROI/New/59_HE.png',\n",
       "   'ROI/New/63_HE.png',\n",
       "   'ROI/New/64_HE.png',\n",
       "   'ROI/New/65_HE.png',\n",
       "   'ROI/New/66_HE.png',\n",
       "   'ROI/New/68_HE.png',\n",
       "   'ROI/New/69_HE.png',\n",
       "   'ROI/New/70_HE.png',\n",
       "   'ROI/New/71_HE.png',\n",
       "   'ROI/New/72_HE.png',\n",
       "   'ROI/New/73_HE.png',\n",
       "   'ROI/New/74_HE.png',\n",
       "   'ROI/New/77_HE.png',\n",
       "   'ROI/New/79_HE.png',\n",
       "   'ROI/New/81_HE.png',\n",
       "   'ROI/New/85_HE.png',\n",
       "   'ROI/New/86_HE.png',\n",
       "   'ROI/New/87_HE.png',\n",
       "   'ROI/New/90_HE.png',\n",
       "   'ROI/New/91_HE.png',\n",
       "   'ROI/New/94_HE.png',\n",
       "   'ROI/New/96_HE.png',\n",
       "   'ROI/New/97_HE.png',\n",
       "   'ROI/New/99_HE.png',\n",
       "   'ROI/New/100_HE.png',\n",
       "   'ROI/New/103_HE.png',\n",
       "   'ROI/New/105_HE.png',\n",
       "   'ROI/New/107_HE.png',\n",
       "   'ROI/New/108_HE.png',\n",
       "   'ROI/New/109_HE.png',\n",
       "   'ROI/New/110_HE.png',\n",
       "   'ROI/New/111_HE.png',\n",
       "   'ROI/New/112_HE.png',\n",
       "   'ROI/New/113_HE.png',\n",
       "   'ROI/New/115_HE.png',\n",
       "   'ROI/New/116_HE.png',\n",
       "   'ROI/New/118_HE.png',\n",
       "   'ROI/New/121_HE.png',\n",
       "   'ROI/New/123_HE.png',\n",
       "   'ROI/New/126_HE.png',\n",
       "   'ROI/New/127_HE.png',\n",
       "   'ROI/New/129_HE.png',\n",
       "   'ROI/New/130_HE.png',\n",
       "   'ROI/New/132_HE.png',\n",
       "   'ROI/New/133_HE.png',\n",
       "   'ROI/New/136_HE.png',\n",
       "   'ROI/New/137_HE.png',\n",
       "   'ROI/New/138_HE.png',\n",
       "   'ROI/New/139_HE.png',\n",
       "   'ROI/New/140_HE.png',\n",
       "   'ROI/New/141_HE.png',\n",
       "   'ROI/New/144_HE.png',\n",
       "   'ROI/New/145_HE.png',\n",
       "   'ROI/New/146_HE.png',\n",
       "   'ROI/New/147_HE.png',\n",
       "   'ROI/New/148_HE.png',\n",
       "   'ROI/New/150_HE.png',\n",
       "   'ROI/New/151_HE.png',\n",
       "   'ROI/New/152_HE.png',\n",
       "   'ROI/New/153_HE.png',\n",
       "   'ROI/New/155_HE.png',\n",
       "   'ROI/New/156_HE.png',\n",
       "   'ROI/New/157_HE.png',\n",
       "   'ROI/New/158_HE.png',\n",
       "   'ROI/New/159_HE.png',\n",
       "   'ROI/New/161_HE.png',\n",
       "   'ROI/New/162_HE.png',\n",
       "   'ROI/New/163_HE.png',\n",
       "   'ROI/New/164_HE.png',\n",
       "   'ROI/New/166_HE.png',\n",
       "   'ROI/New/167_HE.png',\n",
       "   'ROI/New/168_HE.png',\n",
       "   'ROI/New/169_HE.png',\n",
       "   'ROI/New/173_HE.png',\n",
       "   'ROI/New/174_HE.png',\n",
       "   'ROI/New/176_HE.png',\n",
       "   'ROI/New/177_HE.png',\n",
       "   'ROI/New/178_HE.png',\n",
       "   'ROI/New/180_HE.png',\n",
       "   'ROI/New/181_HE.png',\n",
       "   'ROI/New/182_HE.png',\n",
       "   'ROI/New/183_HE.png',\n",
       "   'ROI/New/184_HE.png',\n",
       "   'ROI/New/185_HE.png',\n",
       "   'ROI/New/186_HE.png',\n",
       "   'ROI/New/187_HE.png',\n",
       "   'ROI/New/189_HE.png',\n",
       "   'ROI/New/190_HE.png',\n",
       "   'ROI/New/192_HE.png',\n",
       "   'ROI/New/195_HE.png',\n",
       "   'ROI/New/196_HE.png',\n",
       "   'ROI/New/197_HE.png',\n",
       "   'ROI/New/199_HE.png',\n",
       "   'ROI/New/200_HE.png',\n",
       "   'ROI/New/202_HE.png',\n",
       "   'ROI/New/204_HE.png',\n",
       "   'ROI/New/206_HE.png',\n",
       "   'ROI/New/207_HE.png',\n",
       "   'ROI/New/208_HE.png',\n",
       "   'ROI/New/209_HE.png',\n",
       "   'ROI/New/213_HE.png',\n",
       "   'ROI/New/215_HE.png',\n",
       "   'ROI/New/216_HE.png',\n",
       "   'ROI/New/217_HE.png',\n",
       "   'ROI/New/218_HE.png',\n",
       "   'ROI/New/220_HE.png',\n",
       "   'ROI/New/221_HE.png',\n",
       "   'ROI/New/222_HE.png',\n",
       "   'ROI/New/229_HE.png',\n",
       "   'ROI/New/230_HE.png',\n",
       "   'ROI/New/233_HE.png',\n",
       "   'ROI/New/235_HE.png',\n",
       "   'ROI/New/237_HE.png',\n",
       "   'ROI/New/238_HE.png',\n",
       "   'ROI/New/240_HE.png',\n",
       "   'ROI/New/245_HE.png',\n",
       "   'ROI/New/247_HE.png',\n",
       "   'ROI/New/249_HE.png',\n",
       "   'ROI/New/250_HE.png',\n",
       "   'ROI/New/251_HE.png',\n",
       "   'ROI/New/252_HE.png',\n",
       "   'ROI/New/253_HE.png',\n",
       "   'ROI/New/255_HE.png',\n",
       "   'ROI/New/256_HE.png',\n",
       "   'ROI/New/257_HE.png',\n",
       "   'ROI/New/263_HE.png',\n",
       "   'ROI/New/264_HE.png',\n",
       "   'ROI/New/267_HE.png',\n",
       "   'ROI/New/270_HE.png',\n",
       "   'ROI/New/271_HE.png',\n",
       "   'ROI/New/272_HE.png',\n",
       "   'ROI/New/276_HE.png',\n",
       "   'ROI/New/277_HE.png',\n",
       "   'ROI/New/278_HE.png',\n",
       "   'ROI/New/279_HE.png',\n",
       "   'ROI/New/280_HE.png',\n",
       "   'ROI/New/281_HE.png',\n",
       "   'ROI/New/283_HE.png',\n",
       "   'ROI/New/286_HE.png',\n",
       "   'ROI/New/287_HE.png',\n",
       "   'ROI/New/289_HE.png',\n",
       "   'ROI/New/290_HE.png',\n",
       "   'ROI/New/292_HE.png',\n",
       "   'ROI/New/293_HE.png',\n",
       "   'ROI/New/294_HE.png',\n",
       "   'ROI/New/295_HE.png',\n",
       "   'ROI/New/296_HE.png',\n",
       "   'ROI/New/298_HE.png',\n",
       "   'ROI/New/299_HE.png',\n",
       "   'ROI/New/300_HE.png',\n",
       "   'ROI/New/301_HE.png',\n",
       "   'ROI/New/302_HE.png',\n",
       "   'ROI/New/304_HE.png',\n",
       "   'ROI/New/305_HE.png',\n",
       "   'ROI/New/308_HE.png',\n",
       "   'ROI/New/309_HE.png',\n",
       "   'ROI/New/310_HE.png',\n",
       "   'ROI/New/311_HE.png',\n",
       "   'ROI/New/312_HE.png',\n",
       "   'ROI/New/313_HE.png',\n",
       "   'ROI/New/314_HE.png',\n",
       "   'ROI/New/315_HE.png',\n",
       "   'ROI/New/316_HE.png',\n",
       "   'ROI/New/317_HE.png',\n",
       "   'ROI/New/319_HE.png',\n",
       "   'ROI/New/320_HE.png',\n",
       "   'ROI/New/321_HE.png',\n",
       "   'ROI/New/322_HE.png',\n",
       "   'ROI/New/323_HE.png',\n",
       "   'ROI/New/324_HE.png',\n",
       "   'ROI/New/325_HE.png',\n",
       "   'ROI/New/327_HE.png',\n",
       "   'ROI/New/328_HE.png',\n",
       "   'ROI/New/332_HE.png',\n",
       "   'ROI/New/333_HE.png',\n",
       "   'ROI/New/336_HE.png',\n",
       "   'ROI/New/337_HE.png',\n",
       "   'ROI/New/340_HE.png',\n",
       "   'ROI/New/342_HE.png',\n",
       "   'ROI/New/344_HE.png',\n",
       "   'ROI/New/345_HE.png',\n",
       "   'ROI/New/346_HE.png',\n",
       "   'ROI/New/347_HE.png',\n",
       "   'ROI/New/348_HE.png',\n",
       "   'ROI/New/350_HE.png',\n",
       "   'ROI/New/351_HE.png',\n",
       "   'ROI/New/355_HE.png',\n",
       "   'ROI/New/356_HE.png',\n",
       "   'ROI/New/360_HE.png',\n",
       "   'ROI/New/361_HE.png',\n",
       "   'ROI/New/363_HE.png',\n",
       "   'ROI/New/368_HE.png',\n",
       "   'ROI/New/371_HE.png',\n",
       "   'ROI/New/372_HE.png',\n",
       "   'ROI/New/374_HE.png',\n",
       "   'ROI/New/376_HE.png',\n",
       "   'ROI/New/379_HE.png',\n",
       "   'ROI/New/380_HE.png',\n",
       "   'ROI/New/382_HE.png',\n",
       "   'ROI/New/384_HE.png',\n",
       "   'ROI/New/386_HE.png',\n",
       "   'ROI/New/387_HE.png',\n",
       "   'ROI/New/390_HE.png',\n",
       "   'ROI/New/391_HE.png',\n",
       "   'ROI/New/394_HE.png',\n",
       "   'ROI/New/395_HE.png',\n",
       "   'ROI/New/397_HE.png',\n",
       "   'ROI/New/399_HE.png',\n",
       "   'ROI/New/400_HE.png',\n",
       "   'ROI/New/401_HE.png',\n",
       "   'ROI/New/402_HE.png',\n",
       "   'ROI/New/403_HE.png',\n",
       "   'ROI/New/404_HE.png',\n",
       "   'ROI/New/406_HE.png',\n",
       "   'ROI/New/407_HE.png',\n",
       "   'ROI/New/409_HE.png',\n",
       "   'ROI/New/411_HE.png',\n",
       "   'ROI/New/412_HE.png',\n",
       "   'ROI/New/413_HE.png',\n",
       "   'ROI/New/414_HE.png',\n",
       "   'ROI/New/415_HE.png',\n",
       "   'ROI/New/417_HE.png',\n",
       "   'ROI/New/418_HE.png',\n",
       "   'ROI/New/419_HE.png',\n",
       "   'ROI/New/420_HE.png',\n",
       "   'ROI/New/421_HE.png',\n",
       "   'ROI/New/423_HE.png',\n",
       "   'ROI/New/424_HE.png',\n",
       "   'ROI/New/425_HE.png',\n",
       "   'ROI/New/426_HE.png',\n",
       "   'ROI/New/427_HE.png',\n",
       "   'ROI/New/428_HE.png',\n",
       "   'ROI/New/429_HE.png',\n",
       "   'ROI/New/431_HE.png',\n",
       "   'ROI/New/432_HE.png',\n",
       "   'ROI/New/433_HE.png',\n",
       "   'ROI/New/435_HE.png',\n",
       "   'ROI/New/436_HE.png',\n",
       "   'ROI/New/437_HE.png',\n",
       "   'ROI/New/439_HE.png',\n",
       "   'ROI/New/441_HE.png',\n",
       "   'ROI/New/443_HE.png',\n",
       "   'ROI/New/444_HE.png',\n",
       "   'ROI/New/446_HE.png',\n",
       "   'ROI/New/447_HE.png',\n",
       "   'ROI/New/448_HE.png',\n",
       "   'ROI/New/450_HE.png',\n",
       "   'ROI/New/452_HE.png',\n",
       "   'ROI/New/453_HE.png',\n",
       "   'ROI/New/454_HE.png',\n",
       "   'ROI/New/458_HE.png',\n",
       "   'ROI/New/459_HE.png',\n",
       "   'ROI/New/460_HE.png',\n",
       "   'ROI/New/462_HE.png',\n",
       "   'ROI/New/463_HE.png',\n",
       "   'ROI/New/464_HE.png',\n",
       "   'ROI/New/465_HE.png',\n",
       "   'ROI/New/467_HE.png',\n",
       "   'ROI/New/469_HE.png',\n",
       "   'ROI/New/470_HE.png',\n",
       "   'ROI/New/472_HE.png',\n",
       "   'ROI/New/474_HE.png',\n",
       "   'ROI/New/475_HE.png',\n",
       "   'ROI/New/476_HE.png',\n",
       "   'ROI/New/477_HE.png',\n",
       "   'ROI/New/478_HE.png',\n",
       "   'ROI/New/480_HE.png',\n",
       "   'ROI/New/481_HE.png',\n",
       "   'ROI/New/483_HE.png',\n",
       "   'ROI/New/484_HE.png',\n",
       "   'ROI/New/485_HE.png',\n",
       "   'ROI/New/486_HE.png',\n",
       "   'ROI/New/488_HE.png',\n",
       "   'ROI/New/489_HE.png',\n",
       "   'ROI/New/490_HE.png',\n",
       "   'ROI/New/491_HE.png',\n",
       "   'ROI/New/492_HE.png',\n",
       "   'ROI/New/493_HE.png',\n",
       "   'ROI/New/494_HE.png',\n",
       "   'ROI/New/495_HE.png',\n",
       "   'ROI/New/497_HE.png',\n",
       "   'ROI/New/499_HE.png',\n",
       "   'ROI/New/501_HE.png',\n",
       "   'ROI/New/503_HE.png',\n",
       "   'ROI/New/505_HE.png',\n",
       "   'ROI/New/506_HE.png',\n",
       "   'ROI/New/507_HE.png',\n",
       "   'ROI/New/509_HE.png',\n",
       "   'ROI/New/512_HE.png',\n",
       "   'ROI/New/517_HE.png',\n",
       "   'ROI/New/520_HE.png',\n",
       "   'ROI/New/521_HE.png',\n",
       "   'ROI/New/524_HE.png',\n",
       "   'ROI/New/526_HE.png',\n",
       "   'ROI/New/529_HE.png',\n",
       "   'ROI/New/530_HE.png',\n",
       "   'ROI/New/532_HE.png',\n",
       "   'ROI/New/535_HE.png',\n",
       "   'ROI/New/536_HE.png',\n",
       "   'ROI/New/537_HE.png',\n",
       "   'ROI/New/538_HE.png',\n",
       "   'ROI/New/541_HE.png',\n",
       "   'ROI/New/542_HE.png'],\n",
       "  ['ROI/New/1059_HE.png',\n",
       "   'ROI/New/1138_HE.png',\n",
       "   'ROI/New/840_HE.png',\n",
       "   'ROI/New/543_HE.png',\n",
       "   'ROI/New/306_HE.png',\n",
       "   'ROI/New/373_HE.png',\n",
       "   'ROI/New/362_HE.png',\n",
       "   'ROI/New/378_HE.png',\n",
       "   'ROI/New/142_HE.png',\n",
       "   'ROI/New/44_HE.png',\n",
       "   'ROI/New/124_HE.png',\n",
       "   'ROI/New/1210000_HE.png',\n",
       "   'ROI/New/430000_HE.png',\n",
       "   'ROI/New/620000_HE.png',\n",
       "   'ROI/New/2140000_HE.png',\n",
       "   'ROI/New/6200000_HE.png',\n",
       "   'ROI/New/660000_HE.png',\n",
       "   'ROI/New/8100000_HE.png',\n",
       "   'ROI/New/1270000_HE.png',\n",
       "   'ROI/New/1940000_HE.png',\n",
       "   'ROI/New/1100000_HE.png',\n",
       "   'ROI/New/50000_HE.png',\n",
       "   'ROI/New/420000_HE.png',\n",
       "   'ROI/New/7900000_HE.png',\n",
       "   'ROI/New/1460000_HE.png',\n",
       "   'ROI/New/551_HE.png',\n",
       "   'ROI/New/555_HE.png',\n",
       "   'ROI/New/560_HE.png',\n",
       "   'ROI/New/563_HE.png',\n",
       "   'ROI/New/564_HE.png',\n",
       "   'ROI/New/576_HE.png',\n",
       "   'ROI/New/598_HE.png',\n",
       "   'ROI/New/601_HE.png',\n",
       "   'ROI/New/603_HE.png',\n",
       "   'ROI/New/609_HE.png',\n",
       "   'ROI/New/610_HE.png',\n",
       "   'ROI/New/627_HE.png',\n",
       "   'ROI/New/641_HE.png',\n",
       "   'ROI/New/648_HE.png',\n",
       "   'ROI/New/649_HE.png',\n",
       "   'ROI/New/661_HE.png',\n",
       "   'ROI/New/666_HE.png',\n",
       "   'ROI/New/670_HE.png',\n",
       "   'ROI/New/676_HE.png',\n",
       "   'ROI/New/688_HE.png',\n",
       "   'ROI/New/692_HE.png',\n",
       "   'ROI/New/704_HE.png',\n",
       "   'ROI/New/710_HE.png',\n",
       "   'ROI/New/714_HE.png',\n",
       "   'ROI/New/722_HE.png',\n",
       "   'ROI/New/724_HE.png',\n",
       "   'ROI/New/729_HE.png',\n",
       "   'ROI/New/730_HE.png',\n",
       "   'ROI/New/735_HE.png',\n",
       "   'ROI/New/738_HE.png',\n",
       "   'ROI/New/745_HE.png',\n",
       "   'ROI/New/750_HE.png',\n",
       "   'ROI/New/753_HE.png',\n",
       "   'ROI/New/755_HE.png',\n",
       "   'ROI/New/762_HE.png',\n",
       "   'ROI/New/767_HE.png',\n",
       "   'ROI/New/770_HE.png',\n",
       "   'ROI/New/779_HE.png',\n",
       "   'ROI/New/782_HE.png',\n",
       "   'ROI/New/783_HE.png',\n",
       "   'ROI/New/789_HE.png',\n",
       "   'ROI/New/794_HE.png',\n",
       "   'ROI/New/795_HE.png',\n",
       "   'ROI/New/796_HE.png',\n",
       "   'ROI/New/798_HE.png',\n",
       "   'ROI/New/801_HE.png',\n",
       "   'ROI/New/817_HE.png',\n",
       "   'ROI/New/846_HE.png',\n",
       "   'ROI/New/851_HE.png',\n",
       "   'ROI/New/856_HE.png',\n",
       "   'ROI/New/875_HE.png',\n",
       "   'ROI/New/896_HE.png',\n",
       "   'ROI/New/897_HE.png',\n",
       "   'ROI/New/904_HE.png',\n",
       "   'ROI/New/911_HE.png',\n",
       "   'ROI/New/912_HE.png',\n",
       "   'ROI/New/914_HE.png',\n",
       "   'ROI/New/918_HE.png',\n",
       "   'ROI/New/923_HE.png',\n",
       "   'ROI/New/941_HE.png',\n",
       "   'ROI/New/969_HE.png',\n",
       "   'ROI/New/972_HE.png',\n",
       "   'ROI/New/976_HE.png',\n",
       "   'ROI/New/982_HE.png',\n",
       "   'ROI/New/986_HE.png',\n",
       "   'ROI/New/990_HE.png',\n",
       "   'ROI/New/994_HE.png',\n",
       "   'ROI/New/998_HE.png',\n",
       "   'ROI/New/1002_HE.png',\n",
       "   'ROI/New/1004_HE.png',\n",
       "   'ROI/New/1006_HE.png',\n",
       "   'ROI/New/1025_HE.png',\n",
       "   'ROI/New/1029_HE.png',\n",
       "   'ROI/New/1033_HE.png',\n",
       "   'ROI/New/1040_HE.png',\n",
       "   'ROI/New/1045_HE.png',\n",
       "   'ROI/New/1046_HE.png',\n",
       "   'ROI/New/1061_HE.png',\n",
       "   'ROI/New/1066_HE.png',\n",
       "   'ROI/New/1067_HE.png',\n",
       "   'ROI/New/1069_HE.png',\n",
       "   'ROI/New/1081_HE.png',\n",
       "   'ROI/New/1087_HE.png',\n",
       "   'ROI/New/1098_HE.png',\n",
       "   'ROI/New/1114_HE.png',\n",
       "   'ROI/New/1115_HE.png',\n",
       "   'ROI/New/1122_HE.png',\n",
       "   'ROI/New/1127_HE.png',\n",
       "   'ROI/New/1128_HE.png',\n",
       "   'ROI/New/1130_HE.png',\n",
       "   'ROI/New/1132_HE.png',\n",
       "   'ROI/New/1141_HE.png',\n",
       "   'ROI/New/1143_HE.png',\n",
       "   'ROI/New/1146_HE.png',\n",
       "   'ROI/New/1150_HE.png',\n",
       "   'ROI/New/1163_HE.png',\n",
       "   'ROI/New/1167_HE.png',\n",
       "   'ROI/New/1170_HE.png',\n",
       "   'ROI/New/1176_HE.png',\n",
       "   'ROI/New/1177_HE.png',\n",
       "   'ROI/New/1193_HE.png',\n",
       "   'ROI/New/210000_HE.png',\n",
       "   'ROI/New/410000_HE.png',\n",
       "   'ROI/New/1520000_HE.png',\n",
       "   'ROI/New/2020000_HE.png',\n",
       "   'ROI/New/2370000_HE.png',\n",
       "   'ROI/New/201750000_HE.png',\n",
       "   'ROI/New/201760000_HE.png',\n",
       "   'ROI/New/201770000_HE.png',\n",
       "   'ROI/New/201780000_HE.png',\n",
       "   'ROI/New/201810000_HE.png',\n",
       "   'ROI/New/201830000_HE.png',\n",
       "   'ROI/New/201950000_HE.png',\n",
       "   'ROI/New/201960000_HE.png',\n",
       "   'ROI/New/201990000_HE.png',\n",
       "   'ROI/New/202030000_HE.png',\n",
       "   'ROI/New/202250000_HE.png',\n",
       "   'ROI/New/2016110000_HE.png',\n",
       "   'ROI/New/2017150000_HE.png',\n",
       "   'ROI/New/2019140000_HE.png',\n",
       "   'ROI/New/2019160000_HE.png',\n",
       "   'ROI/New/2019170000_HE.png',\n",
       "   'ROI/New/2022100000_HE.png',\n",
       "   'ROI/New/2022200000_HE.png',\n",
       "   'ROI/New/2022240000_HE.png',\n",
       "   'ROI/New/1_HE.png',\n",
       "   'ROI/New/9_HE.png',\n",
       "   'ROI/New/16_HE.png',\n",
       "   'ROI/New/48_HE.png',\n",
       "   'ROI/New/50_HE.png',\n",
       "   'ROI/New/58_HE.png',\n",
       "   'ROI/New/60_HE.png',\n",
       "   'ROI/New/62_HE.png',\n",
       "   'ROI/New/76_HE.png',\n",
       "   'ROI/New/78_HE.png',\n",
       "   'ROI/New/82_HE.png',\n",
       "   'ROI/New/84_HE.png',\n",
       "   'ROI/New/88_HE.png',\n",
       "   'ROI/New/92_HE.png',\n",
       "   'ROI/New/93_HE.png',\n",
       "   'ROI/New/95_HE.png',\n",
       "   'ROI/New/101_HE.png',\n",
       "   'ROI/New/102_HE.png',\n",
       "   'ROI/New/104_HE.png',\n",
       "   'ROI/New/106_HE.png',\n",
       "   'ROI/New/114_HE.png',\n",
       "   'ROI/New/120_HE.png',\n",
       "   'ROI/New/122_HE.png',\n",
       "   'ROI/New/125_HE.png',\n",
       "   'ROI/New/134_HE.png',\n",
       "   'ROI/New/160_HE.png',\n",
       "   'ROI/New/170_HE.png',\n",
       "   'ROI/New/171_HE.png',\n",
       "   'ROI/New/172_HE.png',\n",
       "   'ROI/New/175_HE.png',\n",
       "   'ROI/New/188_HE.png',\n",
       "   'ROI/New/193_HE.png',\n",
       "   'ROI/New/194_HE.png',\n",
       "   'ROI/New/198_HE.png',\n",
       "   'ROI/New/201_HE.png',\n",
       "   'ROI/New/203_HE.png',\n",
       "   'ROI/New/205_HE.png',\n",
       "   'ROI/New/212_HE.png',\n",
       "   'ROI/New/214_HE.png',\n",
       "   'ROI/New/224_HE.png',\n",
       "   'ROI/New/227_HE.png',\n",
       "   'ROI/New/236_HE.png',\n",
       "   'ROI/New/244_HE.png',\n",
       "   'ROI/New/260_HE.png',\n",
       "   'ROI/New/307_HE.png',\n",
       "   'ROI/New/318_HE.png',\n",
       "   'ROI/New/329_HE.png',\n",
       "   'ROI/New/341_HE.png',\n",
       "   'ROI/New/343_HE.png',\n",
       "   'ROI/New/352_HE.png',\n",
       "   'ROI/New/358_HE.png',\n",
       "   'ROI/New/364_HE.png',\n",
       "   'ROI/New/365_HE.png',\n",
       "   'ROI/New/366_HE.png',\n",
       "   'ROI/New/375_HE.png',\n",
       "   'ROI/New/377_HE.png',\n",
       "   'ROI/New/381_HE.png',\n",
       "   'ROI/New/383_HE.png',\n",
       "   'ROI/New/385_HE.png',\n",
       "   'ROI/New/388_HE.png',\n",
       "   'ROI/New/392_HE.png',\n",
       "   'ROI/New/396_HE.png',\n",
       "   'ROI/New/410_HE.png',\n",
       "   'ROI/New/430_HE.png',\n",
       "   'ROI/New/440_HE.png',\n",
       "   'ROI/New/445_HE.png',\n",
       "   'ROI/New/449_HE.png',\n",
       "   'ROI/New/451_HE.png',\n",
       "   'ROI/New/455_HE.png',\n",
       "   'ROI/New/457_HE.png',\n",
       "   'ROI/New/466_HE.png',\n",
       "   'ROI/New/479_HE.png',\n",
       "   'ROI/New/482_HE.png',\n",
       "   'ROI/New/487_HE.png',\n",
       "   'ROI/New/496_HE.png',\n",
       "   'ROI/New/500_HE.png',\n",
       "   'ROI/New/502_HE.png',\n",
       "   'ROI/New/510_HE.png',\n",
       "   'ROI/New/518_HE.png',\n",
       "   'ROI/New/519_HE.png',\n",
       "   'ROI/New/522_HE.png',\n",
       "   'ROI/New/525_HE.png',\n",
       "   'ROI/New/534_HE.png',\n",
       "   'ROI/New/539_HE.png',\n",
       "   'ROI/New/540_HE.png']],\n",
       " [['ROI/New/248_HE.png',\n",
       "   'ROI/New/357_HE.png',\n",
       "   'ROI/New/89_HE.png',\n",
       "   'ROI/New/1059_HE.png',\n",
       "   'ROI/New/269_HE.png',\n",
       "   'ROI/New/620_HE.png',\n",
       "   'ROI/New/191_HE.png',\n",
       "   'ROI/New/1125_HE.png',\n",
       "   'ROI/New/1138_HE.png',\n",
       "   'ROI/New/840_HE.png',\n",
       "   'ROI/New/845_HE.png',\n",
       "   'ROI/New/543_HE.png',\n",
       "   'ROI/New/622_HE.png',\n",
       "   'ROI/New/650_HE.png',\n",
       "   'ROI/New/228_HE.png',\n",
       "   'ROI/New/225_HE.png',\n",
       "   'ROI/New/246_HE.png',\n",
       "   'ROI/New/242_HE.png',\n",
       "   'ROI/New/259_HE.png',\n",
       "   'ROI/New/268_HE.png',\n",
       "   'ROI/New/275_HE.png',\n",
       "   'ROI/New/266_HE.png',\n",
       "   'ROI/New/288_HE.png',\n",
       "   'ROI/New/306_HE.png',\n",
       "   'ROI/New/297_HE.png',\n",
       "   'ROI/New/353_HE.png',\n",
       "   'ROI/New/369_HE.png',\n",
       "   'ROI/New/373_HE.png',\n",
       "   'ROI/New/362_HE.png',\n",
       "   'ROI/New/378_HE.png',\n",
       "   'ROI/New/142_HE.png',\n",
       "   'ROI/New/389_HE.png',\n",
       "   'ROI/New/35_HE.png',\n",
       "   'ROI/New/31_HE.png',\n",
       "   'ROI/New/44_HE.png',\n",
       "   'ROI/New/67_HE.png',\n",
       "   'ROI/New/80_HE.png',\n",
       "   'ROI/New/143_HE.png',\n",
       "   'ROI/New/124_HE.png',\n",
       "   'ROI/New/149_HE.png',\n",
       "   'ROI/New/179_HE.png',\n",
       "   'ROI/New/165_HE.png',\n",
       "   'ROI/New/902_HE.png',\n",
       "   'ROI/New/1210000_HE.png',\n",
       "   'ROI/New/430000_HE.png',\n",
       "   'ROI/New/1580000_HE.png',\n",
       "   'ROI/New/790000_HE.png',\n",
       "   'ROI/New/730000_HE.png',\n",
       "   'ROI/New/2270000_HE.png',\n",
       "   'ROI/New/440000_HE.png',\n",
       "   'ROI/New/620000_HE.png',\n",
       "   'ROI/New/2290000_HE.png',\n",
       "   'ROI/New/2140000_HE.png',\n",
       "   'ROI/New/6200000_HE.png',\n",
       "   'ROI/New/360000_HE.png',\n",
       "   'ROI/New/10900000_HE.png',\n",
       "   'ROI/New/340000_HE.png',\n",
       "   'ROI/New/940000_HE.png',\n",
       "   'ROI/New/830000_HE.png',\n",
       "   'ROI/New/1440000_HE.png',\n",
       "   'ROI/New/1040000_HE.png',\n",
       "   'ROI/New/1070000_HE.png',\n",
       "   'ROI/New/330000_HE.png',\n",
       "   'ROI/New/1320000_HE.png',\n",
       "   'ROI/New/660000_HE.png',\n",
       "   'ROI/New/8100000_HE.png',\n",
       "   'ROI/New/1590000_HE.png',\n",
       "   'ROI/New/1050000_HE.png',\n",
       "   'ROI/New/1310000_HE.png',\n",
       "   'ROI/New/820000_HE.png',\n",
       "   'ROI/New/202020000_HE.png',\n",
       "   'ROI/New/9700000_HE.png',\n",
       "   'ROI/New/2022160000_HE.png',\n",
       "   'ROI/New/2230000_HE.png',\n",
       "   'ROI/New/490000_HE.png',\n",
       "   'ROI/New/15200000_HE.png',\n",
       "   'ROI/New/1470000_HE.png',\n",
       "   'ROI/New/1270000_HE.png',\n",
       "   'ROI/New/650000_HE.png',\n",
       "   'ROI/New/1000000_HE.png',\n",
       "   'ROI/New/2220000_HE.png',\n",
       "   'ROI/New/370000_HE.png',\n",
       "   'ROI/New/970000_HE.png',\n",
       "   'ROI/New/460000_HE.png',\n",
       "   'ROI/New/310000_HE.png',\n",
       "   'ROI/New/530000_HE.png',\n",
       "   'ROI/New/1940000_HE.png',\n",
       "   'ROI/New/2022140000_HE.png',\n",
       "   'ROI/New/1290000_HE.png',\n",
       "   'ROI/New/640000_HE.png',\n",
       "   'ROI/New/2016120000_HE.png',\n",
       "   'ROI/New/201620000_HE.png',\n",
       "   'ROI/New/2017160000_HE.png',\n",
       "   'ROI/New/1100000_HE.png',\n",
       "   'ROI/New/2017110000_HE.png',\n",
       "   'ROI/New/1060000_HE.png',\n",
       "   'ROI/New/2019180000_HE.png',\n",
       "   'ROI/New/3010000_HE.png',\n",
       "   'ROI/New/1020000_HE.png',\n",
       "   'ROI/New/1570000_HE.png',\n",
       "   'ROI/New/1090000_HE.png',\n",
       "   'ROI/New/202050000_HE.png',\n",
       "   'ROI/New/1230000_HE.png',\n",
       "   'ROI/New/50000_HE.png',\n",
       "   'ROI/New/110000_HE.png',\n",
       "   'ROI/New/300000_HE.png',\n",
       "   'ROI/New/420000_HE.png',\n",
       "   'ROI/New/840000_HE.png',\n",
       "   'ROI/New/890000_HE.png',\n",
       "   'ROI/New/930000_HE.png',\n",
       "   'ROI/New/1650000_HE.png',\n",
       "   'ROI/New/1920000_HE.png',\n",
       "   'ROI/New/2010000_HE.png',\n",
       "   'ROI/New/670000_HE.png',\n",
       "   'ROI/New/7900000_HE.png',\n",
       "   'ROI/New/810000_HE.png',\n",
       "   'ROI/New/1400000_HE.png',\n",
       "   'ROI/New/1460000_HE.png',\n",
       "   'ROI/New/14700000_HE.png',\n",
       "   'ROI/New/2510000_HE.png',\n",
       "   'ROI/New/120000_HE.png',\n",
       "   'ROI/New/16000000_HE.png',\n",
       "   'ROI/New/200000_HE.png',\n",
       "   'ROI/New/470000_HE.png',\n",
       "   'ROI/New/630000_HE.png',\n",
       "   'ROI/New/740000_HE.png',\n",
       "   'ROI/New/8400000_HE.png',\n",
       "   'ROI/New/2016100000_HE.png',\n",
       "   'ROI/New/544_HE.png',\n",
       "   'ROI/New/546_HE.png',\n",
       "   'ROI/New/548_HE.png',\n",
       "   'ROI/New/550_HE.png',\n",
       "   'ROI/New/551_HE.png',\n",
       "   'ROI/New/553_HE.png',\n",
       "   'ROI/New/554_HE.png',\n",
       "   'ROI/New/555_HE.png',\n",
       "   'ROI/New/558_HE.png',\n",
       "   'ROI/New/559_HE.png',\n",
       "   'ROI/New/560_HE.png',\n",
       "   'ROI/New/562_HE.png',\n",
       "   'ROI/New/563_HE.png',\n",
       "   'ROI/New/564_HE.png',\n",
       "   'ROI/New/566_HE.png',\n",
       "   'ROI/New/567_HE.png',\n",
       "   'ROI/New/568_HE.png',\n",
       "   'ROI/New/569_HE.png',\n",
       "   'ROI/New/570_HE.png',\n",
       "   'ROI/New/572_HE.png',\n",
       "   'ROI/New/574_HE.png',\n",
       "   'ROI/New/575_HE.png',\n",
       "   'ROI/New/576_HE.png',\n",
       "   'ROI/New/577_HE.png',\n",
       "   'ROI/New/581_HE.png',\n",
       "   'ROI/New/582_HE.png',\n",
       "   'ROI/New/583_HE.png',\n",
       "   'ROI/New/584_HE.png',\n",
       "   'ROI/New/585_HE.png',\n",
       "   'ROI/New/586_HE.png',\n",
       "   'ROI/New/587_HE.png',\n",
       "   'ROI/New/588_HE.png',\n",
       "   'ROI/New/589_HE.png',\n",
       "   'ROI/New/590_HE.png',\n",
       "   'ROI/New/591_HE.png',\n",
       "   'ROI/New/592_HE.png',\n",
       "   'ROI/New/593_HE.png',\n",
       "   'ROI/New/596_HE.png',\n",
       "   'ROI/New/598_HE.png',\n",
       "   'ROI/New/599_HE.png',\n",
       "   'ROI/New/601_HE.png',\n",
       "   'ROI/New/603_HE.png',\n",
       "   'ROI/New/604_HE.png',\n",
       "   'ROI/New/606_HE.png',\n",
       "   'ROI/New/607_HE.png',\n",
       "   'ROI/New/608_HE.png',\n",
       "   'ROI/New/609_HE.png',\n",
       "   'ROI/New/610_HE.png',\n",
       "   'ROI/New/611_HE.png',\n",
       "   'ROI/New/612_HE.png',\n",
       "   'ROI/New/613_HE.png',\n",
       "   'ROI/New/615_HE.png',\n",
       "   'ROI/New/616_HE.png',\n",
       "   'ROI/New/617_HE.png',\n",
       "   'ROI/New/618_HE.png',\n",
       "   'ROI/New/621_HE.png',\n",
       "   'ROI/New/623_HE.png',\n",
       "   'ROI/New/627_HE.png',\n",
       "   'ROI/New/629_HE.png',\n",
       "   'ROI/New/633_HE.png',\n",
       "   'ROI/New/635_HE.png',\n",
       "   'ROI/New/636_HE.png',\n",
       "   'ROI/New/637_HE.png',\n",
       "   'ROI/New/638_HE.png',\n",
       "   'ROI/New/640_HE.png',\n",
       "   'ROI/New/641_HE.png',\n",
       "   'ROI/New/643_HE.png',\n",
       "   'ROI/New/646_HE.png',\n",
       "   'ROI/New/648_HE.png',\n",
       "   'ROI/New/649_HE.png',\n",
       "   'ROI/New/651_HE.png',\n",
       "   'ROI/New/652_HE.png',\n",
       "   'ROI/New/654_HE.png',\n",
       "   'ROI/New/655_HE.png',\n",
       "   'ROI/New/656_HE.png',\n",
       "   'ROI/New/657_HE.png',\n",
       "   'ROI/New/658_HE.png',\n",
       "   'ROI/New/660_HE.png',\n",
       "   'ROI/New/661_HE.png',\n",
       "   'ROI/New/664_HE.png',\n",
       "   'ROI/New/665_HE.png',\n",
       "   'ROI/New/666_HE.png',\n",
       "   'ROI/New/667_HE.png',\n",
       "   'ROI/New/668_HE.png',\n",
       "   'ROI/New/670_HE.png',\n",
       "   'ROI/New/671_HE.png',\n",
       "   'ROI/New/674_HE.png',\n",
       "   'ROI/New/675_HE.png',\n",
       "   'ROI/New/676_HE.png',\n",
       "   'ROI/New/677_HE.png',\n",
       "   'ROI/New/679_HE.png',\n",
       "   'ROI/New/682_HE.png',\n",
       "   'ROI/New/684_HE.png',\n",
       "   'ROI/New/685_HE.png',\n",
       "   'ROI/New/686_HE.png',\n",
       "   'ROI/New/687_HE.png',\n",
       "   'ROI/New/688_HE.png',\n",
       "   'ROI/New/690_HE.png',\n",
       "   'ROI/New/692_HE.png',\n",
       "   'ROI/New/693_HE.png',\n",
       "   'ROI/New/694_HE.png',\n",
       "   'ROI/New/695_HE.png',\n",
       "   'ROI/New/698_HE.png',\n",
       "   'ROI/New/699_HE.png',\n",
       "   'ROI/New/701_HE.png',\n",
       "   'ROI/New/702_HE.png',\n",
       "   'ROI/New/703_HE.png',\n",
       "   'ROI/New/704_HE.png',\n",
       "   'ROI/New/705_HE.png',\n",
       "   'ROI/New/708_HE.png',\n",
       "   'ROI/New/710_HE.png',\n",
       "   'ROI/New/712_HE.png',\n",
       "   'ROI/New/713_HE.png',\n",
       "   'ROI/New/714_HE.png',\n",
       "   'ROI/New/715_HE.png',\n",
       "   'ROI/New/717_HE.png',\n",
       "   'ROI/New/718_HE.png',\n",
       "   'ROI/New/720_HE.png',\n",
       "   'ROI/New/721_HE.png',\n",
       "   'ROI/New/722_HE.png',\n",
       "   'ROI/New/723_HE.png',\n",
       "   'ROI/New/724_HE.png',\n",
       "   'ROI/New/727_HE.png',\n",
       "   'ROI/New/728_HE.png',\n",
       "   'ROI/New/729_HE.png',\n",
       "   'ROI/New/730_HE.png',\n",
       "   'ROI/New/731_HE.png',\n",
       "   'ROI/New/732_HE.png',\n",
       "   'ROI/New/734_HE.png',\n",
       "   'ROI/New/735_HE.png',\n",
       "   'ROI/New/736_HE.png',\n",
       "   'ROI/New/737_HE.png',\n",
       "   'ROI/New/738_HE.png',\n",
       "   'ROI/New/742_HE.png',\n",
       "   'ROI/New/743_HE.png',\n",
       "   'ROI/New/745_HE.png',\n",
       "   'ROI/New/746_HE.png',\n",
       "   'ROI/New/747_HE.png',\n",
       "   'ROI/New/749_HE.png',\n",
       "   'ROI/New/750_HE.png',\n",
       "   'ROI/New/753_HE.png',\n",
       "   'ROI/New/754_HE.png',\n",
       "   'ROI/New/755_HE.png',\n",
       "   'ROI/New/756_HE.png',\n",
       "   'ROI/New/757_HE.png',\n",
       "   'ROI/New/760_HE.png',\n",
       "   'ROI/New/761_HE.png',\n",
       "   'ROI/New/762_HE.png',\n",
       "   'ROI/New/764_HE.png',\n",
       "   'ROI/New/765_HE.png',\n",
       "   'ROI/New/766_HE.png',\n",
       "   'ROI/New/767_HE.png',\n",
       "   'ROI/New/768_HE.png',\n",
       "   'ROI/New/769_HE.png',\n",
       "   'ROI/New/770_HE.png',\n",
       "   'ROI/New/771_HE.png',\n",
       "   'ROI/New/774_HE.png',\n",
       "   'ROI/New/777_HE.png',\n",
       "   'ROI/New/778_HE.png',\n",
       "   'ROI/New/779_HE.png',\n",
       "   'ROI/New/782_HE.png',\n",
       "   'ROI/New/783_HE.png',\n",
       "   'ROI/New/785_HE.png',\n",
       "   'ROI/New/787_HE.png',\n",
       "   'ROI/New/788_HE.png',\n",
       "   'ROI/New/789_HE.png',\n",
       "   'ROI/New/792_HE.png',\n",
       "   'ROI/New/793_HE.png',\n",
       "   'ROI/New/794_HE.png',\n",
       "   'ROI/New/795_HE.png',\n",
       "   'ROI/New/796_HE.png',\n",
       "   'ROI/New/798_HE.png',\n",
       "   'ROI/New/800_HE.png',\n",
       "   'ROI/New/801_HE.png',\n",
       "   'ROI/New/803_HE.png',\n",
       "   'ROI/New/804_HE.png',\n",
       "   'ROI/New/810_HE.png',\n",
       "   'ROI/New/811_HE.png',\n",
       "   'ROI/New/814_HE.png',\n",
       "   'ROI/New/815_HE.png',\n",
       "   'ROI/New/816_HE.png',\n",
       "   'ROI/New/817_HE.png',\n",
       "   'ROI/New/818_HE.png',\n",
       "   'ROI/New/819_HE.png',\n",
       "   'ROI/New/820_HE.png',\n",
       "   'ROI/New/822_HE.png',\n",
       "   'ROI/New/823_HE.png',\n",
       "   'ROI/New/824_HE.png',\n",
       "   'ROI/New/825_HE.png',\n",
       "   'ROI/New/826_HE.png',\n",
       "   'ROI/New/828_HE.png',\n",
       "   'ROI/New/829_HE.png',\n",
       "   'ROI/New/830_HE.png',\n",
       "   'ROI/New/832_HE.png',\n",
       "   'ROI/New/836_HE.png',\n",
       "   'ROI/New/838_HE.png',\n",
       "   'ROI/New/842_HE.png',\n",
       "   'ROI/New/846_HE.png',\n",
       "   'ROI/New/847_HE.png',\n",
       "   'ROI/New/849_HE.png',\n",
       "   'ROI/New/850_HE.png',\n",
       "   'ROI/New/851_HE.png',\n",
       "   'ROI/New/852_HE.png',\n",
       "   'ROI/New/854_HE.png',\n",
       "   'ROI/New/855_HE.png',\n",
       "   'ROI/New/856_HE.png',\n",
       "   'ROI/New/858_HE.png',\n",
       "   'ROI/New/859_HE.png',\n",
       "   'ROI/New/860_HE.png',\n",
       "   'ROI/New/863_HE.png',\n",
       "   'ROI/New/865_HE.png',\n",
       "   'ROI/New/866_HE.png',\n",
       "   'ROI/New/867_HE.png',\n",
       "   'ROI/New/868_HE.png',\n",
       "   'ROI/New/869_HE.png',\n",
       "   'ROI/New/870_HE.png',\n",
       "   'ROI/New/872_HE.png',\n",
       "   'ROI/New/873_HE.png',\n",
       "   'ROI/New/874_HE.png',\n",
       "   'ROI/New/875_HE.png',\n",
       "   'ROI/New/876_HE.png',\n",
       "   'ROI/New/878_HE.png',\n",
       "   'ROI/New/880_HE.png',\n",
       "   'ROI/New/882_HE.png',\n",
       "   'ROI/New/888_HE.png',\n",
       "   'ROI/New/891_HE.png',\n",
       "   'ROI/New/892_HE.png',\n",
       "   'ROI/New/893_HE.png',\n",
       "   'ROI/New/896_HE.png',\n",
       "   'ROI/New/897_HE.png',\n",
       "   'ROI/New/900_HE.png',\n",
       "   'ROI/New/904_HE.png',\n",
       "   'ROI/New/907_HE.png',\n",
       "   'ROI/New/910_HE.png',\n",
       "   'ROI/New/911_HE.png',\n",
       "   'ROI/New/912_HE.png',\n",
       "   'ROI/New/914_HE.png',\n",
       "   'ROI/New/918_HE.png',\n",
       "   'ROI/New/923_HE.png',\n",
       "   'ROI/New/925_HE.png',\n",
       "   'ROI/New/927_HE.png',\n",
       "   'ROI/New/928_HE.png',\n",
       "   'ROI/New/929_HE.png',\n",
       "   'ROI/New/930_HE.png',\n",
       "   'ROI/New/932_HE.png',\n",
       "   'ROI/New/933_HE.png',\n",
       "   'ROI/New/936_HE.png',\n",
       "   'ROI/New/937_HE.png',\n",
       "   'ROI/New/938_HE.png',\n",
       "   'ROI/New/939_HE.png',\n",
       "   'ROI/New/941_HE.png',\n",
       "   'ROI/New/942_HE.png',\n",
       "   'ROI/New/943_HE.png',\n",
       "   'ROI/New/944_HE.png',\n",
       "   'ROI/New/947_HE.png',\n",
       "   'ROI/New/950_HE.png',\n",
       "   'ROI/New/951_HE.png',\n",
       "   'ROI/New/952_HE.png',\n",
       "   'ROI/New/953_HE.png',\n",
       "   'ROI/New/957_HE.png',\n",
       "   'ROI/New/959_HE.png',\n",
       "   'ROI/New/960_HE.png',\n",
       "   'ROI/New/962_HE.png',\n",
       "   'ROI/New/963_HE.png',\n",
       "   'ROI/New/966_HE.png',\n",
       "   'ROI/New/967_HE.png',\n",
       "   'ROI/New/969_HE.png',\n",
       "   'ROI/New/970_HE.png',\n",
       "   'ROI/New/972_HE.png',\n",
       "   'ROI/New/973_HE.png',\n",
       "   'ROI/New/975_HE.png',\n",
       "   'ROI/New/976_HE.png',\n",
       "   'ROI/New/977_HE.png',\n",
       "   'ROI/New/978_HE.png',\n",
       "   'ROI/New/980_HE.png',\n",
       "   'ROI/New/981_HE.png',\n",
       "   'ROI/New/982_HE.png',\n",
       "   'ROI/New/984_HE.png',\n",
       "   'ROI/New/986_HE.png',\n",
       "   'ROI/New/987_HE.png',\n",
       "   'ROI/New/988_HE.png',\n",
       "   'ROI/New/990_HE.png',\n",
       "   'ROI/New/991_HE.png',\n",
       "   'ROI/New/992_HE.png',\n",
       "   'ROI/New/993_HE.png',\n",
       "   'ROI/New/994_HE.png',\n",
       "   'ROI/New/995_HE.png',\n",
       "   'ROI/New/996_HE.png',\n",
       "   'ROI/New/997_HE.png',\n",
       "   'ROI/New/998_HE.png',\n",
       "   'ROI/New/1002_HE.png',\n",
       "   'ROI/New/1003_HE.png',\n",
       "   'ROI/New/1004_HE.png',\n",
       "   'ROI/New/1005_HE.png',\n",
       "   'ROI/New/1006_HE.png',\n",
       "   'ROI/New/1009_HE.png',\n",
       "   'ROI/New/1010_HE.png',\n",
       "   'ROI/New/1016_HE.png',\n",
       "   'ROI/New/1018_HE.png',\n",
       "   'ROI/New/1022_HE.png',\n",
       "   'ROI/New/1024_HE.png',\n",
       "   'ROI/New/1025_HE.png',\n",
       "   'ROI/New/1029_HE.png',\n",
       "   'ROI/New/1031_HE.png',\n",
       "   'ROI/New/1032_HE.png',\n",
       "   'ROI/New/1033_HE.png',\n",
       "   'ROI/New/1035_HE.png',\n",
       "   'ROI/New/1036_HE.png',\n",
       "   'ROI/New/1039_HE.png',\n",
       "   'ROI/New/1040_HE.png',\n",
       "   'ROI/New/1044_HE.png',\n",
       "   'ROI/New/1045_HE.png',\n",
       "   'ROI/New/1046_HE.png',\n",
       "   'ROI/New/1047_HE.png',\n",
       "   'ROI/New/1048_HE.png',\n",
       "   'ROI/New/1056_HE.png',\n",
       "   'ROI/New/1060_HE.png',\n",
       "   'ROI/New/1061_HE.png',\n",
       "   'ROI/New/1062_HE.png',\n",
       "   'ROI/New/1065_HE.png',\n",
       "   'ROI/New/1066_HE.png',\n",
       "   'ROI/New/1067_HE.png',\n",
       "   'ROI/New/1068_HE.png',\n",
       "   'ROI/New/1069_HE.png',\n",
       "   'ROI/New/1071_HE.png',\n",
       "   'ROI/New/1073_HE.png',\n",
       "   'ROI/New/1074_HE.png',\n",
       "   'ROI/New/1079_HE.png',\n",
       "   'ROI/New/1081_HE.png',\n",
       "   'ROI/New/1082_HE.png',\n",
       "   'ROI/New/1083_HE.png',\n",
       "   'ROI/New/1084_HE.png',\n",
       "   'ROI/New/1085_HE.png',\n",
       "   'ROI/New/1086_HE.png',\n",
       "   'ROI/New/1087_HE.png',\n",
       "   'ROI/New/1089_HE.png',\n",
       "   'ROI/New/1091_HE.png',\n",
       "   'ROI/New/1098_HE.png',\n",
       "   'ROI/New/1100_HE.png',\n",
       "   'ROI/New/1102_HE.png',\n",
       "   'ROI/New/1104_HE.png',\n",
       "   'ROI/New/1105_HE.png',\n",
       "   'ROI/New/1106_HE.png',\n",
       "   'ROI/New/1109_HE.png',\n",
       "   'ROI/New/1111_HE.png',\n",
       "   'ROI/New/1112_HE.png',\n",
       "   'ROI/New/1114_HE.png',\n",
       "   'ROI/New/1115_HE.png',\n",
       "   'ROI/New/1116_HE.png',\n",
       "   'ROI/New/1122_HE.png',\n",
       "   'ROI/New/1124_HE.png',\n",
       "   'ROI/New/1126_HE.png',\n",
       "   'ROI/New/1127_HE.png',\n",
       "   'ROI/New/1128_HE.png',\n",
       "   'ROI/New/1130_HE.png',\n",
       "   'ROI/New/1131_HE.png',\n",
       "   'ROI/New/1132_HE.png',\n",
       "   'ROI/New/1135_HE.png',\n",
       "   'ROI/New/1136_HE.png',\n",
       "   'ROI/New/1139_HE.png',\n",
       "   'ROI/New/1141_HE.png',\n",
       "   'ROI/New/1142_HE.png',\n",
       "   'ROI/New/1143_HE.png',\n",
       "   'ROI/New/1145_HE.png',\n",
       "   'ROI/New/1146_HE.png',\n",
       "   'ROI/New/1148_HE.png',\n",
       "   'ROI/New/1150_HE.png',\n",
       "   'ROI/New/1154_HE.png',\n",
       "   'ROI/New/1156_HE.png',\n",
       "   'ROI/New/1157_HE.png',\n",
       "   'ROI/New/1160_HE.png',\n",
       "   'ROI/New/1162_HE.png',\n",
       "   'ROI/New/1163_HE.png',\n",
       "   'ROI/New/1164_HE.png',\n",
       "   'ROI/New/1165_HE.png',\n",
       "   'ROI/New/1167_HE.png',\n",
       "   'ROI/New/1168_HE.png',\n",
       "   'ROI/New/1170_HE.png',\n",
       "   'ROI/New/1171_HE.png',\n",
       "   'ROI/New/1173_HE.png',\n",
       "   'ROI/New/1176_HE.png',\n",
       "   'ROI/New/1177_HE.png',\n",
       "   'ROI/New/1181_HE.png',\n",
       "   'ROI/New/1182_HE.png',\n",
       "   'ROI/New/1183_HE.png',\n",
       "   'ROI/New/1184_HE.png',\n",
       "   'ROI/New/1186_HE.png',\n",
       "   'ROI/New/1187_HE.png',\n",
       "   'ROI/New/1188_HE.png',\n",
       "   'ROI/New/1189_HE.png',\n",
       "   'ROI/New/1192_HE.png',\n",
       "   'ROI/New/1193_HE.png',\n",
       "   'ROI/New/150000_HE.png',\n",
       "   'ROI/New/160000_HE.png',\n",
       "   'ROI/New/210000_HE.png',\n",
       "   'ROI/New/410000_HE.png',\n",
       "   'ROI/New/1520000_HE.png',\n",
       "   'ROI/New/1600000_HE.png',\n",
       "   'ROI/New/1620000_HE.png',\n",
       "   'ROI/New/1660000_HE.png',\n",
       "   'ROI/New/1950000_HE.png',\n",
       "   'ROI/New/1970000_HE.png',\n",
       "   'ROI/New/2020000_HE.png',\n",
       "   'ROI/New/2250000_HE.png',\n",
       "   'ROI/New/2340000_HE.png',\n",
       "   'ROI/New/2370000_HE.png',\n",
       "   'ROI/New/2450000_HE.png',\n",
       "   'ROI/New/20200000_HE.png',\n",
       "   'ROI/New/201610000_HE.png',\n",
       "   'ROI/New/201640000_HE.png',\n",
       "   'ROI/New/201670000_HE.png',\n",
       "   'ROI/New/201690000_HE.png',\n",
       "   'ROI/New/201710000_HE.png',\n",
       "   'ROI/New/201720000_HE.png',\n",
       "   'ROI/New/201750000_HE.png',\n",
       "   'ROI/New/201760000_HE.png',\n",
       "   'ROI/New/201770000_HE.png',\n",
       "   'ROI/New/201780000_HE.png',\n",
       "   'ROI/New/201790000_HE.png',\n",
       "   'ROI/New/201810000_HE.png',\n",
       "   'ROI/New/201820000_HE.png',\n",
       "   'ROI/New/201830000_HE.png',\n",
       "   'ROI/New/201840000_HE.png',\n",
       "   'ROI/New/201850000_HE.png',\n",
       "   'ROI/New/201860000_HE.png',\n",
       "   'ROI/New/201890000_HE.png',\n",
       "   'ROI/New/201930000_HE.png',\n",
       "   'ROI/New/201950000_HE.png',\n",
       "   'ROI/New/201960000_HE.png',\n",
       "   'ROI/New/201970000_HE.png',\n",
       "   'ROI/New/201990000_HE.png',\n",
       "   'ROI/New/202010000_HE.png',\n",
       "   'ROI/New/202030000_HE.png',\n",
       "   'ROI/New/202040000_HE.png',\n",
       "   'ROI/New/202210000_HE.png',\n",
       "   'ROI/New/202220000_HE.png',\n",
       "   'ROI/New/202230000_HE.png',\n",
       "   'ROI/New/202240000_HE.png',\n",
       "   'ROI/New/202250000_HE.png',\n",
       "   'ROI/New/202260000_HE.png',\n",
       "   'ROI/New/202280000_HE.png',\n",
       "   'ROI/New/202290000_HE.png',\n",
       "   'ROI/New/2016110000_HE.png',\n",
       "   'ROI/New/2017120000_HE.png',\n",
       "   'ROI/New/2017150000_HE.png',\n",
       "   'ROI/New/2017170000_HE.png',\n",
       "   'ROI/New/2018120000_HE.png',\n",
       "   'ROI/New/2018130000_HE.png',\n",
       "   'ROI/New/2018150000_HE.png',\n",
       "   'ROI/New/2018160000_HE.png',\n",
       "   'ROI/New/2018170000_HE.png',\n",
       "   'ROI/New/2019100000_HE.png',\n",
       "   'ROI/New/2019120000_HE.png',\n",
       "   'ROI/New/2019130000_HE.png',\n",
       "   'ROI/New/2019140000_HE.png',\n",
       "   'ROI/New/2019150000_HE.png',\n",
       "   'ROI/New/2019160000_HE.png',\n",
       "   'ROI/New/2019170000_HE.png',\n",
       "   'ROI/New/2022100000_HE.png',\n",
       "   'ROI/New/2022120000_HE.png',\n",
       "   'ROI/New/2022130000_HE.png',\n",
       "   'ROI/New/2022170000_HE.png',\n",
       "   'ROI/New/2022180000_HE.png',\n",
       "   'ROI/New/2022200000_HE.png',\n",
       "   'ROI/New/2022210000_HE.png',\n",
       "   'ROI/New/2022220000_HE.png',\n",
       "   'ROI/New/2022230000_HE.png',\n",
       "   'ROI/New/2022240000_HE.png',\n",
       "   'ROI/New/1_HE.png',\n",
       "   'ROI/New/4_HE.png',\n",
       "   'ROI/New/5_HE.png',\n",
       "   'ROI/New/6_HE.png',\n",
       "   'ROI/New/9_HE.png',\n",
       "   'ROI/New/10_HE.png',\n",
       "   'ROI/New/11_HE.png',\n",
       "   'ROI/New/14_HE.png',\n",
       "   'ROI/New/16_HE.png',\n",
       "   'ROI/New/17_HE.png',\n",
       "   'ROI/New/22_HE.png',\n",
       "   'ROI/New/25_HE.png',\n",
       "   'ROI/New/26_HE.png',\n",
       "   'ROI/New/27_HE.png',\n",
       "   'ROI/New/28_HE.png',\n",
       "   'ROI/New/29_HE.png',\n",
       "   'ROI/New/33_HE.png',\n",
       "   'ROI/New/34_HE.png',\n",
       "   'ROI/New/36_HE.png',\n",
       "   'ROI/New/37_HE.png',\n",
       "   'ROI/New/39_HE.png',\n",
       "   'ROI/New/40_HE.png',\n",
       "   'ROI/New/41_HE.png',\n",
       "   'ROI/New/43_HE.png',\n",
       "   'ROI/New/46_HE.png',\n",
       "   'ROI/New/47_HE.png',\n",
       "   'ROI/New/48_HE.png',\n",
       "   'ROI/New/49_HE.png',\n",
       "   'ROI/New/50_HE.png',\n",
       "   'ROI/New/51_HE.png',\n",
       "   'ROI/New/52_HE.png',\n",
       "   'ROI/New/54_HE.png',\n",
       "   'ROI/New/55_HE.png',\n",
       "   'ROI/New/56_HE.png',\n",
       "   'ROI/New/58_HE.png',\n",
       "   'ROI/New/60_HE.png',\n",
       "   'ROI/New/62_HE.png',\n",
       "   'ROI/New/63_HE.png',\n",
       "   'ROI/New/64_HE.png',\n",
       "   'ROI/New/66_HE.png',\n",
       "   'ROI/New/69_HE.png',\n",
       "   'ROI/New/70_HE.png',\n",
       "   'ROI/New/71_HE.png',\n",
       "   'ROI/New/72_HE.png',\n",
       "   'ROI/New/73_HE.png',\n",
       "   'ROI/New/74_HE.png',\n",
       "   'ROI/New/76_HE.png',\n",
       "   'ROI/New/77_HE.png',\n",
       "   'ROI/New/78_HE.png',\n",
       "   'ROI/New/79_HE.png',\n",
       "   'ROI/New/82_HE.png',\n",
       "   'ROI/New/84_HE.png',\n",
       "   'ROI/New/87_HE.png',\n",
       "   'ROI/New/88_HE.png',\n",
       "   'ROI/New/92_HE.png',\n",
       "   'ROI/New/93_HE.png',\n",
       "   'ROI/New/95_HE.png',\n",
       "   'ROI/New/97_HE.png',\n",
       "   'ROI/New/100_HE.png',\n",
       "   'ROI/New/101_HE.png',\n",
       "   'ROI/New/102_HE.png',\n",
       "   'ROI/New/103_HE.png',\n",
       "   'ROI/New/104_HE.png',\n",
       "   'ROI/New/106_HE.png',\n",
       "   'ROI/New/107_HE.png',\n",
       "   'ROI/New/108_HE.png',\n",
       "   'ROI/New/109_HE.png',\n",
       "   'ROI/New/110_HE.png',\n",
       "   'ROI/New/111_HE.png',\n",
       "   'ROI/New/113_HE.png',\n",
       "   'ROI/New/114_HE.png',\n",
       "   'ROI/New/115_HE.png',\n",
       "   'ROI/New/116_HE.png',\n",
       "   'ROI/New/118_HE.png',\n",
       "   'ROI/New/120_HE.png',\n",
       "   'ROI/New/121_HE.png',\n",
       "   'ROI/New/122_HE.png',\n",
       "   'ROI/New/123_HE.png',\n",
       "   'ROI/New/125_HE.png',\n",
       "   'ROI/New/126_HE.png',\n",
       "   'ROI/New/129_HE.png',\n",
       "   'ROI/New/130_HE.png',\n",
       "   'ROI/New/132_HE.png',\n",
       "   'ROI/New/134_HE.png',\n",
       "   'ROI/New/136_HE.png',\n",
       "   'ROI/New/137_HE.png',\n",
       "   'ROI/New/138_HE.png',\n",
       "   'ROI/New/139_HE.png',\n",
       "   'ROI/New/141_HE.png',\n",
       "   'ROI/New/144_HE.png',\n",
       "   'ROI/New/145_HE.png',\n",
       "   'ROI/New/146_HE.png',\n",
       "   'ROI/New/147_HE.png',\n",
       "   'ROI/New/148_HE.png',\n",
       "   'ROI/New/150_HE.png',\n",
       "   'ROI/New/151_HE.png',\n",
       "   'ROI/New/156_HE.png',\n",
       "   'ROI/New/157_HE.png',\n",
       "   'ROI/New/158_HE.png',\n",
       "   'ROI/New/159_HE.png',\n",
       "   'ROI/New/160_HE.png',\n",
       "   'ROI/New/162_HE.png',\n",
       "   'ROI/New/163_HE.png',\n",
       "   'ROI/New/164_HE.png',\n",
       "   'ROI/New/166_HE.png',\n",
       "   'ROI/New/168_HE.png',\n",
       "   'ROI/New/169_HE.png',\n",
       "   'ROI/New/170_HE.png',\n",
       "   'ROI/New/171_HE.png',\n",
       "   'ROI/New/172_HE.png',\n",
       "   'ROI/New/173_HE.png',\n",
       "   'ROI/New/174_HE.png',\n",
       "   'ROI/New/175_HE.png',\n",
       "   'ROI/New/176_HE.png',\n",
       "   'ROI/New/177_HE.png',\n",
       "   'ROI/New/181_HE.png',\n",
       "   'ROI/New/182_HE.png',\n",
       "   'ROI/New/183_HE.png',\n",
       "   'ROI/New/184_HE.png',\n",
       "   'ROI/New/185_HE.png',\n",
       "   'ROI/New/186_HE.png',\n",
       "   'ROI/New/187_HE.png',\n",
       "   'ROI/New/188_HE.png',\n",
       "   'ROI/New/189_HE.png',\n",
       "   'ROI/New/192_HE.png',\n",
       "   'ROI/New/193_HE.png',\n",
       "   'ROI/New/194_HE.png',\n",
       "   'ROI/New/195_HE.png',\n",
       "   'ROI/New/196_HE.png',\n",
       "   'ROI/New/197_HE.png',\n",
       "   'ROI/New/198_HE.png',\n",
       "   'ROI/New/199_HE.png',\n",
       "   'ROI/New/200_HE.png',\n",
       "   'ROI/New/201_HE.png',\n",
       "   'ROI/New/202_HE.png',\n",
       "   'ROI/New/203_HE.png',\n",
       "   'ROI/New/204_HE.png',\n",
       "   'ROI/New/205_HE.png',\n",
       "   'ROI/New/206_HE.png',\n",
       "   'ROI/New/208_HE.png',\n",
       "   'ROI/New/209_HE.png',\n",
       "   'ROI/New/212_HE.png',\n",
       "   'ROI/New/214_HE.png',\n",
       "   'ROI/New/215_HE.png',\n",
       "   'ROI/New/217_HE.png',\n",
       "   'ROI/New/218_HE.png',\n",
       "   'ROI/New/220_HE.png',\n",
       "   'ROI/New/221_HE.png',\n",
       "   'ROI/New/222_HE.png',\n",
       "   'ROI/New/224_HE.png',\n",
       "   'ROI/New/227_HE.png',\n",
       "   'ROI/New/230_HE.png',\n",
       "   'ROI/New/233_HE.png',\n",
       "   'ROI/New/235_HE.png',\n",
       "   'ROI/New/236_HE.png',\n",
       "   'ROI/New/237_HE.png',\n",
       "   'ROI/New/238_HE.png',\n",
       "   'ROI/New/240_HE.png',\n",
       "   'ROI/New/244_HE.png',\n",
       "   'ROI/New/245_HE.png',\n",
       "   'ROI/New/247_HE.png',\n",
       "   'ROI/New/249_HE.png',\n",
       "   'ROI/New/251_HE.png',\n",
       "   'ROI/New/252_HE.png',\n",
       "   'ROI/New/253_HE.png',\n",
       "   'ROI/New/255_HE.png',\n",
       "   'ROI/New/256_HE.png',\n",
       "   'ROI/New/257_HE.png',\n",
       "   'ROI/New/260_HE.png',\n",
       "   'ROI/New/263_HE.png',\n",
       "   'ROI/New/264_HE.png',\n",
       "   'ROI/New/267_HE.png',\n",
       "   'ROI/New/270_HE.png',\n",
       "   'ROI/New/271_HE.png',\n",
       "   'ROI/New/272_HE.png',\n",
       "   'ROI/New/276_HE.png',\n",
       "   'ROI/New/277_HE.png',\n",
       "   'ROI/New/278_HE.png',\n",
       "   'ROI/New/280_HE.png',\n",
       "   'ROI/New/281_HE.png',\n",
       "   'ROI/New/283_HE.png',\n",
       "   'ROI/New/286_HE.png',\n",
       "   'ROI/New/287_HE.png',\n",
       "   'ROI/New/292_HE.png',\n",
       "   'ROI/New/293_HE.png',\n",
       "   'ROI/New/294_HE.png',\n",
       "   'ROI/New/295_HE.png',\n",
       "   'ROI/New/296_HE.png',\n",
       "   'ROI/New/298_HE.png',\n",
       "   'ROI/New/299_HE.png',\n",
       "   'ROI/New/301_HE.png',\n",
       "   'ROI/New/304_HE.png',\n",
       "   'ROI/New/305_HE.png',\n",
       "   'ROI/New/307_HE.png',\n",
       "   'ROI/New/308_HE.png',\n",
       "   'ROI/New/309_HE.png',\n",
       "   'ROI/New/310_HE.png',\n",
       "   'ROI/New/311_HE.png',\n",
       "   'ROI/New/312_HE.png',\n",
       "   'ROI/New/313_HE.png',\n",
       "   'ROI/New/316_HE.png',\n",
       "   'ROI/New/317_HE.png',\n",
       "   'ROI/New/318_HE.png',\n",
       "   'ROI/New/319_HE.png',\n",
       "   'ROI/New/320_HE.png',\n",
       "   'ROI/New/321_HE.png',\n",
       "   'ROI/New/322_HE.png',\n",
       "   'ROI/New/323_HE.png',\n",
       "   'ROI/New/325_HE.png',\n",
       "   'ROI/New/327_HE.png',\n",
       "   'ROI/New/328_HE.png',\n",
       "   'ROI/New/329_HE.png',\n",
       "   'ROI/New/332_HE.png',\n",
       "   'ROI/New/333_HE.png',\n",
       "   'ROI/New/336_HE.png',\n",
       "   'ROI/New/337_HE.png',\n",
       "   'ROI/New/340_HE.png',\n",
       "   'ROI/New/341_HE.png',\n",
       "   'ROI/New/343_HE.png',\n",
       "   'ROI/New/344_HE.png',\n",
       "   'ROI/New/345_HE.png',\n",
       "   'ROI/New/347_HE.png',\n",
       "   'ROI/New/348_HE.png',\n",
       "   'ROI/New/350_HE.png',\n",
       "   'ROI/New/351_HE.png',\n",
       "   'ROI/New/352_HE.png',\n",
       "   'ROI/New/355_HE.png',\n",
       "   'ROI/New/358_HE.png',\n",
       "   'ROI/New/363_HE.png',\n",
       "   'ROI/New/364_HE.png',\n",
       "   'ROI/New/365_HE.png',\n",
       "   'ROI/New/366_HE.png',\n",
       "   'ROI/New/368_HE.png',\n",
       "   'ROI/New/372_HE.png',\n",
       "   'ROI/New/375_HE.png',\n",
       "   'ROI/New/376_HE.png',\n",
       "   'ROI/New/377_HE.png',\n",
       "   'ROI/New/380_HE.png',\n",
       "   'ROI/New/381_HE.png',\n",
       "   'ROI/New/382_HE.png',\n",
       "   'ROI/New/383_HE.png',\n",
       "   'ROI/New/384_HE.png',\n",
       "   'ROI/New/385_HE.png',\n",
       "   'ROI/New/386_HE.png',\n",
       "   'ROI/New/388_HE.png',\n",
       "   'ROI/New/390_HE.png',\n",
       "   'ROI/New/391_HE.png',\n",
       "   'ROI/New/392_HE.png',\n",
       "   'ROI/New/394_HE.png',\n",
       "   'ROI/New/395_HE.png',\n",
       "   'ROI/New/396_HE.png',\n",
       "   'ROI/New/397_HE.png',\n",
       "   'ROI/New/399_HE.png',\n",
       "   'ROI/New/401_HE.png',\n",
       "   'ROI/New/402_HE.png',\n",
       "   'ROI/New/403_HE.png',\n",
       "   'ROI/New/404_HE.png',\n",
       "   'ROI/New/406_HE.png',\n",
       "   'ROI/New/407_HE.png',\n",
       "   'ROI/New/410_HE.png',\n",
       "   'ROI/New/411_HE.png',\n",
       "   'ROI/New/413_HE.png',\n",
       "   'ROI/New/414_HE.png',\n",
       "   'ROI/New/419_HE.png',\n",
       "   'ROI/New/420_HE.png',\n",
       "   'ROI/New/421_HE.png',\n",
       "   'ROI/New/423_HE.png',\n",
       "   'ROI/New/425_HE.png',\n",
       "   'ROI/New/426_HE.png',\n",
       "   'ROI/New/427_HE.png',\n",
       "   'ROI/New/430_HE.png',\n",
       "   'ROI/New/431_HE.png',\n",
       "   'ROI/New/433_HE.png',\n",
       "   'ROI/New/435_HE.png',\n",
       "   'ROI/New/436_HE.png',\n",
       "   'ROI/New/437_HE.png',\n",
       "   'ROI/New/439_HE.png',\n",
       "   'ROI/New/440_HE.png',\n",
       "   'ROI/New/441_HE.png',\n",
       "   'ROI/New/443_HE.png',\n",
       "   'ROI/New/444_HE.png',\n",
       "   'ROI/New/445_HE.png',\n",
       "   'ROI/New/446_HE.png',\n",
       "   'ROI/New/448_HE.png',\n",
       "   'ROI/New/449_HE.png',\n",
       "   'ROI/New/451_HE.png',\n",
       "   'ROI/New/452_HE.png',\n",
       "   'ROI/New/453_HE.png',\n",
       "   'ROI/New/454_HE.png',\n",
       "   'ROI/New/455_HE.png',\n",
       "   'ROI/New/457_HE.png',\n",
       "   'ROI/New/458_HE.png',\n",
       "   'ROI/New/459_HE.png',\n",
       "   'ROI/New/462_HE.png',\n",
       "   'ROI/New/463_HE.png',\n",
       "   'ROI/New/464_HE.png',\n",
       "   'ROI/New/465_HE.png',\n",
       "   'ROI/New/466_HE.png',\n",
       "   'ROI/New/469_HE.png',\n",
       "   'ROI/New/472_HE.png',\n",
       "   'ROI/New/474_HE.png',\n",
       "   'ROI/New/476_HE.png',\n",
       "   'ROI/New/477_HE.png',\n",
       "   'ROI/New/478_HE.png',\n",
       "   'ROI/New/479_HE.png',\n",
       "   'ROI/New/482_HE.png',\n",
       "   'ROI/New/483_HE.png',\n",
       "   'ROI/New/484_HE.png',\n",
       "   'ROI/New/485_HE.png',\n",
       "   'ROI/New/486_HE.png',\n",
       "   'ROI/New/487_HE.png',\n",
       "   'ROI/New/489_HE.png',\n",
       "   'ROI/New/491_HE.png',\n",
       "   'ROI/New/492_HE.png',\n",
       "   'ROI/New/496_HE.png',\n",
       "   'ROI/New/497_HE.png',\n",
       "   'ROI/New/499_HE.png',\n",
       "   'ROI/New/500_HE.png',\n",
       "   'ROI/New/502_HE.png',\n",
       "   'ROI/New/503_HE.png',\n",
       "   'ROI/New/505_HE.png',\n",
       "   'ROI/New/506_HE.png',\n",
       "   'ROI/New/507_HE.png',\n",
       "   'ROI/New/509_HE.png',\n",
       "   'ROI/New/510_HE.png',\n",
       "   'ROI/New/512_HE.png',\n",
       "   'ROI/New/518_HE.png',\n",
       "   'ROI/New/519_HE.png',\n",
       "   'ROI/New/520_HE.png',\n",
       "   'ROI/New/521_HE.png',\n",
       "   'ROI/New/522_HE.png',\n",
       "   'ROI/New/524_HE.png',\n",
       "   'ROI/New/525_HE.png',\n",
       "   'ROI/New/526_HE.png',\n",
       "   'ROI/New/529_HE.png',\n",
       "   'ROI/New/530_HE.png',\n",
       "   'ROI/New/532_HE.png',\n",
       "   'ROI/New/534_HE.png',\n",
       "   'ROI/New/535_HE.png',\n",
       "   'ROI/New/537_HE.png',\n",
       "   'ROI/New/539_HE.png',\n",
       "   'ROI/New/540_HE.png',\n",
       "   'ROI/New/541_HE.png',\n",
       "   'ROI/New/542_HE.png'],\n",
       "  ['ROI/New/1013_HE.png',\n",
       "   'ROI/New/1075_HE.png',\n",
       "   'ROI/New/1043_HE.png',\n",
       "   'ROI/New/1161_HE.png',\n",
       "   'ROI/New/261_HE.png',\n",
       "   'ROI/New/398_HE.png',\n",
       "   'ROI/New/61_HE.png',\n",
       "   'ROI/New/390000_HE.png',\n",
       "   'ROI/New/9500000_HE.png',\n",
       "   'ROI/New/2022110000_HE.png',\n",
       "   'ROI/New/950000_HE.png',\n",
       "   'ROI/New/2022190000_HE.png',\n",
       "   'ROI/New/1510000_HE.png',\n",
       "   'ROI/New/450000_HE.png',\n",
       "   'ROI/New/100000_HE.png',\n",
       "   'ROI/New/880000_HE.png',\n",
       "   'ROI/New/1080000_HE.png',\n",
       "   'ROI/New/1140000_HE.png',\n",
       "   'ROI/New/1150000_HE.png',\n",
       "   'ROI/New/1860000_HE.png',\n",
       "   'ROI/New/1870000_HE.png',\n",
       "   'ROI/New/2017100000_HE.png',\n",
       "   'ROI/New/545_HE.png',\n",
       "   'ROI/New/547_HE.png',\n",
       "   'ROI/New/561_HE.png',\n",
       "   'ROI/New/571_HE.png',\n",
       "   'ROI/New/579_HE.png',\n",
       "   'ROI/New/580_HE.png',\n",
       "   'ROI/New/594_HE.png',\n",
       "   'ROI/New/597_HE.png',\n",
       "   'ROI/New/600_HE.png',\n",
       "   'ROI/New/602_HE.png',\n",
       "   'ROI/New/605_HE.png',\n",
       "   'ROI/New/614_HE.png',\n",
       "   'ROI/New/625_HE.png',\n",
       "   'ROI/New/630_HE.png',\n",
       "   'ROI/New/639_HE.png',\n",
       "   'ROI/New/645_HE.png',\n",
       "   'ROI/New/647_HE.png',\n",
       "   'ROI/New/659_HE.png',\n",
       "   'ROI/New/662_HE.png',\n",
       "   'ROI/New/669_HE.png',\n",
       "   'ROI/New/680_HE.png',\n",
       "   'ROI/New/700_HE.png',\n",
       "   'ROI/New/707_HE.png',\n",
       "   'ROI/New/716_HE.png',\n",
       "   'ROI/New/725_HE.png',\n",
       "   'ROI/New/733_HE.png',\n",
       "   'ROI/New/741_HE.png',\n",
       "   'ROI/New/758_HE.png',\n",
       "   'ROI/New/759_HE.png',\n",
       "   'ROI/New/763_HE.png',\n",
       "   'ROI/New/772_HE.png',\n",
       "   'ROI/New/776_HE.png',\n",
       "   'ROI/New/781_HE.png',\n",
       "   'ROI/New/786_HE.png',\n",
       "   'ROI/New/799_HE.png',\n",
       "   'ROI/New/808_HE.png',\n",
       "   'ROI/New/809_HE.png',\n",
       "   'ROI/New/812_HE.png',\n",
       "   'ROI/New/813_HE.png',\n",
       "   'ROI/New/827_HE.png',\n",
       "   'ROI/New/833_HE.png',\n",
       "   'ROI/New/837_HE.png',\n",
       "   'ROI/New/841_HE.png',\n",
       "   'ROI/New/848_HE.png',\n",
       "   'ROI/New/857_HE.png',\n",
       "   'ROI/New/862_HE.png',\n",
       "   'ROI/New/864_HE.png',\n",
       "   'ROI/New/879_HE.png',\n",
       "   'ROI/New/881_HE.png',\n",
       "   'ROI/New/883_HE.png',\n",
       "   'ROI/New/884_HE.png',\n",
       "   'ROI/New/885_HE.png',\n",
       "   'ROI/New/886_HE.png',\n",
       "   'ROI/New/887_HE.png',\n",
       "   'ROI/New/899_HE.png',\n",
       "   'ROI/New/903_HE.png',\n",
       "   'ROI/New/905_HE.png',\n",
       "   'ROI/New/906_HE.png',\n",
       "   'ROI/New/909_HE.png',\n",
       "   'ROI/New/919_HE.png',\n",
       "   'ROI/New/922_HE.png',\n",
       "   'ROI/New/931_HE.png',\n",
       "   'ROI/New/934_HE.png',\n",
       "   'ROI/New/940_HE.png',\n",
       "   'ROI/New/948_HE.png',\n",
       "   'ROI/New/949_HE.png',\n",
       "   'ROI/New/954_HE.png',\n",
       "   'ROI/New/961_HE.png',\n",
       "   'ROI/New/964_HE.png',\n",
       "   'ROI/New/968_HE.png',\n",
       "   'ROI/New/971_HE.png',\n",
       "   'ROI/New/979_HE.png',\n",
       "   'ROI/New/985_HE.png',\n",
       "   'ROI/New/989_HE.png',\n",
       "   'ROI/New/999_HE.png',\n",
       "   'ROI/New/1007_HE.png',\n",
       "   'ROI/New/1008_HE.png',\n",
       "   'ROI/New/1012_HE.png',\n",
       "   'ROI/New/1014_HE.png',\n",
       "   'ROI/New/1015_HE.png',\n",
       "   'ROI/New/1026_HE.png',\n",
       "   'ROI/New/1028_HE.png',\n",
       "   'ROI/New/1037_HE.png',\n",
       "   'ROI/New/1049_HE.png',\n",
       "   'ROI/New/1058_HE.png',\n",
       "   'ROI/New/1063_HE.png',\n",
       "   'ROI/New/1072_HE.png',\n",
       "   'ROI/New/1076_HE.png',\n",
       "   'ROI/New/1078_HE.png',\n",
       "   'ROI/New/1088_HE.png',\n",
       "   'ROI/New/1096_HE.png',\n",
       "   'ROI/New/1097_HE.png',\n",
       "   'ROI/New/1099_HE.png',\n",
       "   'ROI/New/1103_HE.png',\n",
       "   'ROI/New/1107_HE.png',\n",
       "   'ROI/New/1117_HE.png',\n",
       "   'ROI/New/1123_HE.png',\n",
       "   'ROI/New/1129_HE.png',\n",
       "   'ROI/New/1144_HE.png',\n",
       "   'ROI/New/1152_HE.png',\n",
       "   'ROI/New/1159_HE.png',\n",
       "   'ROI/New/1169_HE.png',\n",
       "   'ROI/New/1172_HE.png',\n",
       "   'ROI/New/1174_HE.png',\n",
       "   'ROI/New/1175_HE.png',\n",
       "   'ROI/New/1180_HE.png',\n",
       "   'ROI/New/1190_HE.png',\n",
       "   'ROI/New/1191_HE.png',\n",
       "   'ROI/New/280000_HE.png',\n",
       "   'ROI/New/290000_HE.png',\n",
       "   'ROI/New/1670000_HE.png',\n",
       "   'ROI/New/2110000_HE.png',\n",
       "   'ROI/New/2190000_HE.png',\n",
       "   'ROI/New/2300000_HE.png',\n",
       "   'ROI/New/201680000_HE.png',\n",
       "   'ROI/New/201730000_HE.png',\n",
       "   'ROI/New/201740000_HE.png',\n",
       "   'ROI/New/201870000_HE.png',\n",
       "   'ROI/New/201880000_HE.png',\n",
       "   'ROI/New/201910000_HE.png',\n",
       "   'ROI/New/201940000_HE.png',\n",
       "   'ROI/New/202270000_HE.png',\n",
       "   'ROI/New/2017130000_HE.png',\n",
       "   'ROI/New/2017140000_HE.png',\n",
       "   'ROI/New/2018100000_HE.png',\n",
       "   'ROI/New/2018140000_HE.png',\n",
       "   'ROI/New/2019110000_HE.png',\n",
       "   'ROI/New/2019190000_HE.png',\n",
       "   'ROI/New/2022150000_HE.png',\n",
       "   'ROI/New/2_HE.png',\n",
       "   'ROI/New/3_HE.png',\n",
       "   'ROI/New/12_HE.png',\n",
       "   'ROI/New/13_HE.png',\n",
       "   'ROI/New/15_HE.png',\n",
       "   'ROI/New/18_HE.png',\n",
       "   'ROI/New/20_HE.png',\n",
       "   'ROI/New/21_HE.png',\n",
       "   'ROI/New/23_HE.png',\n",
       "   'ROI/New/45_HE.png',\n",
       "   'ROI/New/57_HE.png',\n",
       "   'ROI/New/59_HE.png',\n",
       "   'ROI/New/65_HE.png',\n",
       "   'ROI/New/68_HE.png',\n",
       "   'ROI/New/81_HE.png',\n",
       "   'ROI/New/85_HE.png',\n",
       "   'ROI/New/86_HE.png',\n",
       "   'ROI/New/90_HE.png',\n",
       "   'ROI/New/91_HE.png',\n",
       "   'ROI/New/94_HE.png',\n",
       "   'ROI/New/96_HE.png',\n",
       "   'ROI/New/99_HE.png',\n",
       "   'ROI/New/105_HE.png',\n",
       "   'ROI/New/112_HE.png',\n",
       "   'ROI/New/127_HE.png',\n",
       "   'ROI/New/133_HE.png',\n",
       "   'ROI/New/140_HE.png',\n",
       "   'ROI/New/152_HE.png',\n",
       "   'ROI/New/153_HE.png',\n",
       "   'ROI/New/155_HE.png',\n",
       "   'ROI/New/161_HE.png',\n",
       "   'ROI/New/167_HE.png',\n",
       "   'ROI/New/178_HE.png',\n",
       "   'ROI/New/180_HE.png',\n",
       "   'ROI/New/190_HE.png',\n",
       "   'ROI/New/207_HE.png',\n",
       "   'ROI/New/213_HE.png',\n",
       "   'ROI/New/216_HE.png',\n",
       "   'ROI/New/229_HE.png',\n",
       "   'ROI/New/250_HE.png',\n",
       "   'ROI/New/279_HE.png',\n",
       "   'ROI/New/289_HE.png',\n",
       "   'ROI/New/290_HE.png',\n",
       "   'ROI/New/300_HE.png',\n",
       "   'ROI/New/302_HE.png',\n",
       "   'ROI/New/314_HE.png',\n",
       "   'ROI/New/315_HE.png',\n",
       "   'ROI/New/324_HE.png',\n",
       "   'ROI/New/342_HE.png',\n",
       "   'ROI/New/346_HE.png',\n",
       "   'ROI/New/356_HE.png',\n",
       "   'ROI/New/360_HE.png',\n",
       "   'ROI/New/361_HE.png',\n",
       "   'ROI/New/371_HE.png',\n",
       "   'ROI/New/374_HE.png',\n",
       "   'ROI/New/379_HE.png',\n",
       "   'ROI/New/387_HE.png',\n",
       "   'ROI/New/400_HE.png',\n",
       "   'ROI/New/409_HE.png',\n",
       "   'ROI/New/412_HE.png',\n",
       "   'ROI/New/415_HE.png',\n",
       "   'ROI/New/417_HE.png',\n",
       "   'ROI/New/418_HE.png',\n",
       "   'ROI/New/424_HE.png',\n",
       "   'ROI/New/428_HE.png',\n",
       "   'ROI/New/429_HE.png',\n",
       "   'ROI/New/432_HE.png',\n",
       "   'ROI/New/447_HE.png',\n",
       "   'ROI/New/450_HE.png',\n",
       "   'ROI/New/460_HE.png',\n",
       "   'ROI/New/467_HE.png',\n",
       "   'ROI/New/470_HE.png',\n",
       "   'ROI/New/475_HE.png',\n",
       "   'ROI/New/480_HE.png',\n",
       "   'ROI/New/481_HE.png',\n",
       "   'ROI/New/488_HE.png',\n",
       "   'ROI/New/490_HE.png',\n",
       "   'ROI/New/493_HE.png',\n",
       "   'ROI/New/494_HE.png',\n",
       "   'ROI/New/495_HE.png',\n",
       "   'ROI/New/501_HE.png',\n",
       "   'ROI/New/517_HE.png',\n",
       "   'ROI/New/536_HE.png',\n",
       "   'ROI/New/538_HE.png']],\n",
       " [['ROI/New/248_HE.png',\n",
       "   'ROI/New/357_HE.png',\n",
       "   'ROI/New/89_HE.png',\n",
       "   'ROI/New/1059_HE.png',\n",
       "   'ROI/New/1013_HE.png',\n",
       "   'ROI/New/269_HE.png',\n",
       "   'ROI/New/1075_HE.png',\n",
       "   'ROI/New/1043_HE.png',\n",
       "   'ROI/New/191_HE.png',\n",
       "   'ROI/New/1138_HE.png',\n",
       "   'ROI/New/1161_HE.png',\n",
       "   'ROI/New/840_HE.png',\n",
       "   'ROI/New/845_HE.png',\n",
       "   'ROI/New/543_HE.png',\n",
       "   'ROI/New/650_HE.png',\n",
       "   'ROI/New/228_HE.png',\n",
       "   'ROI/New/225_HE.png',\n",
       "   'ROI/New/246_HE.png',\n",
       "   'ROI/New/261_HE.png',\n",
       "   'ROI/New/268_HE.png',\n",
       "   'ROI/New/275_HE.png',\n",
       "   'ROI/New/288_HE.png',\n",
       "   'ROI/New/306_HE.png',\n",
       "   'ROI/New/297_HE.png',\n",
       "   'ROI/New/369_HE.png',\n",
       "   'ROI/New/373_HE.png',\n",
       "   'ROI/New/362_HE.png',\n",
       "   'ROI/New/378_HE.png',\n",
       "   'ROI/New/142_HE.png',\n",
       "   'ROI/New/389_HE.png',\n",
       "   'ROI/New/398_HE.png',\n",
       "   'ROI/New/35_HE.png',\n",
       "   'ROI/New/31_HE.png',\n",
       "   'ROI/New/44_HE.png',\n",
       "   'ROI/New/67_HE.png',\n",
       "   'ROI/New/61_HE.png',\n",
       "   'ROI/New/80_HE.png',\n",
       "   'ROI/New/143_HE.png',\n",
       "   'ROI/New/124_HE.png',\n",
       "   'ROI/New/1210000_HE.png',\n",
       "   'ROI/New/430000_HE.png',\n",
       "   'ROI/New/730000_HE.png',\n",
       "   'ROI/New/2270000_HE.png',\n",
       "   'ROI/New/620000_HE.png',\n",
       "   'ROI/New/2290000_HE.png',\n",
       "   'ROI/New/2140000_HE.png',\n",
       "   'ROI/New/6200000_HE.png',\n",
       "   'ROI/New/360000_HE.png',\n",
       "   'ROI/New/340000_HE.png',\n",
       "   'ROI/New/1040000_HE.png',\n",
       "   'ROI/New/330000_HE.png',\n",
       "   'ROI/New/1320000_HE.png',\n",
       "   'ROI/New/660000_HE.png',\n",
       "   'ROI/New/8100000_HE.png',\n",
       "   'ROI/New/1590000_HE.png',\n",
       "   'ROI/New/1050000_HE.png',\n",
       "   'ROI/New/820000_HE.png',\n",
       "   'ROI/New/9700000_HE.png',\n",
       "   'ROI/New/2022160000_HE.png',\n",
       "   'ROI/New/2230000_HE.png',\n",
       "   'ROI/New/490000_HE.png',\n",
       "   'ROI/New/15200000_HE.png',\n",
       "   'ROI/New/1470000_HE.png',\n",
       "   'ROI/New/390000_HE.png',\n",
       "   'ROI/New/9500000_HE.png',\n",
       "   'ROI/New/1270000_HE.png',\n",
       "   'ROI/New/2022110000_HE.png',\n",
       "   'ROI/New/650000_HE.png',\n",
       "   'ROI/New/2220000_HE.png',\n",
       "   'ROI/New/370000_HE.png',\n",
       "   'ROI/New/970000_HE.png',\n",
       "   'ROI/New/950000_HE.png',\n",
       "   'ROI/New/460000_HE.png',\n",
       "   'ROI/New/310000_HE.png',\n",
       "   'ROI/New/530000_HE.png',\n",
       "   'ROI/New/1940000_HE.png',\n",
       "   'ROI/New/2022140000_HE.png',\n",
       "   'ROI/New/2022190000_HE.png',\n",
       "   'ROI/New/1290000_HE.png',\n",
       "   'ROI/New/640000_HE.png',\n",
       "   'ROI/New/2016120000_HE.png',\n",
       "   'ROI/New/201620000_HE.png',\n",
       "   'ROI/New/1510000_HE.png',\n",
       "   'ROI/New/1100000_HE.png',\n",
       "   'ROI/New/450000_HE.png',\n",
       "   'ROI/New/1060000_HE.png',\n",
       "   'ROI/New/2019180000_HE.png',\n",
       "   'ROI/New/1020000_HE.png',\n",
       "   'ROI/New/1570000_HE.png',\n",
       "   'ROI/New/1090000_HE.png',\n",
       "   'ROI/New/50000_HE.png',\n",
       "   'ROI/New/100000_HE.png',\n",
       "   'ROI/New/110000_HE.png',\n",
       "   'ROI/New/420000_HE.png',\n",
       "   'ROI/New/840000_HE.png',\n",
       "   'ROI/New/880000_HE.png',\n",
       "   'ROI/New/1080000_HE.png',\n",
       "   'ROI/New/1650000_HE.png',\n",
       "   'ROI/New/670000_HE.png',\n",
       "   'ROI/New/7900000_HE.png',\n",
       "   'ROI/New/1140000_HE.png',\n",
       "   'ROI/New/1150000_HE.png',\n",
       "   'ROI/New/1460000_HE.png',\n",
       "   'ROI/New/14700000_HE.png',\n",
       "   'ROI/New/1860000_HE.png',\n",
       "   'ROI/New/1870000_HE.png',\n",
       "   'ROI/New/16000000_HE.png',\n",
       "   'ROI/New/470000_HE.png',\n",
       "   'ROI/New/630000_HE.png',\n",
       "   'ROI/New/740000_HE.png',\n",
       "   'ROI/New/8400000_HE.png',\n",
       "   'ROI/New/2017100000_HE.png',\n",
       "   'ROI/New/545_HE.png',\n",
       "   'ROI/New/546_HE.png',\n",
       "   'ROI/New/547_HE.png',\n",
       "   'ROI/New/548_HE.png',\n",
       "   'ROI/New/551_HE.png',\n",
       "   'ROI/New/553_HE.png',\n",
       "   'ROI/New/554_HE.png',\n",
       "   'ROI/New/555_HE.png',\n",
       "   'ROI/New/558_HE.png',\n",
       "   'ROI/New/559_HE.png',\n",
       "   'ROI/New/560_HE.png',\n",
       "   'ROI/New/561_HE.png',\n",
       "   'ROI/New/562_HE.png',\n",
       "   'ROI/New/563_HE.png',\n",
       "   'ROI/New/564_HE.png',\n",
       "   'ROI/New/566_HE.png',\n",
       "   'ROI/New/567_HE.png',\n",
       "   'ROI/New/568_HE.png',\n",
       "   'ROI/New/570_HE.png',\n",
       "   'ROI/New/571_HE.png',\n",
       "   'ROI/New/572_HE.png',\n",
       "   'ROI/New/574_HE.png',\n",
       "   'ROI/New/575_HE.png',\n",
       "   'ROI/New/576_HE.png',\n",
       "   'ROI/New/577_HE.png',\n",
       "   'ROI/New/579_HE.png',\n",
       "   'ROI/New/580_HE.png',\n",
       "   'ROI/New/581_HE.png',\n",
       "   'ROI/New/582_HE.png',\n",
       "   'ROI/New/583_HE.png',\n",
       "   'ROI/New/584_HE.png',\n",
       "   'ROI/New/586_HE.png',\n",
       "   'ROI/New/589_HE.png',\n",
       "   'ROI/New/591_HE.png',\n",
       "   'ROI/New/592_HE.png',\n",
       "   'ROI/New/593_HE.png',\n",
       "   'ROI/New/594_HE.png',\n",
       "   'ROI/New/597_HE.png',\n",
       "   'ROI/New/598_HE.png',\n",
       "   'ROI/New/600_HE.png',\n",
       "   'ROI/New/601_HE.png',\n",
       "   'ROI/New/602_HE.png',\n",
       "   'ROI/New/603_HE.png',\n",
       "   'ROI/New/604_HE.png',\n",
       "   'ROI/New/605_HE.png',\n",
       "   'ROI/New/606_HE.png',\n",
       "   'ROI/New/607_HE.png',\n",
       "   'ROI/New/608_HE.png',\n",
       "   'ROI/New/609_HE.png',\n",
       "   'ROI/New/610_HE.png',\n",
       "   'ROI/New/611_HE.png',\n",
       "   'ROI/New/612_HE.png',\n",
       "   'ROI/New/613_HE.png',\n",
       "   'ROI/New/614_HE.png',\n",
       "   'ROI/New/617_HE.png',\n",
       "   'ROI/New/618_HE.png',\n",
       "   'ROI/New/621_HE.png',\n",
       "   'ROI/New/623_HE.png',\n",
       "   'ROI/New/625_HE.png',\n",
       "   'ROI/New/627_HE.png',\n",
       "   'ROI/New/629_HE.png',\n",
       "   'ROI/New/630_HE.png',\n",
       "   'ROI/New/633_HE.png',\n",
       "   'ROI/New/636_HE.png',\n",
       "   'ROI/New/637_HE.png',\n",
       "   'ROI/New/638_HE.png',\n",
       "   'ROI/New/639_HE.png',\n",
       "   'ROI/New/640_HE.png',\n",
       "   'ROI/New/641_HE.png',\n",
       "   'ROI/New/643_HE.png',\n",
       "   'ROI/New/645_HE.png',\n",
       "   'ROI/New/646_HE.png',\n",
       "   'ROI/New/647_HE.png',\n",
       "   'ROI/New/648_HE.png',\n",
       "   'ROI/New/649_HE.png',\n",
       "   'ROI/New/651_HE.png',\n",
       "   'ROI/New/652_HE.png',\n",
       "   'ROI/New/654_HE.png',\n",
       "   'ROI/New/656_HE.png',\n",
       "   'ROI/New/658_HE.png',\n",
       "   'ROI/New/659_HE.png',\n",
       "   'ROI/New/660_HE.png',\n",
       "   'ROI/New/661_HE.png',\n",
       "   'ROI/New/662_HE.png',\n",
       "   'ROI/New/666_HE.png',\n",
       "   'ROI/New/667_HE.png',\n",
       "   'ROI/New/669_HE.png',\n",
       "   'ROI/New/670_HE.png',\n",
       "   'ROI/New/671_HE.png',\n",
       "   'ROI/New/675_HE.png',\n",
       "   'ROI/New/676_HE.png',\n",
       "   'ROI/New/680_HE.png',\n",
       "   'ROI/New/682_HE.png',\n",
       "   'ROI/New/684_HE.png',\n",
       "   'ROI/New/685_HE.png',\n",
       "   'ROI/New/686_HE.png',\n",
       "   'ROI/New/688_HE.png',\n",
       "   'ROI/New/690_HE.png',\n",
       "   'ROI/New/692_HE.png',\n",
       "   'ROI/New/693_HE.png',\n",
       "   'ROI/New/694_HE.png',\n",
       "   'ROI/New/699_HE.png',\n",
       "   'ROI/New/700_HE.png',\n",
       "   'ROI/New/701_HE.png',\n",
       "   'ROI/New/702_HE.png',\n",
       "   'ROI/New/704_HE.png',\n",
       "   'ROI/New/705_HE.png',\n",
       "   'ROI/New/707_HE.png',\n",
       "   'ROI/New/710_HE.png',\n",
       "   'ROI/New/712_HE.png',\n",
       "   'ROI/New/714_HE.png',\n",
       "   'ROI/New/715_HE.png',\n",
       "   'ROI/New/716_HE.png',\n",
       "   'ROI/New/717_HE.png',\n",
       "   'ROI/New/718_HE.png',\n",
       "   'ROI/New/720_HE.png',\n",
       "   'ROI/New/722_HE.png',\n",
       "   'ROI/New/723_HE.png',\n",
       "   'ROI/New/724_HE.png',\n",
       "   'ROI/New/725_HE.png',\n",
       "   'ROI/New/728_HE.png',\n",
       "   'ROI/New/729_HE.png',\n",
       "   'ROI/New/730_HE.png',\n",
       "   'ROI/New/731_HE.png',\n",
       "   'ROI/New/733_HE.png',\n",
       "   'ROI/New/734_HE.png',\n",
       "   'ROI/New/735_HE.png',\n",
       "   'ROI/New/737_HE.png',\n",
       "   'ROI/New/738_HE.png',\n",
       "   'ROI/New/741_HE.png',\n",
       "   'ROI/New/743_HE.png',\n",
       "   'ROI/New/745_HE.png',\n",
       "   'ROI/New/747_HE.png',\n",
       "   'ROI/New/749_HE.png',\n",
       "   'ROI/New/750_HE.png',\n",
       "   'ROI/New/753_HE.png',\n",
       "   'ROI/New/755_HE.png',\n",
       "   'ROI/New/756_HE.png',\n",
       "   'ROI/New/757_HE.png',\n",
       "   'ROI/New/758_HE.png',\n",
       "   'ROI/New/759_HE.png',\n",
       "   'ROI/New/760_HE.png',\n",
       "   'ROI/New/762_HE.png',\n",
       "   'ROI/New/763_HE.png',\n",
       "   'ROI/New/764_HE.png',\n",
       "   'ROI/New/767_HE.png',\n",
       "   'ROI/New/768_HE.png',\n",
       "   'ROI/New/769_HE.png',\n",
       "   'ROI/New/770_HE.png',\n",
       "   'ROI/New/771_HE.png',\n",
       "   'ROI/New/772_HE.png',\n",
       "   'ROI/New/776_HE.png',\n",
       "   'ROI/New/777_HE.png',\n",
       "   'ROI/New/778_HE.png',\n",
       "   'ROI/New/779_HE.png',\n",
       "   'ROI/New/781_HE.png',\n",
       "   'ROI/New/782_HE.png',\n",
       "   'ROI/New/783_HE.png',\n",
       "   'ROI/New/785_HE.png',\n",
       "   'ROI/New/786_HE.png',\n",
       "   'ROI/New/789_HE.png',\n",
       "   'ROI/New/792_HE.png',\n",
       "   'ROI/New/793_HE.png',\n",
       "   'ROI/New/794_HE.png',\n",
       "   'ROI/New/795_HE.png',\n",
       "   'ROI/New/796_HE.png',\n",
       "   'ROI/New/798_HE.png',\n",
       "   'ROI/New/799_HE.png',\n",
       "   'ROI/New/801_HE.png',\n",
       "   'ROI/New/808_HE.png',\n",
       "   'ROI/New/809_HE.png',\n",
       "   'ROI/New/811_HE.png',\n",
       "   'ROI/New/812_HE.png',\n",
       "   'ROI/New/813_HE.png',\n",
       "   'ROI/New/814_HE.png',\n",
       "   'ROI/New/817_HE.png',\n",
       "   'ROI/New/818_HE.png',\n",
       "   'ROI/New/819_HE.png',\n",
       "   'ROI/New/820_HE.png',\n",
       "   'ROI/New/822_HE.png',\n",
       "   'ROI/New/823_HE.png',\n",
       "   'ROI/New/824_HE.png',\n",
       "   'ROI/New/825_HE.png',\n",
       "   'ROI/New/827_HE.png',\n",
       "   'ROI/New/828_HE.png',\n",
       "   'ROI/New/829_HE.png',\n",
       "   'ROI/New/830_HE.png',\n",
       "   'ROI/New/833_HE.png',\n",
       "   'ROI/New/837_HE.png',\n",
       "   'ROI/New/838_HE.png',\n",
       "   'ROI/New/841_HE.png',\n",
       "   'ROI/New/842_HE.png',\n",
       "   'ROI/New/846_HE.png',\n",
       "   'ROI/New/847_HE.png',\n",
       "   'ROI/New/848_HE.png',\n",
       "   'ROI/New/849_HE.png',\n",
       "   'ROI/New/851_HE.png',\n",
       "   'ROI/New/854_HE.png',\n",
       "   'ROI/New/855_HE.png',\n",
       "   'ROI/New/856_HE.png',\n",
       "   'ROI/New/857_HE.png',\n",
       "   'ROI/New/858_HE.png',\n",
       "   'ROI/New/859_HE.png',\n",
       "   'ROI/New/860_HE.png',\n",
       "   'ROI/New/862_HE.png',\n",
       "   'ROI/New/864_HE.png',\n",
       "   'ROI/New/865_HE.png',\n",
       "   'ROI/New/866_HE.png',\n",
       "   'ROI/New/868_HE.png',\n",
       "   'ROI/New/869_HE.png',\n",
       "   'ROI/New/870_HE.png',\n",
       "   'ROI/New/872_HE.png',\n",
       "   'ROI/New/873_HE.png',\n",
       "   'ROI/New/874_HE.png',\n",
       "   'ROI/New/875_HE.png',\n",
       "   'ROI/New/878_HE.png',\n",
       "   'ROI/New/879_HE.png',\n",
       "   'ROI/New/881_HE.png',\n",
       "   'ROI/New/882_HE.png',\n",
       "   'ROI/New/883_HE.png',\n",
       "   'ROI/New/884_HE.png',\n",
       "   'ROI/New/885_HE.png',\n",
       "   'ROI/New/886_HE.png',\n",
       "   'ROI/New/887_HE.png',\n",
       "   'ROI/New/888_HE.png',\n",
       "   'ROI/New/891_HE.png',\n",
       "   'ROI/New/892_HE.png',\n",
       "   'ROI/New/896_HE.png',\n",
       "   'ROI/New/897_HE.png',\n",
       "   'ROI/New/899_HE.png',\n",
       "   'ROI/New/900_HE.png',\n",
       "   'ROI/New/903_HE.png',\n",
       "   'ROI/New/904_HE.png',\n",
       "   'ROI/New/905_HE.png',\n",
       "   'ROI/New/906_HE.png',\n",
       "   'ROI/New/909_HE.png',\n",
       "   'ROI/New/910_HE.png',\n",
       "   'ROI/New/911_HE.png',\n",
       "   'ROI/New/912_HE.png',\n",
       "   'ROI/New/914_HE.png',\n",
       "   'ROI/New/918_HE.png',\n",
       "   'ROI/New/919_HE.png',\n",
       "   'ROI/New/922_HE.png',\n",
       "   'ROI/New/923_HE.png',\n",
       "   'ROI/New/925_HE.png',\n",
       "   'ROI/New/929_HE.png',\n",
       "   'ROI/New/931_HE.png',\n",
       "   'ROI/New/933_HE.png',\n",
       "   'ROI/New/934_HE.png',\n",
       "   'ROI/New/936_HE.png',\n",
       "   'ROI/New/937_HE.png',\n",
       "   'ROI/New/938_HE.png',\n",
       "   'ROI/New/940_HE.png',\n",
       "   'ROI/New/941_HE.png',\n",
       "   'ROI/New/942_HE.png',\n",
       "   'ROI/New/947_HE.png',\n",
       "   'ROI/New/948_HE.png',\n",
       "   'ROI/New/949_HE.png',\n",
       "   'ROI/New/950_HE.png',\n",
       "   'ROI/New/952_HE.png',\n",
       "   'ROI/New/953_HE.png',\n",
       "   'ROI/New/954_HE.png',\n",
       "   'ROI/New/957_HE.png',\n",
       "   'ROI/New/961_HE.png',\n",
       "   'ROI/New/964_HE.png',\n",
       "   'ROI/New/966_HE.png',\n",
       "   'ROI/New/967_HE.png',\n",
       "   'ROI/New/968_HE.png',\n",
       "   'ROI/New/969_HE.png',\n",
       "   'ROI/New/970_HE.png',\n",
       "   'ROI/New/971_HE.png',\n",
       "   'ROI/New/972_HE.png',\n",
       "   'ROI/New/973_HE.png',\n",
       "   'ROI/New/975_HE.png',\n",
       "   'ROI/New/976_HE.png',\n",
       "   'ROI/New/977_HE.png',\n",
       "   'ROI/New/979_HE.png',\n",
       "   'ROI/New/980_HE.png',\n",
       "   'ROI/New/981_HE.png',\n",
       "   'ROI/New/982_HE.png',\n",
       "   'ROI/New/984_HE.png',\n",
       "   'ROI/New/985_HE.png',\n",
       "   'ROI/New/986_HE.png',\n",
       "   'ROI/New/988_HE.png',\n",
       "   'ROI/New/989_HE.png',\n",
       "   'ROI/New/990_HE.png',\n",
       "   'ROI/New/991_HE.png',\n",
       "   'ROI/New/992_HE.png',\n",
       "   'ROI/New/993_HE.png',\n",
       "   'ROI/New/994_HE.png',\n",
       "   'ROI/New/996_HE.png',\n",
       "   'ROI/New/998_HE.png',\n",
       "   'ROI/New/999_HE.png',\n",
       "   'ROI/New/1002_HE.png',\n",
       "   'ROI/New/1003_HE.png',\n",
       "   'ROI/New/1004_HE.png',\n",
       "   'ROI/New/1005_HE.png',\n",
       "   'ROI/New/1006_HE.png',\n",
       "   'ROI/New/1007_HE.png',\n",
       "   'ROI/New/1008_HE.png',\n",
       "   'ROI/New/1009_HE.png',\n",
       "   'ROI/New/1010_HE.png',\n",
       "   'ROI/New/1012_HE.png',\n",
       "   'ROI/New/1014_HE.png',\n",
       "   'ROI/New/1015_HE.png',\n",
       "   'ROI/New/1016_HE.png',\n",
       "   'ROI/New/1018_HE.png',\n",
       "   'ROI/New/1022_HE.png',\n",
       "   'ROI/New/1025_HE.png',\n",
       "   'ROI/New/1026_HE.png',\n",
       "   'ROI/New/1028_HE.png',\n",
       "   'ROI/New/1029_HE.png',\n",
       "   'ROI/New/1031_HE.png',\n",
       "   'ROI/New/1033_HE.png',\n",
       "   'ROI/New/1035_HE.png',\n",
       "   'ROI/New/1036_HE.png',\n",
       "   'ROI/New/1037_HE.png',\n",
       "   'ROI/New/1039_HE.png',\n",
       "   'ROI/New/1040_HE.png',\n",
       "   'ROI/New/1044_HE.png',\n",
       "   'ROI/New/1045_HE.png',\n",
       "   'ROI/New/1046_HE.png',\n",
       "   'ROI/New/1048_HE.png',\n",
       "   'ROI/New/1049_HE.png',\n",
       "   'ROI/New/1056_HE.png',\n",
       "   'ROI/New/1058_HE.png',\n",
       "   'ROI/New/1060_HE.png',\n",
       "   'ROI/New/1061_HE.png',\n",
       "   'ROI/New/1063_HE.png',\n",
       "   'ROI/New/1066_HE.png',\n",
       "   'ROI/New/1067_HE.png',\n",
       "   'ROI/New/1068_HE.png',\n",
       "   'ROI/New/1069_HE.png',\n",
       "   'ROI/New/1071_HE.png',\n",
       "   'ROI/New/1072_HE.png',\n",
       "   'ROI/New/1076_HE.png',\n",
       "   'ROI/New/1078_HE.png',\n",
       "   'ROI/New/1079_HE.png',\n",
       "   'ROI/New/1081_HE.png',\n",
       "   'ROI/New/1083_HE.png',\n",
       "   'ROI/New/1084_HE.png',\n",
       "   'ROI/New/1085_HE.png',\n",
       "   'ROI/New/1086_HE.png',\n",
       "   'ROI/New/1087_HE.png',\n",
       "   'ROI/New/1088_HE.png',\n",
       "   'ROI/New/1091_HE.png',\n",
       "   'ROI/New/1096_HE.png',\n",
       "   'ROI/New/1097_HE.png',\n",
       "   'ROI/New/1098_HE.png',\n",
       "   'ROI/New/1099_HE.png',\n",
       "   'ROI/New/1102_HE.png',\n",
       "   'ROI/New/1103_HE.png',\n",
       "   'ROI/New/1104_HE.png',\n",
       "   'ROI/New/1105_HE.png',\n",
       "   'ROI/New/1107_HE.png',\n",
       "   'ROI/New/1109_HE.png',\n",
       "   'ROI/New/1114_HE.png',\n",
       "   'ROI/New/1115_HE.png',\n",
       "   'ROI/New/1116_HE.png',\n",
       "   'ROI/New/1117_HE.png',\n",
       "   'ROI/New/1122_HE.png',\n",
       "   'ROI/New/1123_HE.png',\n",
       "   'ROI/New/1124_HE.png',\n",
       "   'ROI/New/1126_HE.png',\n",
       "   'ROI/New/1127_HE.png',\n",
       "   'ROI/New/1128_HE.png',\n",
       "   'ROI/New/1129_HE.png',\n",
       "   'ROI/New/1130_HE.png',\n",
       "   'ROI/New/1131_HE.png',\n",
       "   'ROI/New/1132_HE.png',\n",
       "   'ROI/New/1135_HE.png',\n",
       "   'ROI/New/1139_HE.png',\n",
       "   'ROI/New/1141_HE.png',\n",
       "   'ROI/New/1142_HE.png',\n",
       "   'ROI/New/1143_HE.png',\n",
       "   'ROI/New/1144_HE.png',\n",
       "   'ROI/New/1146_HE.png',\n",
       "   'ROI/New/1148_HE.png',\n",
       "   'ROI/New/1150_HE.png',\n",
       "   'ROI/New/1152_HE.png',\n",
       "   'ROI/New/1154_HE.png',\n",
       "   'ROI/New/1156_HE.png',\n",
       "   'ROI/New/1159_HE.png',\n",
       "   'ROI/New/1160_HE.png',\n",
       "   'ROI/New/1162_HE.png',\n",
       "   'ROI/New/1163_HE.png',\n",
       "   'ROI/New/1164_HE.png',\n",
       "   'ROI/New/1165_HE.png',\n",
       "   'ROI/New/1167_HE.png',\n",
       "   'ROI/New/1169_HE.png',\n",
       "   'ROI/New/1170_HE.png',\n",
       "   'ROI/New/1172_HE.png',\n",
       "   'ROI/New/1173_HE.png',\n",
       "   'ROI/New/1174_HE.png',\n",
       "   'ROI/New/1175_HE.png',\n",
       "   'ROI/New/1176_HE.png',\n",
       "   'ROI/New/1177_HE.png',\n",
       "   'ROI/New/1180_HE.png',\n",
       "   'ROI/New/1181_HE.png',\n",
       "   'ROI/New/1182_HE.png',\n",
       "   'ROI/New/1183_HE.png',\n",
       "   'ROI/New/1186_HE.png',\n",
       "   'ROI/New/1189_HE.png',\n",
       "   'ROI/New/1190_HE.png',\n",
       "   'ROI/New/1191_HE.png',\n",
       "   'ROI/New/1192_HE.png',\n",
       "   'ROI/New/1193_HE.png',\n",
       "   'ROI/New/160000_HE.png',\n",
       "   'ROI/New/210000_HE.png',\n",
       "   'ROI/New/280000_HE.png',\n",
       "   'ROI/New/290000_HE.png',\n",
       "   'ROI/New/410000_HE.png',\n",
       "   'ROI/New/1520000_HE.png',\n",
       "   'ROI/New/1620000_HE.png',\n",
       "   'ROI/New/1660000_HE.png',\n",
       "   'ROI/New/1670000_HE.png',\n",
       "   'ROI/New/1970000_HE.png',\n",
       "   'ROI/New/2020000_HE.png',\n",
       "   'ROI/New/2110000_HE.png',\n",
       "   'ROI/New/2190000_HE.png',\n",
       "   'ROI/New/2250000_HE.png',\n",
       "   'ROI/New/2300000_HE.png',\n",
       "   'ROI/New/2340000_HE.png',\n",
       "   'ROI/New/2370000_HE.png',\n",
       "   'ROI/New/2450000_HE.png',\n",
       "   'ROI/New/20200000_HE.png',\n",
       "   'ROI/New/201640000_HE.png',\n",
       "   'ROI/New/201670000_HE.png',\n",
       "   'ROI/New/201680000_HE.png',\n",
       "   'ROI/New/201690000_HE.png',\n",
       "   'ROI/New/201710000_HE.png',\n",
       "   'ROI/New/201720000_HE.png',\n",
       "   'ROI/New/201730000_HE.png',\n",
       "   'ROI/New/201740000_HE.png',\n",
       "   'ROI/New/201750000_HE.png',\n",
       "   'ROI/New/201760000_HE.png',\n",
       "   'ROI/New/201770000_HE.png',\n",
       "   'ROI/New/201780000_HE.png',\n",
       "   'ROI/New/201790000_HE.png',\n",
       "   'ROI/New/201810000_HE.png',\n",
       "   'ROI/New/201830000_HE.png',\n",
       "   'ROI/New/201840000_HE.png',\n",
       "   'ROI/New/201870000_HE.png',\n",
       "   'ROI/New/201880000_HE.png',\n",
       "   'ROI/New/201890000_HE.png',\n",
       "   'ROI/New/201910000_HE.png',\n",
       "   'ROI/New/201930000_HE.png',\n",
       "   'ROI/New/201940000_HE.png',\n",
       "   'ROI/New/201950000_HE.png',\n",
       "   'ROI/New/201960000_HE.png',\n",
       "   'ROI/New/201990000_HE.png',\n",
       "   'ROI/New/202030000_HE.png',\n",
       "   'ROI/New/202040000_HE.png',\n",
       "   'ROI/New/202210000_HE.png',\n",
       "   'ROI/New/202230000_HE.png',\n",
       "   'ROI/New/202250000_HE.png',\n",
       "   'ROI/New/202260000_HE.png',\n",
       "   'ROI/New/202270000_HE.png',\n",
       "   'ROI/New/202280000_HE.png',\n",
       "   'ROI/New/202290000_HE.png',\n",
       "   'ROI/New/2016110000_HE.png',\n",
       "   'ROI/New/2017130000_HE.png',\n",
       "   'ROI/New/2017140000_HE.png',\n",
       "   'ROI/New/2017150000_HE.png',\n",
       "   'ROI/New/2017170000_HE.png',\n",
       "   'ROI/New/2018100000_HE.png',\n",
       "   'ROI/New/2018120000_HE.png',\n",
       "   'ROI/New/2018140000_HE.png',\n",
       "   'ROI/New/2018160000_HE.png',\n",
       "   'ROI/New/2018170000_HE.png',\n",
       "   'ROI/New/2019100000_HE.png',\n",
       "   'ROI/New/2019110000_HE.png',\n",
       "   'ROI/New/2019120000_HE.png',\n",
       "   'ROI/New/2019140000_HE.png',\n",
       "   'ROI/New/2019160000_HE.png',\n",
       "   'ROI/New/2019170000_HE.png',\n",
       "   'ROI/New/2019190000_HE.png',\n",
       "   'ROI/New/2022100000_HE.png',\n",
       "   'ROI/New/2022130000_HE.png',\n",
       "   'ROI/New/2022150000_HE.png',\n",
       "   'ROI/New/2022170000_HE.png',\n",
       "   'ROI/New/2022180000_HE.png',\n",
       "   'ROI/New/2022200000_HE.png',\n",
       "   'ROI/New/2022220000_HE.png',\n",
       "   'ROI/New/2022230000_HE.png',\n",
       "   'ROI/New/2022240000_HE.png',\n",
       "   'ROI/New/1_HE.png',\n",
       "   'ROI/New/2_HE.png',\n",
       "   'ROI/New/3_HE.png',\n",
       "   'ROI/New/4_HE.png',\n",
       "   'ROI/New/5_HE.png',\n",
       "   'ROI/New/6_HE.png',\n",
       "   'ROI/New/9_HE.png',\n",
       "   'ROI/New/11_HE.png',\n",
       "   'ROI/New/12_HE.png',\n",
       "   'ROI/New/13_HE.png',\n",
       "   'ROI/New/14_HE.png',\n",
       "   'ROI/New/15_HE.png',\n",
       "   'ROI/New/16_HE.png',\n",
       "   'ROI/New/17_HE.png',\n",
       "   'ROI/New/18_HE.png',\n",
       "   'ROI/New/20_HE.png',\n",
       "   'ROI/New/21_HE.png',\n",
       "   'ROI/New/22_HE.png',\n",
       "   'ROI/New/23_HE.png',\n",
       "   'ROI/New/26_HE.png',\n",
       "   'ROI/New/28_HE.png',\n",
       "   'ROI/New/29_HE.png',\n",
       "   'ROI/New/36_HE.png',\n",
       "   'ROI/New/39_HE.png',\n",
       "   'ROI/New/41_HE.png',\n",
       "   'ROI/New/45_HE.png',\n",
       "   'ROI/New/46_HE.png',\n",
       "   'ROI/New/48_HE.png',\n",
       "   'ROI/New/49_HE.png',\n",
       "   'ROI/New/50_HE.png',\n",
       "   'ROI/New/51_HE.png',\n",
       "   'ROI/New/52_HE.png',\n",
       "   'ROI/New/56_HE.png',\n",
       "   'ROI/New/57_HE.png',\n",
       "   'ROI/New/58_HE.png',\n",
       "   'ROI/New/59_HE.png',\n",
       "   'ROI/New/60_HE.png',\n",
       "   'ROI/New/62_HE.png',\n",
       "   'ROI/New/65_HE.png',\n",
       "   'ROI/New/66_HE.png',\n",
       "   'ROI/New/68_HE.png',\n",
       "   'ROI/New/69_HE.png',\n",
       "   'ROI/New/71_HE.png',\n",
       "   'ROI/New/76_HE.png',\n",
       "   'ROI/New/77_HE.png',\n",
       "   'ROI/New/78_HE.png',\n",
       "   'ROI/New/81_HE.png',\n",
       "   'ROI/New/82_HE.png',\n",
       "   'ROI/New/84_HE.png',\n",
       "   'ROI/New/85_HE.png',\n",
       "   'ROI/New/86_HE.png',\n",
       "   'ROI/New/88_HE.png',\n",
       "   'ROI/New/90_HE.png',\n",
       "   'ROI/New/91_HE.png',\n",
       "   'ROI/New/92_HE.png',\n",
       "   'ROI/New/93_HE.png',\n",
       "   'ROI/New/94_HE.png',\n",
       "   'ROI/New/95_HE.png',\n",
       "   'ROI/New/96_HE.png',\n",
       "   'ROI/New/97_HE.png',\n",
       "   'ROI/New/99_HE.png',\n",
       "   'ROI/New/100_HE.png',\n",
       "   'ROI/New/101_HE.png',\n",
       "   'ROI/New/102_HE.png',\n",
       "   'ROI/New/104_HE.png',\n",
       "   'ROI/New/105_HE.png',\n",
       "   'ROI/New/106_HE.png',\n",
       "   'ROI/New/107_HE.png',\n",
       "   'ROI/New/108_HE.png',\n",
       "   'ROI/New/109_HE.png',\n",
       "   'ROI/New/110_HE.png',\n",
       "   'ROI/New/112_HE.png',\n",
       "   'ROI/New/114_HE.png',\n",
       "   'ROI/New/118_HE.png',\n",
       "   'ROI/New/120_HE.png',\n",
       "   'ROI/New/121_HE.png',\n",
       "   'ROI/New/122_HE.png',\n",
       "   'ROI/New/123_HE.png',\n",
       "   'ROI/New/125_HE.png',\n",
       "   'ROI/New/126_HE.png',\n",
       "   'ROI/New/127_HE.png',\n",
       "   'ROI/New/129_HE.png',\n",
       "   'ROI/New/130_HE.png',\n",
       "   'ROI/New/133_HE.png',\n",
       "   'ROI/New/134_HE.png',\n",
       "   'ROI/New/136_HE.png',\n",
       "   'ROI/New/138_HE.png',\n",
       "   'ROI/New/139_HE.png',\n",
       "   'ROI/New/140_HE.png',\n",
       "   'ROI/New/141_HE.png',\n",
       "   'ROI/New/145_HE.png',\n",
       "   'ROI/New/147_HE.png',\n",
       "   'ROI/New/148_HE.png',\n",
       "   'ROI/New/150_HE.png',\n",
       "   'ROI/New/152_HE.png',\n",
       "   'ROI/New/153_HE.png',\n",
       "   'ROI/New/155_HE.png',\n",
       "   'ROI/New/156_HE.png',\n",
       "   'ROI/New/160_HE.png',\n",
       "   'ROI/New/161_HE.png',\n",
       "   'ROI/New/162_HE.png',\n",
       "   'ROI/New/164_HE.png',\n",
       "   'ROI/New/166_HE.png',\n",
       "   'ROI/New/167_HE.png',\n",
       "   'ROI/New/168_HE.png',\n",
       "   'ROI/New/169_HE.png',\n",
       "   'ROI/New/170_HE.png',\n",
       "   'ROI/New/171_HE.png',\n",
       "   'ROI/New/172_HE.png',\n",
       "   'ROI/New/173_HE.png',\n",
       "   'ROI/New/174_HE.png',\n",
       "   'ROI/New/175_HE.png',\n",
       "   'ROI/New/176_HE.png',\n",
       "   'ROI/New/177_HE.png',\n",
       "   'ROI/New/178_HE.png',\n",
       "   'ROI/New/180_HE.png',\n",
       "   'ROI/New/181_HE.png',\n",
       "   'ROI/New/182_HE.png',\n",
       "   'ROI/New/183_HE.png',\n",
       "   'ROI/New/184_HE.png',\n",
       "   'ROI/New/185_HE.png',\n",
       "   'ROI/New/186_HE.png',\n",
       "   'ROI/New/187_HE.png',\n",
       "   'ROI/New/188_HE.png',\n",
       "   'ROI/New/189_HE.png',\n",
       "   'ROI/New/190_HE.png',\n",
       "   'ROI/New/193_HE.png',\n",
       "   'ROI/New/194_HE.png',\n",
       "   'ROI/New/196_HE.png',\n",
       "   'ROI/New/198_HE.png',\n",
       "   'ROI/New/199_HE.png',\n",
       "   'ROI/New/200_HE.png',\n",
       "   'ROI/New/201_HE.png',\n",
       "   'ROI/New/202_HE.png',\n",
       "   'ROI/New/203_HE.png',\n",
       "   'ROI/New/204_HE.png',\n",
       "   'ROI/New/205_HE.png',\n",
       "   'ROI/New/206_HE.png',\n",
       "   'ROI/New/207_HE.png',\n",
       "   'ROI/New/208_HE.png',\n",
       "   'ROI/New/212_HE.png',\n",
       "   'ROI/New/213_HE.png',\n",
       "   'ROI/New/214_HE.png',\n",
       "   'ROI/New/216_HE.png',\n",
       "   'ROI/New/217_HE.png',\n",
       "   'ROI/New/218_HE.png',\n",
       "   'ROI/New/220_HE.png',\n",
       "   'ROI/New/221_HE.png',\n",
       "   'ROI/New/224_HE.png',\n",
       "   'ROI/New/227_HE.png',\n",
       "   'ROI/New/229_HE.png',\n",
       "   'ROI/New/230_HE.png',\n",
       "   'ROI/New/236_HE.png',\n",
       "   'ROI/New/237_HE.png',\n",
       "   'ROI/New/238_HE.png',\n",
       "   'ROI/New/240_HE.png',\n",
       "   'ROI/New/244_HE.png',\n",
       "   'ROI/New/245_HE.png',\n",
       "   'ROI/New/250_HE.png',\n",
       "   'ROI/New/251_HE.png',\n",
       "   'ROI/New/252_HE.png',\n",
       "   'ROI/New/253_HE.png',\n",
       "   'ROI/New/255_HE.png',\n",
       "   'ROI/New/260_HE.png',\n",
       "   'ROI/New/263_HE.png',\n",
       "   'ROI/New/264_HE.png',\n",
       "   'ROI/New/270_HE.png',\n",
       "   'ROI/New/271_HE.png',\n",
       "   'ROI/New/276_HE.png',\n",
       "   'ROI/New/277_HE.png',\n",
       "   'ROI/New/279_HE.png',\n",
       "   'ROI/New/281_HE.png',\n",
       "   'ROI/New/286_HE.png',\n",
       "   'ROI/New/289_HE.png',\n",
       "   'ROI/New/290_HE.png',\n",
       "   'ROI/New/293_HE.png',\n",
       "   'ROI/New/295_HE.png',\n",
       "   'ROI/New/299_HE.png',\n",
       "   'ROI/New/300_HE.png',\n",
       "   'ROI/New/301_HE.png',\n",
       "   'ROI/New/302_HE.png',\n",
       "   'ROI/New/307_HE.png',\n",
       "   'ROI/New/308_HE.png',\n",
       "   'ROI/New/309_HE.png',\n",
       "   'ROI/New/310_HE.png',\n",
       "   'ROI/New/311_HE.png',\n",
       "   'ROI/New/312_HE.png',\n",
       "   'ROI/New/313_HE.png',\n",
       "   'ROI/New/314_HE.png',\n",
       "   'ROI/New/315_HE.png',\n",
       "   'ROI/New/316_HE.png',\n",
       "   'ROI/New/318_HE.png',\n",
       "   'ROI/New/319_HE.png',\n",
       "   'ROI/New/320_HE.png',\n",
       "   'ROI/New/321_HE.png',\n",
       "   'ROI/New/322_HE.png',\n",
       "   'ROI/New/323_HE.png',\n",
       "   'ROI/New/324_HE.png',\n",
       "   'ROI/New/325_HE.png',\n",
       "   'ROI/New/328_HE.png',\n",
       "   'ROI/New/329_HE.png',\n",
       "   'ROI/New/333_HE.png',\n",
       "   'ROI/New/336_HE.png',\n",
       "   'ROI/New/341_HE.png',\n",
       "   'ROI/New/342_HE.png',\n",
       "   'ROI/New/343_HE.png',\n",
       "   'ROI/New/344_HE.png',\n",
       "   'ROI/New/345_HE.png',\n",
       "   'ROI/New/346_HE.png',\n",
       "   'ROI/New/347_HE.png',\n",
       "   'ROI/New/348_HE.png',\n",
       "   'ROI/New/350_HE.png',\n",
       "   'ROI/New/352_HE.png',\n",
       "   'ROI/New/355_HE.png',\n",
       "   'ROI/New/356_HE.png',\n",
       "   'ROI/New/358_HE.png',\n",
       "   'ROI/New/360_HE.png',\n",
       "   'ROI/New/361_HE.png',\n",
       "   'ROI/New/364_HE.png',\n",
       "   'ROI/New/365_HE.png',\n",
       "   'ROI/New/366_HE.png',\n",
       "   'ROI/New/368_HE.png',\n",
       "   'ROI/New/371_HE.png',\n",
       "   'ROI/New/372_HE.png',\n",
       "   'ROI/New/374_HE.png',\n",
       "   'ROI/New/375_HE.png',\n",
       "   'ROI/New/376_HE.png',\n",
       "   'ROI/New/377_HE.png',\n",
       "   'ROI/New/379_HE.png',\n",
       "   'ROI/New/380_HE.png',\n",
       "   'ROI/New/381_HE.png',\n",
       "   'ROI/New/382_HE.png',\n",
       "   'ROI/New/383_HE.png',\n",
       "   'ROI/New/384_HE.png',\n",
       "   'ROI/New/385_HE.png',\n",
       "   'ROI/New/386_HE.png',\n",
       "   'ROI/New/387_HE.png',\n",
       "   'ROI/New/388_HE.png',\n",
       "   'ROI/New/392_HE.png',\n",
       "   'ROI/New/394_HE.png',\n",
       "   'ROI/New/395_HE.png',\n",
       "   'ROI/New/396_HE.png',\n",
       "   'ROI/New/397_HE.png',\n",
       "   'ROI/New/399_HE.png',\n",
       "   'ROI/New/400_HE.png',\n",
       "   'ROI/New/401_HE.png',\n",
       "   'ROI/New/402_HE.png',\n",
       "   'ROI/New/403_HE.png',\n",
       "   'ROI/New/404_HE.png',\n",
       "   'ROI/New/409_HE.png',\n",
       "   'ROI/New/410_HE.png',\n",
       "   'ROI/New/411_HE.png',\n",
       "   'ROI/New/412_HE.png',\n",
       "   'ROI/New/413_HE.png',\n",
       "   'ROI/New/414_HE.png',\n",
       "   'ROI/New/415_HE.png',\n",
       "   'ROI/New/417_HE.png',\n",
       "   'ROI/New/418_HE.png',\n",
       "   'ROI/New/419_HE.png',\n",
       "   'ROI/New/420_HE.png',\n",
       "   'ROI/New/424_HE.png',\n",
       "   'ROI/New/427_HE.png',\n",
       "   'ROI/New/428_HE.png',\n",
       "   'ROI/New/429_HE.png',\n",
       "   'ROI/New/430_HE.png',\n",
       "   'ROI/New/431_HE.png',\n",
       "   'ROI/New/432_HE.png',\n",
       "   'ROI/New/433_HE.png',\n",
       "   'ROI/New/435_HE.png',\n",
       "   'ROI/New/436_HE.png',\n",
       "   'ROI/New/437_HE.png',\n",
       "   'ROI/New/440_HE.png',\n",
       "   'ROI/New/443_HE.png',\n",
       "   'ROI/New/444_HE.png',\n",
       "   'ROI/New/445_HE.png',\n",
       "   'ROI/New/446_HE.png',\n",
       "   'ROI/New/447_HE.png',\n",
       "   'ROI/New/448_HE.png',\n",
       "   'ROI/New/449_HE.png',\n",
       "   'ROI/New/450_HE.png',\n",
       "   'ROI/New/451_HE.png',\n",
       "   'ROI/New/452_HE.png',\n",
       "   'ROI/New/454_HE.png',\n",
       "   'ROI/New/455_HE.png',\n",
       "   'ROI/New/457_HE.png',\n",
       "   'ROI/New/458_HE.png',\n",
       "   'ROI/New/459_HE.png',\n",
       "   'ROI/New/460_HE.png',\n",
       "   'ROI/New/462_HE.png',\n",
       "   'ROI/New/463_HE.png',\n",
       "   'ROI/New/464_HE.png',\n",
       "   'ROI/New/466_HE.png',\n",
       "   'ROI/New/467_HE.png',\n",
       "   'ROI/New/469_HE.png',\n",
       "   'ROI/New/470_HE.png',\n",
       "   'ROI/New/472_HE.png',\n",
       "   'ROI/New/474_HE.png',\n",
       "   'ROI/New/475_HE.png',\n",
       "   'ROI/New/476_HE.png',\n",
       "   'ROI/New/478_HE.png',\n",
       "   'ROI/New/479_HE.png',\n",
       "   'ROI/New/480_HE.png',\n",
       "   'ROI/New/481_HE.png',\n",
       "   'ROI/New/482_HE.png',\n",
       "   'ROI/New/483_HE.png',\n",
       "   'ROI/New/484_HE.png',\n",
       "   'ROI/New/486_HE.png',\n",
       "   'ROI/New/487_HE.png',\n",
       "   'ROI/New/488_HE.png',\n",
       "   'ROI/New/489_HE.png',\n",
       "   'ROI/New/490_HE.png',\n",
       "   'ROI/New/492_HE.png',\n",
       "   'ROI/New/493_HE.png',\n",
       "   'ROI/New/494_HE.png',\n",
       "   'ROI/New/495_HE.png',\n",
       "   'ROI/New/496_HE.png',\n",
       "   'ROI/New/497_HE.png',\n",
       "   'ROI/New/499_HE.png',\n",
       "   'ROI/New/500_HE.png',\n",
       "   'ROI/New/501_HE.png',\n",
       "   'ROI/New/502_HE.png',\n",
       "   'ROI/New/506_HE.png',\n",
       "   'ROI/New/507_HE.png',\n",
       "   'ROI/New/509_HE.png',\n",
       "   'ROI/New/510_HE.png',\n",
       "   'ROI/New/517_HE.png',\n",
       "   'ROI/New/518_HE.png',\n",
       "   'ROI/New/519_HE.png',\n",
       "   'ROI/New/522_HE.png',\n",
       "   'ROI/New/525_HE.png',\n",
       "   'ROI/New/526_HE.png',\n",
       "   'ROI/New/529_HE.png',\n",
       "   'ROI/New/530_HE.png',\n",
       "   'ROI/New/532_HE.png',\n",
       "   'ROI/New/534_HE.png',\n",
       "   'ROI/New/536_HE.png',\n",
       "   'ROI/New/537_HE.png',\n",
       "   'ROI/New/538_HE.png',\n",
       "   'ROI/New/539_HE.png',\n",
       "   'ROI/New/540_HE.png',\n",
       "   'ROI/New/541_HE.png',\n",
       "   'ROI/New/542_HE.png'],\n",
       "  ['ROI/New/620_HE.png',\n",
       "   'ROI/New/1125_HE.png',\n",
       "   'ROI/New/622_HE.png',\n",
       "   'ROI/New/242_HE.png',\n",
       "   'ROI/New/259_HE.png',\n",
       "   'ROI/New/266_HE.png',\n",
       "   'ROI/New/353_HE.png',\n",
       "   'ROI/New/149_HE.png',\n",
       "   'ROI/New/179_HE.png',\n",
       "   'ROI/New/165_HE.png',\n",
       "   'ROI/New/902_HE.png',\n",
       "   'ROI/New/1580000_HE.png',\n",
       "   'ROI/New/790000_HE.png',\n",
       "   'ROI/New/440000_HE.png',\n",
       "   'ROI/New/10900000_HE.png',\n",
       "   'ROI/New/940000_HE.png',\n",
       "   'ROI/New/830000_HE.png',\n",
       "   'ROI/New/1440000_HE.png',\n",
       "   'ROI/New/1070000_HE.png',\n",
       "   'ROI/New/1310000_HE.png',\n",
       "   'ROI/New/202020000_HE.png',\n",
       "   'ROI/New/1000000_HE.png',\n",
       "   'ROI/New/2017160000_HE.png',\n",
       "   'ROI/New/2017110000_HE.png',\n",
       "   'ROI/New/3010000_HE.png',\n",
       "   'ROI/New/202050000_HE.png',\n",
       "   'ROI/New/1230000_HE.png',\n",
       "   'ROI/New/300000_HE.png',\n",
       "   'ROI/New/890000_HE.png',\n",
       "   'ROI/New/930000_HE.png',\n",
       "   'ROI/New/1920000_HE.png',\n",
       "   'ROI/New/2010000_HE.png',\n",
       "   'ROI/New/810000_HE.png',\n",
       "   'ROI/New/1400000_HE.png',\n",
       "   'ROI/New/2510000_HE.png',\n",
       "   'ROI/New/120000_HE.png',\n",
       "   'ROI/New/200000_HE.png',\n",
       "   'ROI/New/2016100000_HE.png',\n",
       "   'ROI/New/544_HE.png',\n",
       "   'ROI/New/550_HE.png',\n",
       "   'ROI/New/569_HE.png',\n",
       "   'ROI/New/585_HE.png',\n",
       "   'ROI/New/587_HE.png',\n",
       "   'ROI/New/588_HE.png',\n",
       "   'ROI/New/590_HE.png',\n",
       "   'ROI/New/596_HE.png',\n",
       "   'ROI/New/599_HE.png',\n",
       "   'ROI/New/615_HE.png',\n",
       "   'ROI/New/616_HE.png',\n",
       "   'ROI/New/635_HE.png',\n",
       "   'ROI/New/655_HE.png',\n",
       "   'ROI/New/657_HE.png',\n",
       "   'ROI/New/664_HE.png',\n",
       "   'ROI/New/665_HE.png',\n",
       "   'ROI/New/668_HE.png',\n",
       "   'ROI/New/674_HE.png',\n",
       "   'ROI/New/677_HE.png',\n",
       "   'ROI/New/679_HE.png',\n",
       "   'ROI/New/687_HE.png',\n",
       "   'ROI/New/695_HE.png',\n",
       "   'ROI/New/698_HE.png',\n",
       "   'ROI/New/703_HE.png',\n",
       "   'ROI/New/708_HE.png',\n",
       "   'ROI/New/713_HE.png',\n",
       "   'ROI/New/721_HE.png',\n",
       "   'ROI/New/727_HE.png',\n",
       "   'ROI/New/732_HE.png',\n",
       "   'ROI/New/736_HE.png',\n",
       "   'ROI/New/742_HE.png',\n",
       "   'ROI/New/746_HE.png',\n",
       "   'ROI/New/754_HE.png',\n",
       "   'ROI/New/761_HE.png',\n",
       "   'ROI/New/765_HE.png',\n",
       "   'ROI/New/766_HE.png',\n",
       "   'ROI/New/774_HE.png',\n",
       "   'ROI/New/787_HE.png',\n",
       "   'ROI/New/788_HE.png',\n",
       "   'ROI/New/800_HE.png',\n",
       "   'ROI/New/803_HE.png',\n",
       "   'ROI/New/804_HE.png',\n",
       "   'ROI/New/810_HE.png',\n",
       "   'ROI/New/815_HE.png',\n",
       "   'ROI/New/816_HE.png',\n",
       "   'ROI/New/826_HE.png',\n",
       "   'ROI/New/832_HE.png',\n",
       "   'ROI/New/836_HE.png',\n",
       "   'ROI/New/850_HE.png',\n",
       "   'ROI/New/852_HE.png',\n",
       "   'ROI/New/863_HE.png',\n",
       "   'ROI/New/867_HE.png',\n",
       "   'ROI/New/876_HE.png',\n",
       "   'ROI/New/880_HE.png',\n",
       "   'ROI/New/893_HE.png',\n",
       "   'ROI/New/907_HE.png',\n",
       "   'ROI/New/927_HE.png',\n",
       "   'ROI/New/928_HE.png',\n",
       "   'ROI/New/930_HE.png',\n",
       "   'ROI/New/932_HE.png',\n",
       "   'ROI/New/939_HE.png',\n",
       "   'ROI/New/943_HE.png',\n",
       "   'ROI/New/944_HE.png',\n",
       "   'ROI/New/951_HE.png',\n",
       "   'ROI/New/959_HE.png',\n",
       "   'ROI/New/960_HE.png',\n",
       "   'ROI/New/962_HE.png',\n",
       "   'ROI/New/963_HE.png',\n",
       "   'ROI/New/978_HE.png',\n",
       "   'ROI/New/987_HE.png',\n",
       "   'ROI/New/995_HE.png',\n",
       "   'ROI/New/997_HE.png',\n",
       "   'ROI/New/1024_HE.png',\n",
       "   'ROI/New/1032_HE.png',\n",
       "   'ROI/New/1047_HE.png',\n",
       "   'ROI/New/1062_HE.png',\n",
       "   'ROI/New/1065_HE.png',\n",
       "   'ROI/New/1073_HE.png',\n",
       "   'ROI/New/1074_HE.png',\n",
       "   'ROI/New/1082_HE.png',\n",
       "   'ROI/New/1089_HE.png',\n",
       "   'ROI/New/1100_HE.png',\n",
       "   'ROI/New/1106_HE.png',\n",
       "   'ROI/New/1111_HE.png',\n",
       "   'ROI/New/1112_HE.png',\n",
       "   'ROI/New/1136_HE.png',\n",
       "   'ROI/New/1145_HE.png',\n",
       "   'ROI/New/1157_HE.png',\n",
       "   'ROI/New/1168_HE.png',\n",
       "   'ROI/New/1171_HE.png',\n",
       "   'ROI/New/1184_HE.png',\n",
       "   'ROI/New/1187_HE.png',\n",
       "   'ROI/New/1188_HE.png',\n",
       "   'ROI/New/150000_HE.png',\n",
       "   'ROI/New/1600000_HE.png',\n",
       "   'ROI/New/1950000_HE.png',\n",
       "   'ROI/New/201610000_HE.png',\n",
       "   'ROI/New/201820000_HE.png',\n",
       "   'ROI/New/201850000_HE.png',\n",
       "   'ROI/New/201860000_HE.png',\n",
       "   'ROI/New/201970000_HE.png',\n",
       "   'ROI/New/202010000_HE.png',\n",
       "   'ROI/New/202220000_HE.png',\n",
       "   'ROI/New/202240000_HE.png',\n",
       "   'ROI/New/2017120000_HE.png',\n",
       "   'ROI/New/2018130000_HE.png',\n",
       "   'ROI/New/2018150000_HE.png',\n",
       "   'ROI/New/2019130000_HE.png',\n",
       "   'ROI/New/2019150000_HE.png',\n",
       "   'ROI/New/2022120000_HE.png',\n",
       "   'ROI/New/2022210000_HE.png',\n",
       "   'ROI/New/10_HE.png',\n",
       "   'ROI/New/25_HE.png',\n",
       "   'ROI/New/27_HE.png',\n",
       "   'ROI/New/33_HE.png',\n",
       "   'ROI/New/34_HE.png',\n",
       "   'ROI/New/37_HE.png',\n",
       "   'ROI/New/40_HE.png',\n",
       "   'ROI/New/43_HE.png',\n",
       "   'ROI/New/47_HE.png',\n",
       "   'ROI/New/54_HE.png',\n",
       "   'ROI/New/55_HE.png',\n",
       "   'ROI/New/63_HE.png',\n",
       "   'ROI/New/64_HE.png',\n",
       "   'ROI/New/70_HE.png',\n",
       "   'ROI/New/72_HE.png',\n",
       "   'ROI/New/73_HE.png',\n",
       "   'ROI/New/74_HE.png',\n",
       "   'ROI/New/79_HE.png',\n",
       "   'ROI/New/87_HE.png',\n",
       "   'ROI/New/103_HE.png',\n",
       "   'ROI/New/111_HE.png',\n",
       "   'ROI/New/113_HE.png',\n",
       "   'ROI/New/115_HE.png',\n",
       "   'ROI/New/116_HE.png',\n",
       "   'ROI/New/132_HE.png',\n",
       "   'ROI/New/137_HE.png',\n",
       "   'ROI/New/144_HE.png',\n",
       "   'ROI/New/146_HE.png',\n",
       "   'ROI/New/151_HE.png',\n",
       "   'ROI/New/157_HE.png',\n",
       "   'ROI/New/158_HE.png',\n",
       "   'ROI/New/159_HE.png',\n",
       "   'ROI/New/163_HE.png',\n",
       "   'ROI/New/192_HE.png',\n",
       "   'ROI/New/195_HE.png',\n",
       "   'ROI/New/197_HE.png',\n",
       "   'ROI/New/209_HE.png',\n",
       "   'ROI/New/215_HE.png',\n",
       "   'ROI/New/222_HE.png',\n",
       "   'ROI/New/233_HE.png',\n",
       "   'ROI/New/235_HE.png',\n",
       "   'ROI/New/247_HE.png',\n",
       "   'ROI/New/249_HE.png',\n",
       "   'ROI/New/256_HE.png',\n",
       "   'ROI/New/257_HE.png',\n",
       "   'ROI/New/267_HE.png',\n",
       "   'ROI/New/272_HE.png',\n",
       "   'ROI/New/278_HE.png',\n",
       "   'ROI/New/280_HE.png',\n",
       "   'ROI/New/283_HE.png',\n",
       "   'ROI/New/287_HE.png',\n",
       "   'ROI/New/292_HE.png',\n",
       "   'ROI/New/294_HE.png',\n",
       "   'ROI/New/296_HE.png',\n",
       "   'ROI/New/298_HE.png',\n",
       "   'ROI/New/304_HE.png',\n",
       "   'ROI/New/305_HE.png',\n",
       "   'ROI/New/317_HE.png',\n",
       "   'ROI/New/327_HE.png',\n",
       "   'ROI/New/332_HE.png',\n",
       "   'ROI/New/337_HE.png',\n",
       "   'ROI/New/340_HE.png',\n",
       "   'ROI/New/351_HE.png',\n",
       "   'ROI/New/363_HE.png',\n",
       "   'ROI/New/390_HE.png',\n",
       "   'ROI/New/391_HE.png',\n",
       "   'ROI/New/406_HE.png',\n",
       "   'ROI/New/407_HE.png',\n",
       "   'ROI/New/421_HE.png',\n",
       "   'ROI/New/423_HE.png',\n",
       "   'ROI/New/425_HE.png',\n",
       "   'ROI/New/426_HE.png',\n",
       "   'ROI/New/439_HE.png',\n",
       "   'ROI/New/441_HE.png',\n",
       "   'ROI/New/453_HE.png',\n",
       "   'ROI/New/465_HE.png',\n",
       "   'ROI/New/477_HE.png',\n",
       "   'ROI/New/485_HE.png',\n",
       "   'ROI/New/491_HE.png',\n",
       "   'ROI/New/503_HE.png',\n",
       "   'ROI/New/505_HE.png',\n",
       "   'ROI/New/512_HE.png',\n",
       "   'ROI/New/520_HE.png',\n",
       "   'ROI/New/521_HE.png',\n",
       "   'ROI/New/524_HE.png',\n",
       "   'ROI/New/535_HE.png']],\n",
       " [['ROI/New/357_HE.png',\n",
       "   'ROI/New/89_HE.png',\n",
       "   'ROI/New/1059_HE.png',\n",
       "   'ROI/New/1013_HE.png',\n",
       "   'ROI/New/269_HE.png',\n",
       "   'ROI/New/620_HE.png',\n",
       "   'ROI/New/1075_HE.png',\n",
       "   'ROI/New/1043_HE.png',\n",
       "   'ROI/New/1125_HE.png',\n",
       "   'ROI/New/1138_HE.png',\n",
       "   'ROI/New/1161_HE.png',\n",
       "   'ROI/New/840_HE.png',\n",
       "   'ROI/New/845_HE.png',\n",
       "   'ROI/New/543_HE.png',\n",
       "   'ROI/New/622_HE.png',\n",
       "   'ROI/New/246_HE.png',\n",
       "   'ROI/New/242_HE.png',\n",
       "   'ROI/New/259_HE.png',\n",
       "   'ROI/New/261_HE.png',\n",
       "   'ROI/New/266_HE.png',\n",
       "   'ROI/New/288_HE.png',\n",
       "   'ROI/New/306_HE.png',\n",
       "   'ROI/New/297_HE.png',\n",
       "   'ROI/New/353_HE.png',\n",
       "   'ROI/New/369_HE.png',\n",
       "   'ROI/New/373_HE.png',\n",
       "   'ROI/New/362_HE.png',\n",
       "   'ROI/New/378_HE.png',\n",
       "   'ROI/New/142_HE.png',\n",
       "   'ROI/New/389_HE.png',\n",
       "   'ROI/New/398_HE.png',\n",
       "   'ROI/New/44_HE.png',\n",
       "   'ROI/New/67_HE.png',\n",
       "   'ROI/New/61_HE.png',\n",
       "   'ROI/New/143_HE.png',\n",
       "   'ROI/New/124_HE.png',\n",
       "   'ROI/New/149_HE.png',\n",
       "   'ROI/New/179_HE.png',\n",
       "   'ROI/New/165_HE.png',\n",
       "   'ROI/New/902_HE.png',\n",
       "   'ROI/New/1210000_HE.png',\n",
       "   'ROI/New/430000_HE.png',\n",
       "   'ROI/New/1580000_HE.png',\n",
       "   'ROI/New/790000_HE.png',\n",
       "   'ROI/New/440000_HE.png',\n",
       "   'ROI/New/620000_HE.png',\n",
       "   'ROI/New/2140000_HE.png',\n",
       "   'ROI/New/6200000_HE.png',\n",
       "   'ROI/New/10900000_HE.png',\n",
       "   'ROI/New/340000_HE.png',\n",
       "   'ROI/New/940000_HE.png',\n",
       "   'ROI/New/830000_HE.png',\n",
       "   'ROI/New/1440000_HE.png',\n",
       "   'ROI/New/1070000_HE.png',\n",
       "   'ROI/New/660000_HE.png',\n",
       "   'ROI/New/8100000_HE.png',\n",
       "   'ROI/New/1590000_HE.png',\n",
       "   'ROI/New/1050000_HE.png',\n",
       "   'ROI/New/1310000_HE.png',\n",
       "   'ROI/New/202020000_HE.png',\n",
       "   'ROI/New/9700000_HE.png',\n",
       "   'ROI/New/15200000_HE.png',\n",
       "   'ROI/New/390000_HE.png',\n",
       "   'ROI/New/9500000_HE.png',\n",
       "   'ROI/New/1270000_HE.png',\n",
       "   'ROI/New/2022110000_HE.png',\n",
       "   'ROI/New/1000000_HE.png',\n",
       "   'ROI/New/370000_HE.png',\n",
       "   'ROI/New/950000_HE.png',\n",
       "   'ROI/New/460000_HE.png',\n",
       "   'ROI/New/310000_HE.png',\n",
       "   'ROI/New/1940000_HE.png',\n",
       "   'ROI/New/2022190000_HE.png',\n",
       "   'ROI/New/1290000_HE.png',\n",
       "   'ROI/New/2016120000_HE.png',\n",
       "   'ROI/New/201620000_HE.png',\n",
       "   'ROI/New/1510000_HE.png',\n",
       "   'ROI/New/2017160000_HE.png',\n",
       "   'ROI/New/1100000_HE.png',\n",
       "   'ROI/New/2017110000_HE.png',\n",
       "   'ROI/New/450000_HE.png',\n",
       "   'ROI/New/2019180000_HE.png',\n",
       "   'ROI/New/3010000_HE.png',\n",
       "   'ROI/New/1020000_HE.png',\n",
       "   'ROI/New/1570000_HE.png',\n",
       "   'ROI/New/1090000_HE.png',\n",
       "   'ROI/New/202050000_HE.png',\n",
       "   'ROI/New/1230000_HE.png',\n",
       "   'ROI/New/50000_HE.png',\n",
       "   'ROI/New/100000_HE.png',\n",
       "   'ROI/New/300000_HE.png',\n",
       "   'ROI/New/420000_HE.png',\n",
       "   'ROI/New/880000_HE.png',\n",
       "   'ROI/New/890000_HE.png',\n",
       "   'ROI/New/930000_HE.png',\n",
       "   'ROI/New/1080000_HE.png',\n",
       "   'ROI/New/1920000_HE.png',\n",
       "   'ROI/New/2010000_HE.png',\n",
       "   'ROI/New/670000_HE.png',\n",
       "   'ROI/New/7900000_HE.png',\n",
       "   'ROI/New/810000_HE.png',\n",
       "   'ROI/New/1140000_HE.png',\n",
       "   'ROI/New/1150000_HE.png',\n",
       "   'ROI/New/1400000_HE.png',\n",
       "   'ROI/New/1460000_HE.png',\n",
       "   'ROI/New/1860000_HE.png',\n",
       "   'ROI/New/1870000_HE.png',\n",
       "   'ROI/New/2510000_HE.png',\n",
       "   'ROI/New/120000_HE.png',\n",
       "   'ROI/New/16000000_HE.png',\n",
       "   'ROI/New/200000_HE.png',\n",
       "   'ROI/New/470000_HE.png',\n",
       "   'ROI/New/740000_HE.png',\n",
       "   'ROI/New/8400000_HE.png',\n",
       "   'ROI/New/2017100000_HE.png',\n",
       "   'ROI/New/2016100000_HE.png',\n",
       "   'ROI/New/544_HE.png',\n",
       "   'ROI/New/545_HE.png',\n",
       "   'ROI/New/547_HE.png',\n",
       "   'ROI/New/548_HE.png',\n",
       "   'ROI/New/550_HE.png',\n",
       "   'ROI/New/551_HE.png',\n",
       "   'ROI/New/555_HE.png',\n",
       "   'ROI/New/560_HE.png',\n",
       "   'ROI/New/561_HE.png',\n",
       "   'ROI/New/563_HE.png',\n",
       "   'ROI/New/564_HE.png',\n",
       "   'ROI/New/566_HE.png',\n",
       "   'ROI/New/568_HE.png',\n",
       "   'ROI/New/569_HE.png',\n",
       "   'ROI/New/570_HE.png',\n",
       "   'ROI/New/571_HE.png',\n",
       "   'ROI/New/572_HE.png',\n",
       "   'ROI/New/575_HE.png',\n",
       "   'ROI/New/576_HE.png',\n",
       "   'ROI/New/577_HE.png',\n",
       "   'ROI/New/579_HE.png',\n",
       "   'ROI/New/580_HE.png',\n",
       "   'ROI/New/581_HE.png',\n",
       "   'ROI/New/582_HE.png',\n",
       "   'ROI/New/584_HE.png',\n",
       "   'ROI/New/585_HE.png',\n",
       "   'ROI/New/587_HE.png',\n",
       "   'ROI/New/588_HE.png',\n",
       "   'ROI/New/590_HE.png',\n",
       "   'ROI/New/591_HE.png',\n",
       "   'ROI/New/593_HE.png',\n",
       "   'ROI/New/594_HE.png',\n",
       "   'ROI/New/596_HE.png',\n",
       "   'ROI/New/597_HE.png',\n",
       "   'ROI/New/598_HE.png',\n",
       "   'ROI/New/599_HE.png',\n",
       "   'ROI/New/600_HE.png',\n",
       "   'ROI/New/601_HE.png',\n",
       "   'ROI/New/602_HE.png',\n",
       "   'ROI/New/603_HE.png',\n",
       "   'ROI/New/604_HE.png',\n",
       "   'ROI/New/605_HE.png',\n",
       "   'ROI/New/606_HE.png',\n",
       "   'ROI/New/607_HE.png',\n",
       "   'ROI/New/608_HE.png',\n",
       "   'ROI/New/609_HE.png',\n",
       "   'ROI/New/610_HE.png',\n",
       "   'ROI/New/612_HE.png',\n",
       "   'ROI/New/613_HE.png',\n",
       "   'ROI/New/614_HE.png',\n",
       "   'ROI/New/615_HE.png',\n",
       "   'ROI/New/616_HE.png',\n",
       "   'ROI/New/618_HE.png',\n",
       "   'ROI/New/621_HE.png',\n",
       "   'ROI/New/625_HE.png',\n",
       "   'ROI/New/627_HE.png',\n",
       "   'ROI/New/630_HE.png',\n",
       "   'ROI/New/635_HE.png',\n",
       "   'ROI/New/636_HE.png',\n",
       "   'ROI/New/639_HE.png',\n",
       "   'ROI/New/640_HE.png',\n",
       "   'ROI/New/641_HE.png',\n",
       "   'ROI/New/645_HE.png',\n",
       "   'ROI/New/646_HE.png',\n",
       "   'ROI/New/647_HE.png',\n",
       "   'ROI/New/648_HE.png',\n",
       "   'ROI/New/649_HE.png',\n",
       "   'ROI/New/655_HE.png',\n",
       "   'ROI/New/657_HE.png',\n",
       "   'ROI/New/658_HE.png',\n",
       "   'ROI/New/659_HE.png',\n",
       "   'ROI/New/660_HE.png',\n",
       "   'ROI/New/661_HE.png',\n",
       "   'ROI/New/662_HE.png',\n",
       "   'ROI/New/664_HE.png',\n",
       "   'ROI/New/665_HE.png',\n",
       "   'ROI/New/666_HE.png',\n",
       "   'ROI/New/667_HE.png',\n",
       "   'ROI/New/668_HE.png',\n",
       "   'ROI/New/669_HE.png',\n",
       "   'ROI/New/670_HE.png',\n",
       "   'ROI/New/671_HE.png',\n",
       "   'ROI/New/674_HE.png',\n",
       "   'ROI/New/675_HE.png',\n",
       "   'ROI/New/676_HE.png',\n",
       "   'ROI/New/677_HE.png',\n",
       "   'ROI/New/679_HE.png',\n",
       "   'ROI/New/680_HE.png',\n",
       "   'ROI/New/684_HE.png',\n",
       "   'ROI/New/685_HE.png',\n",
       "   'ROI/New/686_HE.png',\n",
       "   'ROI/New/687_HE.png',\n",
       "   'ROI/New/688_HE.png',\n",
       "   'ROI/New/692_HE.png',\n",
       "   'ROI/New/693_HE.png',\n",
       "   'ROI/New/695_HE.png',\n",
       "   'ROI/New/698_HE.png',\n",
       "   'ROI/New/699_HE.png',\n",
       "   'ROI/New/700_HE.png',\n",
       "   'ROI/New/701_HE.png',\n",
       "   'ROI/New/703_HE.png',\n",
       "   'ROI/New/704_HE.png',\n",
       "   'ROI/New/707_HE.png',\n",
       "   'ROI/New/708_HE.png',\n",
       "   'ROI/New/710_HE.png',\n",
       "   'ROI/New/712_HE.png',\n",
       "   'ROI/New/713_HE.png',\n",
       "   'ROI/New/714_HE.png',\n",
       "   'ROI/New/715_HE.png',\n",
       "   'ROI/New/716_HE.png',\n",
       "   'ROI/New/718_HE.png',\n",
       "   'ROI/New/720_HE.png',\n",
       "   'ROI/New/721_HE.png',\n",
       "   'ROI/New/722_HE.png',\n",
       "   'ROI/New/723_HE.png',\n",
       "   'ROI/New/724_HE.png',\n",
       "   'ROI/New/725_HE.png',\n",
       "   'ROI/New/727_HE.png',\n",
       "   'ROI/New/729_HE.png',\n",
       "   'ROI/New/730_HE.png',\n",
       "   'ROI/New/732_HE.png',\n",
       "   'ROI/New/733_HE.png',\n",
       "   'ROI/New/735_HE.png',\n",
       "   'ROI/New/736_HE.png',\n",
       "   'ROI/New/738_HE.png',\n",
       "   'ROI/New/741_HE.png',\n",
       "   'ROI/New/742_HE.png',\n",
       "   'ROI/New/745_HE.png',\n",
       "   'ROI/New/746_HE.png',\n",
       "   'ROI/New/750_HE.png',\n",
       "   'ROI/New/753_HE.png',\n",
       "   'ROI/New/754_HE.png',\n",
       "   'ROI/New/755_HE.png',\n",
       "   'ROI/New/756_HE.png',\n",
       "   'ROI/New/758_HE.png',\n",
       "   'ROI/New/759_HE.png',\n",
       "   'ROI/New/760_HE.png',\n",
       "   'ROI/New/761_HE.png',\n",
       "   'ROI/New/762_HE.png',\n",
       "   'ROI/New/763_HE.png',\n",
       "   'ROI/New/765_HE.png',\n",
       "   'ROI/New/766_HE.png',\n",
       "   'ROI/New/767_HE.png',\n",
       "   'ROI/New/768_HE.png',\n",
       "   'ROI/New/770_HE.png',\n",
       "   'ROI/New/771_HE.png',\n",
       "   'ROI/New/772_HE.png',\n",
       "   'ROI/New/774_HE.png',\n",
       "   'ROI/New/776_HE.png',\n",
       "   'ROI/New/779_HE.png',\n",
       "   'ROI/New/781_HE.png',\n",
       "   'ROI/New/782_HE.png',\n",
       "   'ROI/New/783_HE.png',\n",
       "   'ROI/New/786_HE.png',\n",
       "   'ROI/New/787_HE.png',\n",
       "   'ROI/New/788_HE.png',\n",
       "   'ROI/New/789_HE.png',\n",
       "   'ROI/New/794_HE.png',\n",
       "   'ROI/New/795_HE.png',\n",
       "   'ROI/New/796_HE.png',\n",
       "   'ROI/New/798_HE.png',\n",
       "   'ROI/New/799_HE.png',\n",
       "   'ROI/New/800_HE.png',\n",
       "   'ROI/New/801_HE.png',\n",
       "   'ROI/New/803_HE.png',\n",
       "   'ROI/New/804_HE.png',\n",
       "   'ROI/New/808_HE.png',\n",
       "   'ROI/New/809_HE.png',\n",
       "   'ROI/New/810_HE.png',\n",
       "   'ROI/New/811_HE.png',\n",
       "   'ROI/New/812_HE.png',\n",
       "   'ROI/New/813_HE.png',\n",
       "   'ROI/New/814_HE.png',\n",
       "   'ROI/New/815_HE.png',\n",
       "   'ROI/New/816_HE.png',\n",
       "   'ROI/New/817_HE.png',\n",
       "   'ROI/New/819_HE.png',\n",
       "   'ROI/New/822_HE.png',\n",
       "   'ROI/New/823_HE.png',\n",
       "   'ROI/New/825_HE.png',\n",
       "   'ROI/New/826_HE.png',\n",
       "   'ROI/New/827_HE.png',\n",
       "   'ROI/New/828_HE.png',\n",
       "   'ROI/New/832_HE.png',\n",
       "   'ROI/New/833_HE.png',\n",
       "   'ROI/New/836_HE.png',\n",
       "   'ROI/New/837_HE.png',\n",
       "   'ROI/New/838_HE.png',\n",
       "   'ROI/New/841_HE.png',\n",
       "   'ROI/New/846_HE.png',\n",
       "   'ROI/New/847_HE.png',\n",
       "   'ROI/New/848_HE.png',\n",
       "   'ROI/New/849_HE.png',\n",
       "   'ROI/New/850_HE.png',\n",
       "   'ROI/New/851_HE.png',\n",
       "   'ROI/New/852_HE.png',\n",
       "   'ROI/New/855_HE.png',\n",
       "   'ROI/New/856_HE.png',\n",
       "   'ROI/New/857_HE.png',\n",
       "   'ROI/New/858_HE.png',\n",
       "   'ROI/New/859_HE.png',\n",
       "   'ROI/New/860_HE.png',\n",
       "   'ROI/New/862_HE.png',\n",
       "   'ROI/New/863_HE.png',\n",
       "   'ROI/New/864_HE.png',\n",
       "   'ROI/New/865_HE.png',\n",
       "   'ROI/New/866_HE.png',\n",
       "   'ROI/New/867_HE.png',\n",
       "   'ROI/New/868_HE.png',\n",
       "   'ROI/New/869_HE.png',\n",
       "   'ROI/New/870_HE.png',\n",
       "   'ROI/New/873_HE.png',\n",
       "   'ROI/New/874_HE.png',\n",
       "   'ROI/New/875_HE.png',\n",
       "   'ROI/New/876_HE.png',\n",
       "   'ROI/New/878_HE.png',\n",
       "   'ROI/New/879_HE.png',\n",
       "   'ROI/New/880_HE.png',\n",
       "   'ROI/New/881_HE.png',\n",
       "   'ROI/New/883_HE.png',\n",
       "   'ROI/New/884_HE.png',\n",
       "   'ROI/New/885_HE.png',\n",
       "   'ROI/New/886_HE.png',\n",
       "   'ROI/New/887_HE.png',\n",
       "   'ROI/New/892_HE.png',\n",
       "   'ROI/New/893_HE.png',\n",
       "   'ROI/New/896_HE.png',\n",
       "   'ROI/New/897_HE.png',\n",
       "   'ROI/New/899_HE.png',\n",
       "   'ROI/New/900_HE.png',\n",
       "   'ROI/New/903_HE.png',\n",
       "   'ROI/New/904_HE.png',\n",
       "   'ROI/New/905_HE.png',\n",
       "   'ROI/New/906_HE.png',\n",
       "   'ROI/New/907_HE.png',\n",
       "   'ROI/New/909_HE.png',\n",
       "   'ROI/New/911_HE.png',\n",
       "   'ROI/New/912_HE.png',\n",
       "   'ROI/New/914_HE.png',\n",
       "   'ROI/New/918_HE.png',\n",
       "   'ROI/New/919_HE.png',\n",
       "   'ROI/New/922_HE.png',\n",
       "   'ROI/New/923_HE.png',\n",
       "   'ROI/New/927_HE.png',\n",
       "   'ROI/New/928_HE.png',\n",
       "   'ROI/New/929_HE.png',\n",
       "   'ROI/New/930_HE.png',\n",
       "   'ROI/New/931_HE.png',\n",
       "   'ROI/New/932_HE.png',\n",
       "   'ROI/New/934_HE.png',\n",
       "   'ROI/New/936_HE.png',\n",
       "   'ROI/New/939_HE.png',\n",
       "   'ROI/New/940_HE.png',\n",
       "   'ROI/New/941_HE.png',\n",
       "   'ROI/New/942_HE.png',\n",
       "   'ROI/New/943_HE.png',\n",
       "   'ROI/New/944_HE.png',\n",
       "   'ROI/New/948_HE.png',\n",
       "   'ROI/New/949_HE.png',\n",
       "   'ROI/New/951_HE.png',\n",
       "   'ROI/New/952_HE.png',\n",
       "   'ROI/New/954_HE.png',\n",
       "   'ROI/New/957_HE.png',\n",
       "   'ROI/New/959_HE.png',\n",
       "   'ROI/New/960_HE.png',\n",
       "   'ROI/New/961_HE.png',\n",
       "   'ROI/New/962_HE.png',\n",
       "   'ROI/New/963_HE.png',\n",
       "   'ROI/New/964_HE.png',\n",
       "   'ROI/New/968_HE.png',\n",
       "   'ROI/New/969_HE.png',\n",
       "   'ROI/New/970_HE.png',\n",
       "   'ROI/New/971_HE.png',\n",
       "   'ROI/New/972_HE.png',\n",
       "   'ROI/New/975_HE.png',\n",
       "   'ROI/New/976_HE.png',\n",
       "   'ROI/New/978_HE.png',\n",
       "   'ROI/New/979_HE.png',\n",
       "   'ROI/New/980_HE.png',\n",
       "   'ROI/New/981_HE.png',\n",
       "   'ROI/New/982_HE.png',\n",
       "   'ROI/New/985_HE.png',\n",
       "   'ROI/New/986_HE.png',\n",
       "   'ROI/New/987_HE.png',\n",
       "   'ROI/New/989_HE.png',\n",
       "   'ROI/New/990_HE.png',\n",
       "   'ROI/New/992_HE.png',\n",
       "   'ROI/New/994_HE.png',\n",
       "   'ROI/New/995_HE.png',\n",
       "   'ROI/New/996_HE.png',\n",
       "   'ROI/New/997_HE.png',\n",
       "   'ROI/New/998_HE.png',\n",
       "   'ROI/New/999_HE.png',\n",
       "   'ROI/New/1002_HE.png',\n",
       "   'ROI/New/1003_HE.png',\n",
       "   'ROI/New/1004_HE.png',\n",
       "   'ROI/New/1006_HE.png',\n",
       "   'ROI/New/1007_HE.png',\n",
       "   'ROI/New/1008_HE.png',\n",
       "   'ROI/New/1012_HE.png',\n",
       "   'ROI/New/1014_HE.png',\n",
       "   'ROI/New/1015_HE.png',\n",
       "   'ROI/New/1018_HE.png',\n",
       "   'ROI/New/1024_HE.png',\n",
       "   'ROI/New/1025_HE.png',\n",
       "   'ROI/New/1026_HE.png',\n",
       "   'ROI/New/1028_HE.png',\n",
       "   'ROI/New/1029_HE.png',\n",
       "   'ROI/New/1031_HE.png',\n",
       "   'ROI/New/1032_HE.png',\n",
       "   'ROI/New/1033_HE.png',\n",
       "   'ROI/New/1036_HE.png',\n",
       "   'ROI/New/1037_HE.png',\n",
       "   'ROI/New/1040_HE.png',\n",
       "   'ROI/New/1044_HE.png',\n",
       "   'ROI/New/1045_HE.png',\n",
       "   'ROI/New/1046_HE.png',\n",
       "   'ROI/New/1047_HE.png',\n",
       "   'ROI/New/1048_HE.png',\n",
       "   'ROI/New/1049_HE.png',\n",
       "   'ROI/New/1056_HE.png',\n",
       "   'ROI/New/1058_HE.png',\n",
       "   'ROI/New/1061_HE.png',\n",
       "   'ROI/New/1062_HE.png',\n",
       "   'ROI/New/1063_HE.png',\n",
       "   'ROI/New/1065_HE.png',\n",
       "   'ROI/New/1066_HE.png',\n",
       "   'ROI/New/1067_HE.png',\n",
       "   'ROI/New/1069_HE.png',\n",
       "   'ROI/New/1072_HE.png',\n",
       "   'ROI/New/1073_HE.png',\n",
       "   'ROI/New/1074_HE.png',\n",
       "   'ROI/New/1076_HE.png',\n",
       "   'ROI/New/1078_HE.png',\n",
       "   'ROI/New/1079_HE.png',\n",
       "   'ROI/New/1081_HE.png',\n",
       "   'ROI/New/1082_HE.png',\n",
       "   'ROI/New/1083_HE.png',\n",
       "   'ROI/New/1087_HE.png',\n",
       "   'ROI/New/1088_HE.png',\n",
       "   'ROI/New/1089_HE.png',\n",
       "   'ROI/New/1096_HE.png',\n",
       "   'ROI/New/1097_HE.png',\n",
       "   'ROI/New/1098_HE.png',\n",
       "   'ROI/New/1099_HE.png',\n",
       "   'ROI/New/1100_HE.png',\n",
       "   'ROI/New/1103_HE.png',\n",
       "   'ROI/New/1104_HE.png',\n",
       "   'ROI/New/1106_HE.png',\n",
       "   'ROI/New/1107_HE.png',\n",
       "   'ROI/New/1111_HE.png',\n",
       "   'ROI/New/1112_HE.png',\n",
       "   'ROI/New/1114_HE.png',\n",
       "   'ROI/New/1115_HE.png',\n",
       "   'ROI/New/1117_HE.png',\n",
       "   'ROI/New/1122_HE.png',\n",
       "   'ROI/New/1123_HE.png',\n",
       "   'ROI/New/1124_HE.png',\n",
       "   'ROI/New/1126_HE.png',\n",
       "   'ROI/New/1127_HE.png',\n",
       "   'ROI/New/1128_HE.png',\n",
       "   'ROI/New/1129_HE.png',\n",
       "   'ROI/New/1130_HE.png',\n",
       "   'ROI/New/1131_HE.png',\n",
       "   'ROI/New/1132_HE.png',\n",
       "   'ROI/New/1135_HE.png',\n",
       "   'ROI/New/1136_HE.png',\n",
       "   'ROI/New/1141_HE.png',\n",
       "   'ROI/New/1143_HE.png',\n",
       "   'ROI/New/1144_HE.png',\n",
       "   'ROI/New/1145_HE.png',\n",
       "   'ROI/New/1146_HE.png',\n",
       "   'ROI/New/1150_HE.png',\n",
       "   'ROI/New/1152_HE.png',\n",
       "   'ROI/New/1156_HE.png',\n",
       "   'ROI/New/1157_HE.png',\n",
       "   'ROI/New/1159_HE.png',\n",
       "   'ROI/New/1163_HE.png',\n",
       "   'ROI/New/1164_HE.png',\n",
       "   'ROI/New/1165_HE.png',\n",
       "   'ROI/New/1167_HE.png',\n",
       "   'ROI/New/1168_HE.png',\n",
       "   'ROI/New/1169_HE.png',\n",
       "   'ROI/New/1170_HE.png',\n",
       "   'ROI/New/1171_HE.png',\n",
       "   'ROI/New/1172_HE.png',\n",
       "   'ROI/New/1173_HE.png',\n",
       "   'ROI/New/1174_HE.png',\n",
       "   'ROI/New/1175_HE.png',\n",
       "   'ROI/New/1176_HE.png',\n",
       "   'ROI/New/1177_HE.png',\n",
       "   'ROI/New/1180_HE.png',\n",
       "   'ROI/New/1181_HE.png',\n",
       "   'ROI/New/1183_HE.png',\n",
       "   'ROI/New/1184_HE.png',\n",
       "   'ROI/New/1187_HE.png',\n",
       "   'ROI/New/1188_HE.png',\n",
       "   'ROI/New/1189_HE.png',\n",
       "   'ROI/New/1190_HE.png',\n",
       "   'ROI/New/1191_HE.png',\n",
       "   'ROI/New/1193_HE.png',\n",
       "   'ROI/New/150000_HE.png',\n",
       "   'ROI/New/210000_HE.png',\n",
       "   'ROI/New/280000_HE.png',\n",
       "   'ROI/New/290000_HE.png',\n",
       "   'ROI/New/410000_HE.png',\n",
       "   'ROI/New/1520000_HE.png',\n",
       "   'ROI/New/1600000_HE.png',\n",
       "   'ROI/New/1660000_HE.png',\n",
       "   'ROI/New/1670000_HE.png',\n",
       "   'ROI/New/1950000_HE.png',\n",
       "   'ROI/New/2020000_HE.png',\n",
       "   'ROI/New/2110000_HE.png',\n",
       "   'ROI/New/2190000_HE.png',\n",
       "   'ROI/New/2300000_HE.png',\n",
       "   'ROI/New/2370000_HE.png',\n",
       "   'ROI/New/2450000_HE.png',\n",
       "   'ROI/New/20200000_HE.png',\n",
       "   'ROI/New/201610000_HE.png',\n",
       "   'ROI/New/201680000_HE.png',\n",
       "   'ROI/New/201690000_HE.png',\n",
       "   'ROI/New/201710000_HE.png',\n",
       "   'ROI/New/201720000_HE.png',\n",
       "   'ROI/New/201730000_HE.png',\n",
       "   'ROI/New/201740000_HE.png',\n",
       "   'ROI/New/201750000_HE.png',\n",
       "   'ROI/New/201760000_HE.png',\n",
       "   'ROI/New/201770000_HE.png',\n",
       "   'ROI/New/201780000_HE.png',\n",
       "   'ROI/New/201790000_HE.png',\n",
       "   'ROI/New/201810000_HE.png',\n",
       "   'ROI/New/201820000_HE.png',\n",
       "   'ROI/New/201830000_HE.png',\n",
       "   'ROI/New/201850000_HE.png',\n",
       "   'ROI/New/201860000_HE.png',\n",
       "   'ROI/New/201870000_HE.png',\n",
       "   'ROI/New/201880000_HE.png',\n",
       "   'ROI/New/201910000_HE.png',\n",
       "   'ROI/New/201940000_HE.png',\n",
       "   'ROI/New/201950000_HE.png',\n",
       "   'ROI/New/201960000_HE.png',\n",
       "   'ROI/New/201970000_HE.png',\n",
       "   'ROI/New/201990000_HE.png',\n",
       "   'ROI/New/202010000_HE.png',\n",
       "   'ROI/New/202030000_HE.png',\n",
       "   'ROI/New/202040000_HE.png',\n",
       "   'ROI/New/202210000_HE.png',\n",
       "   'ROI/New/202220000_HE.png',\n",
       "   'ROI/New/202240000_HE.png',\n",
       "   'ROI/New/202250000_HE.png',\n",
       "   'ROI/New/202270000_HE.png',\n",
       "   'ROI/New/202280000_HE.png',\n",
       "   'ROI/New/2016110000_HE.png',\n",
       "   'ROI/New/2017120000_HE.png',\n",
       "   'ROI/New/2017130000_HE.png',\n",
       "   'ROI/New/2017140000_HE.png',\n",
       "   'ROI/New/2017150000_HE.png',\n",
       "   'ROI/New/2017170000_HE.png',\n",
       "   'ROI/New/2018100000_HE.png',\n",
       "   'ROI/New/2018120000_HE.png',\n",
       "   'ROI/New/2018130000_HE.png',\n",
       "   'ROI/New/2018140000_HE.png',\n",
       "   'ROI/New/2018150000_HE.png',\n",
       "   'ROI/New/2018160000_HE.png',\n",
       "   'ROI/New/2019100000_HE.png',\n",
       "   'ROI/New/2019110000_HE.png',\n",
       "   'ROI/New/2019120000_HE.png',\n",
       "   'ROI/New/2019130000_HE.png',\n",
       "   'ROI/New/2019140000_HE.png',\n",
       "   'ROI/New/2019150000_HE.png',\n",
       "   'ROI/New/2019160000_HE.png',\n",
       "   'ROI/New/2019170000_HE.png',\n",
       "   'ROI/New/2019190000_HE.png',\n",
       "   'ROI/New/2022100000_HE.png',\n",
       "   'ROI/New/2022120000_HE.png',\n",
       "   'ROI/New/2022150000_HE.png',\n",
       "   'ROI/New/2022170000_HE.png',\n",
       "   'ROI/New/2022200000_HE.png',\n",
       "   'ROI/New/2022210000_HE.png',\n",
       "   'ROI/New/2022220000_HE.png',\n",
       "   'ROI/New/2022230000_HE.png',\n",
       "   'ROI/New/2022240000_HE.png',\n",
       "   'ROI/New/1_HE.png',\n",
       "   'ROI/New/2_HE.png',\n",
       "   'ROI/New/3_HE.png',\n",
       "   'ROI/New/5_HE.png',\n",
       "   'ROI/New/9_HE.png',\n",
       "   'ROI/New/10_HE.png',\n",
       "   'ROI/New/12_HE.png',\n",
       "   'ROI/New/13_HE.png',\n",
       "   'ROI/New/14_HE.png',\n",
       "   'ROI/New/15_HE.png',\n",
       "   'ROI/New/16_HE.png',\n",
       "   'ROI/New/17_HE.png',\n",
       "   'ROI/New/18_HE.png',\n",
       "   'ROI/New/20_HE.png',\n",
       "   'ROI/New/21_HE.png',\n",
       "   'ROI/New/22_HE.png',\n",
       "   'ROI/New/23_HE.png',\n",
       "   'ROI/New/25_HE.png',\n",
       "   'ROI/New/26_HE.png',\n",
       "   'ROI/New/27_HE.png',\n",
       "   'ROI/New/28_HE.png',\n",
       "   'ROI/New/29_HE.png',\n",
       "   'ROI/New/33_HE.png',\n",
       "   'ROI/New/34_HE.png',\n",
       "   'ROI/New/37_HE.png',\n",
       "   'ROI/New/40_HE.png',\n",
       "   'ROI/New/41_HE.png',\n",
       "   'ROI/New/43_HE.png',\n",
       "   'ROI/New/45_HE.png',\n",
       "   'ROI/New/47_HE.png',\n",
       "   'ROI/New/48_HE.png',\n",
       "   'ROI/New/50_HE.png',\n",
       "   'ROI/New/54_HE.png',\n",
       "   'ROI/New/55_HE.png',\n",
       "   'ROI/New/57_HE.png',\n",
       "   'ROI/New/58_HE.png',\n",
       "   'ROI/New/59_HE.png',\n",
       "   'ROI/New/60_HE.png',\n",
       "   'ROI/New/62_HE.png',\n",
       "   'ROI/New/63_HE.png',\n",
       "   'ROI/New/64_HE.png',\n",
       "   'ROI/New/65_HE.png',\n",
       "   'ROI/New/66_HE.png',\n",
       "   'ROI/New/68_HE.png',\n",
       "   'ROI/New/69_HE.png',\n",
       "   'ROI/New/70_HE.png',\n",
       "   'ROI/New/71_HE.png',\n",
       "   'ROI/New/72_HE.png',\n",
       "   'ROI/New/73_HE.png',\n",
       "   'ROI/New/74_HE.png',\n",
       "   'ROI/New/76_HE.png',\n",
       "   'ROI/New/77_HE.png',\n",
       "   'ROI/New/78_HE.png',\n",
       "   'ROI/New/79_HE.png',\n",
       "   'ROI/New/81_HE.png',\n",
       "   'ROI/New/82_HE.png',\n",
       "   'ROI/New/84_HE.png',\n",
       "   'ROI/New/85_HE.png',\n",
       "   'ROI/New/86_HE.png',\n",
       "   'ROI/New/87_HE.png',\n",
       "   'ROI/New/88_HE.png',\n",
       "   'ROI/New/90_HE.png',\n",
       "   'ROI/New/91_HE.png',\n",
       "   'ROI/New/92_HE.png',\n",
       "   'ROI/New/93_HE.png',\n",
       "   'ROI/New/94_HE.png',\n",
       "   'ROI/New/95_HE.png',\n",
       "   'ROI/New/96_HE.png',\n",
       "   'ROI/New/99_HE.png',\n",
       "   'ROI/New/100_HE.png',\n",
       "   'ROI/New/101_HE.png',\n",
       "   'ROI/New/102_HE.png',\n",
       "   'ROI/New/103_HE.png',\n",
       "   'ROI/New/104_HE.png',\n",
       "   'ROI/New/105_HE.png',\n",
       "   'ROI/New/106_HE.png',\n",
       "   'ROI/New/108_HE.png',\n",
       "   'ROI/New/109_HE.png',\n",
       "   'ROI/New/110_HE.png',\n",
       "   'ROI/New/111_HE.png',\n",
       "   'ROI/New/112_HE.png',\n",
       "   'ROI/New/113_HE.png',\n",
       "   'ROI/New/114_HE.png',\n",
       "   'ROI/New/115_HE.png',\n",
       "   'ROI/New/116_HE.png',\n",
       "   'ROI/New/120_HE.png',\n",
       "   'ROI/New/121_HE.png',\n",
       "   'ROI/New/122_HE.png',\n",
       "   'ROI/New/125_HE.png',\n",
       "   'ROI/New/126_HE.png',\n",
       "   'ROI/New/127_HE.png',\n",
       "   'ROI/New/130_HE.png',\n",
       "   'ROI/New/132_HE.png',\n",
       "   'ROI/New/133_HE.png',\n",
       "   'ROI/New/134_HE.png',\n",
       "   'ROI/New/137_HE.png',\n",
       "   'ROI/New/139_HE.png',\n",
       "   'ROI/New/140_HE.png',\n",
       "   'ROI/New/141_HE.png',\n",
       "   'ROI/New/144_HE.png',\n",
       "   'ROI/New/145_HE.png',\n",
       "   'ROI/New/146_HE.png',\n",
       "   'ROI/New/148_HE.png',\n",
       "   'ROI/New/150_HE.png',\n",
       "   'ROI/New/151_HE.png',\n",
       "   'ROI/New/152_HE.png',\n",
       "   'ROI/New/153_HE.png',\n",
       "   'ROI/New/155_HE.png',\n",
       "   'ROI/New/157_HE.png',\n",
       "   'ROI/New/158_HE.png',\n",
       "   'ROI/New/159_HE.png',\n",
       "   'ROI/New/160_HE.png',\n",
       "   'ROI/New/161_HE.png',\n",
       "   'ROI/New/162_HE.png',\n",
       "   'ROI/New/163_HE.png',\n",
       "   'ROI/New/164_HE.png',\n",
       "   'ROI/New/166_HE.png',\n",
       "   'ROI/New/167_HE.png',\n",
       "   'ROI/New/168_HE.png',\n",
       "   'ROI/New/170_HE.png',\n",
       "   'ROI/New/171_HE.png',\n",
       "   'ROI/New/172_HE.png',\n",
       "   'ROI/New/173_HE.png',\n",
       "   'ROI/New/175_HE.png',\n",
       "   'ROI/New/176_HE.png',\n",
       "   'ROI/New/177_HE.png',\n",
       "   'ROI/New/178_HE.png',\n",
       "   'ROI/New/180_HE.png',\n",
       "   'ROI/New/181_HE.png',\n",
       "   'ROI/New/182_HE.png',\n",
       "   'ROI/New/183_HE.png',\n",
       "   'ROI/New/184_HE.png',\n",
       "   'ROI/New/185_HE.png',\n",
       "   'ROI/New/186_HE.png',\n",
       "   'ROI/New/187_HE.png',\n",
       "   'ROI/New/188_HE.png',\n",
       "   'ROI/New/189_HE.png',\n",
       "   'ROI/New/190_HE.png',\n",
       "   'ROI/New/192_HE.png',\n",
       "   'ROI/New/193_HE.png',\n",
       "   'ROI/New/194_HE.png',\n",
       "   'ROI/New/195_HE.png',\n",
       "   'ROI/New/197_HE.png',\n",
       "   'ROI/New/198_HE.png',\n",
       "   'ROI/New/200_HE.png',\n",
       "   'ROI/New/201_HE.png',\n",
       "   'ROI/New/203_HE.png',\n",
       "   'ROI/New/204_HE.png',\n",
       "   'ROI/New/205_HE.png',\n",
       "   'ROI/New/206_HE.png',\n",
       "   'ROI/New/207_HE.png',\n",
       "   'ROI/New/209_HE.png',\n",
       "   'ROI/New/212_HE.png',\n",
       "   'ROI/New/213_HE.png',\n",
       "   'ROI/New/214_HE.png',\n",
       "   'ROI/New/215_HE.png',\n",
       "   'ROI/New/216_HE.png',\n",
       "   'ROI/New/218_HE.png',\n",
       "   'ROI/New/220_HE.png',\n",
       "   'ROI/New/222_HE.png',\n",
       "   'ROI/New/224_HE.png',\n",
       "   'ROI/New/227_HE.png',\n",
       "   'ROI/New/229_HE.png',\n",
       "   'ROI/New/230_HE.png',\n",
       "   'ROI/New/233_HE.png',\n",
       "   'ROI/New/235_HE.png',\n",
       "   'ROI/New/236_HE.png',\n",
       "   'ROI/New/244_HE.png',\n",
       "   'ROI/New/245_HE.png',\n",
       "   'ROI/New/247_HE.png',\n",
       "   'ROI/New/249_HE.png',\n",
       "   'ROI/New/250_HE.png',\n",
       "   'ROI/New/253_HE.png',\n",
       "   'ROI/New/256_HE.png',\n",
       "   'ROI/New/257_HE.png',\n",
       "   'ROI/New/260_HE.png',\n",
       "   'ROI/New/267_HE.png',\n",
       "   'ROI/New/270_HE.png',\n",
       "   'ROI/New/271_HE.png',\n",
       "   'ROI/New/272_HE.png',\n",
       "   'ROI/New/278_HE.png',\n",
       "   'ROI/New/279_HE.png',\n",
       "   'ROI/New/280_HE.png',\n",
       "   'ROI/New/281_HE.png',\n",
       "   'ROI/New/283_HE.png',\n",
       "   'ROI/New/287_HE.png',\n",
       "   'ROI/New/289_HE.png',\n",
       "   'ROI/New/290_HE.png',\n",
       "   'ROI/New/292_HE.png',\n",
       "   'ROI/New/293_HE.png',\n",
       "   'ROI/New/294_HE.png',\n",
       "   'ROI/New/295_HE.png',\n",
       "   'ROI/New/296_HE.png',\n",
       "   'ROI/New/298_HE.png',\n",
       "   'ROI/New/299_HE.png',\n",
       "   'ROI/New/300_HE.png',\n",
       "   'ROI/New/302_HE.png',\n",
       "   'ROI/New/304_HE.png',\n",
       "   'ROI/New/305_HE.png',\n",
       "   'ROI/New/307_HE.png',\n",
       "   'ROI/New/308_HE.png',\n",
       "   'ROI/New/309_HE.png',\n",
       "   'ROI/New/314_HE.png',\n",
       "   'ROI/New/315_HE.png',\n",
       "   'ROI/New/316_HE.png',\n",
       "   'ROI/New/317_HE.png',\n",
       "   'ROI/New/318_HE.png',\n",
       "   'ROI/New/320_HE.png',\n",
       "   'ROI/New/321_HE.png',\n",
       "   'ROI/New/324_HE.png',\n",
       "   'ROI/New/327_HE.png',\n",
       "   'ROI/New/329_HE.png',\n",
       "   'ROI/New/332_HE.png',\n",
       "   'ROI/New/337_HE.png',\n",
       "   'ROI/New/340_HE.png',\n",
       "   'ROI/New/341_HE.png',\n",
       "   'ROI/New/342_HE.png',\n",
       "   'ROI/New/343_HE.png',\n",
       "   'ROI/New/346_HE.png',\n",
       "   'ROI/New/347_HE.png',\n",
       "   'ROI/New/348_HE.png',\n",
       "   'ROI/New/350_HE.png',\n",
       "   'ROI/New/351_HE.png',\n",
       "   'ROI/New/352_HE.png',\n",
       "   'ROI/New/356_HE.png',\n",
       "   'ROI/New/358_HE.png',\n",
       "   'ROI/New/360_HE.png',\n",
       "   'ROI/New/361_HE.png',\n",
       "   'ROI/New/363_HE.png',\n",
       "   'ROI/New/364_HE.png',\n",
       "   'ROI/New/365_HE.png',\n",
       "   'ROI/New/366_HE.png',\n",
       "   'ROI/New/368_HE.png',\n",
       "   'ROI/New/371_HE.png',\n",
       "   'ROI/New/374_HE.png',\n",
       "   'ROI/New/375_HE.png',\n",
       "   'ROI/New/376_HE.png',\n",
       "   'ROI/New/377_HE.png',\n",
       "   'ROI/New/379_HE.png',\n",
       "   'ROI/New/381_HE.png',\n",
       "   'ROI/New/382_HE.png',\n",
       "   'ROI/New/383_HE.png',\n",
       "   'ROI/New/385_HE.png',\n",
       "   'ROI/New/386_HE.png',\n",
       "   'ROI/New/387_HE.png',\n",
       "   'ROI/New/388_HE.png',\n",
       "   'ROI/New/390_HE.png',\n",
       "   'ROI/New/391_HE.png',\n",
       "   'ROI/New/392_HE.png',\n",
       "   'ROI/New/395_HE.png',\n",
       "   'ROI/New/396_HE.png',\n",
       "   'ROI/New/399_HE.png',\n",
       "   'ROI/New/400_HE.png',\n",
       "   'ROI/New/406_HE.png',\n",
       "   'ROI/New/407_HE.png',\n",
       "   'ROI/New/409_HE.png',\n",
       "   'ROI/New/410_HE.png',\n",
       "   'ROI/New/411_HE.png',\n",
       "   'ROI/New/412_HE.png',\n",
       "   'ROI/New/413_HE.png',\n",
       "   'ROI/New/415_HE.png',\n",
       "   'ROI/New/417_HE.png',\n",
       "   'ROI/New/418_HE.png',\n",
       "   'ROI/New/419_HE.png',\n",
       "   'ROI/New/421_HE.png',\n",
       "   'ROI/New/423_HE.png',\n",
       "   'ROI/New/424_HE.png',\n",
       "   'ROI/New/425_HE.png',\n",
       "   'ROI/New/426_HE.png',\n",
       "   'ROI/New/428_HE.png',\n",
       "   'ROI/New/429_HE.png',\n",
       "   'ROI/New/430_HE.png',\n",
       "   'ROI/New/432_HE.png',\n",
       "   'ROI/New/433_HE.png',\n",
       "   'ROI/New/436_HE.png',\n",
       "   'ROI/New/437_HE.png',\n",
       "   'ROI/New/439_HE.png',\n",
       "   'ROI/New/440_HE.png',\n",
       "   'ROI/New/441_HE.png',\n",
       "   'ROI/New/445_HE.png',\n",
       "   'ROI/New/447_HE.png',\n",
       "   'ROI/New/449_HE.png',\n",
       "   'ROI/New/450_HE.png',\n",
       "   'ROI/New/451_HE.png',\n",
       "   'ROI/New/453_HE.png',\n",
       "   'ROI/New/454_HE.png',\n",
       "   'ROI/New/455_HE.png',\n",
       "   'ROI/New/457_HE.png',\n",
       "   'ROI/New/458_HE.png',\n",
       "   'ROI/New/460_HE.png',\n",
       "   'ROI/New/462_HE.png',\n",
       "   'ROI/New/463_HE.png',\n",
       "   'ROI/New/465_HE.png',\n",
       "   'ROI/New/466_HE.png',\n",
       "   'ROI/New/467_HE.png',\n",
       "   'ROI/New/470_HE.png',\n",
       "   'ROI/New/472_HE.png',\n",
       "   'ROI/New/474_HE.png',\n",
       "   'ROI/New/475_HE.png',\n",
       "   'ROI/New/476_HE.png',\n",
       "   'ROI/New/477_HE.png',\n",
       "   'ROI/New/478_HE.png',\n",
       "   'ROI/New/479_HE.png',\n",
       "   'ROI/New/480_HE.png',\n",
       "   'ROI/New/481_HE.png',\n",
       "   'ROI/New/482_HE.png',\n",
       "   'ROI/New/484_HE.png',\n",
       "   'ROI/New/485_HE.png',\n",
       "   'ROI/New/487_HE.png',\n",
       "   'ROI/New/488_HE.png',\n",
       "   'ROI/New/489_HE.png',\n",
       "   'ROI/New/490_HE.png',\n",
       "   'ROI/New/491_HE.png',\n",
       "   'ROI/New/492_HE.png',\n",
       "   'ROI/New/493_HE.png',\n",
       "   'ROI/New/494_HE.png',\n",
       "   'ROI/New/495_HE.png',\n",
       "   'ROI/New/496_HE.png',\n",
       "   'ROI/New/497_HE.png',\n",
       "   'ROI/New/500_HE.png',\n",
       "   'ROI/New/501_HE.png',\n",
       "   'ROI/New/502_HE.png',\n",
       "   'ROI/New/503_HE.png',\n",
       "   'ROI/New/505_HE.png',\n",
       "   'ROI/New/506_HE.png',\n",
       "   'ROI/New/510_HE.png',\n",
       "   'ROI/New/512_HE.png',\n",
       "   'ROI/New/517_HE.png',\n",
       "   'ROI/New/518_HE.png',\n",
       "   'ROI/New/519_HE.png',\n",
       "   'ROI/New/520_HE.png',\n",
       "   'ROI/New/521_HE.png',\n",
       "   'ROI/New/522_HE.png',\n",
       "   'ROI/New/524_HE.png',\n",
       "   'ROI/New/525_HE.png',\n",
       "   'ROI/New/534_HE.png',\n",
       "   'ROI/New/535_HE.png',\n",
       "   'ROI/New/536_HE.png',\n",
       "   'ROI/New/538_HE.png',\n",
       "   'ROI/New/539_HE.png',\n",
       "   'ROI/New/540_HE.png',\n",
       "   'ROI/New/541_HE.png'],\n",
       "  ['ROI/New/248_HE.png',\n",
       "   'ROI/New/191_HE.png',\n",
       "   'ROI/New/650_HE.png',\n",
       "   'ROI/New/228_HE.png',\n",
       "   'ROI/New/225_HE.png',\n",
       "   'ROI/New/268_HE.png',\n",
       "   'ROI/New/275_HE.png',\n",
       "   'ROI/New/35_HE.png',\n",
       "   'ROI/New/31_HE.png',\n",
       "   'ROI/New/80_HE.png',\n",
       "   'ROI/New/730000_HE.png',\n",
       "   'ROI/New/2270000_HE.png',\n",
       "   'ROI/New/2290000_HE.png',\n",
       "   'ROI/New/360000_HE.png',\n",
       "   'ROI/New/1040000_HE.png',\n",
       "   'ROI/New/330000_HE.png',\n",
       "   'ROI/New/1320000_HE.png',\n",
       "   'ROI/New/820000_HE.png',\n",
       "   'ROI/New/2022160000_HE.png',\n",
       "   'ROI/New/2230000_HE.png',\n",
       "   'ROI/New/490000_HE.png',\n",
       "   'ROI/New/1470000_HE.png',\n",
       "   'ROI/New/650000_HE.png',\n",
       "   'ROI/New/2220000_HE.png',\n",
       "   'ROI/New/970000_HE.png',\n",
       "   'ROI/New/530000_HE.png',\n",
       "   'ROI/New/2022140000_HE.png',\n",
       "   'ROI/New/640000_HE.png',\n",
       "   'ROI/New/1060000_HE.png',\n",
       "   'ROI/New/110000_HE.png',\n",
       "   'ROI/New/840000_HE.png',\n",
       "   'ROI/New/1650000_HE.png',\n",
       "   'ROI/New/14700000_HE.png',\n",
       "   'ROI/New/630000_HE.png',\n",
       "   'ROI/New/546_HE.png',\n",
       "   'ROI/New/553_HE.png',\n",
       "   'ROI/New/554_HE.png',\n",
       "   'ROI/New/558_HE.png',\n",
       "   'ROI/New/559_HE.png',\n",
       "   'ROI/New/562_HE.png',\n",
       "   'ROI/New/567_HE.png',\n",
       "   'ROI/New/574_HE.png',\n",
       "   'ROI/New/583_HE.png',\n",
       "   'ROI/New/586_HE.png',\n",
       "   'ROI/New/589_HE.png',\n",
       "   'ROI/New/592_HE.png',\n",
       "   'ROI/New/611_HE.png',\n",
       "   'ROI/New/617_HE.png',\n",
       "   'ROI/New/623_HE.png',\n",
       "   'ROI/New/629_HE.png',\n",
       "   'ROI/New/633_HE.png',\n",
       "   'ROI/New/637_HE.png',\n",
       "   'ROI/New/638_HE.png',\n",
       "   'ROI/New/643_HE.png',\n",
       "   'ROI/New/651_HE.png',\n",
       "   'ROI/New/652_HE.png',\n",
       "   'ROI/New/654_HE.png',\n",
       "   'ROI/New/656_HE.png',\n",
       "   'ROI/New/682_HE.png',\n",
       "   'ROI/New/690_HE.png',\n",
       "   'ROI/New/694_HE.png',\n",
       "   'ROI/New/702_HE.png',\n",
       "   'ROI/New/705_HE.png',\n",
       "   'ROI/New/717_HE.png',\n",
       "   'ROI/New/728_HE.png',\n",
       "   'ROI/New/731_HE.png',\n",
       "   'ROI/New/734_HE.png',\n",
       "   'ROI/New/737_HE.png',\n",
       "   'ROI/New/743_HE.png',\n",
       "   'ROI/New/747_HE.png',\n",
       "   'ROI/New/749_HE.png',\n",
       "   'ROI/New/757_HE.png',\n",
       "   'ROI/New/764_HE.png',\n",
       "   'ROI/New/769_HE.png',\n",
       "   'ROI/New/777_HE.png',\n",
       "   'ROI/New/778_HE.png',\n",
       "   'ROI/New/785_HE.png',\n",
       "   'ROI/New/792_HE.png',\n",
       "   'ROI/New/793_HE.png',\n",
       "   'ROI/New/818_HE.png',\n",
       "   'ROI/New/820_HE.png',\n",
       "   'ROI/New/824_HE.png',\n",
       "   'ROI/New/829_HE.png',\n",
       "   'ROI/New/830_HE.png',\n",
       "   'ROI/New/842_HE.png',\n",
       "   'ROI/New/854_HE.png',\n",
       "   'ROI/New/872_HE.png',\n",
       "   'ROI/New/882_HE.png',\n",
       "   'ROI/New/888_HE.png',\n",
       "   'ROI/New/891_HE.png',\n",
       "   'ROI/New/910_HE.png',\n",
       "   'ROI/New/925_HE.png',\n",
       "   'ROI/New/933_HE.png',\n",
       "   'ROI/New/937_HE.png',\n",
       "   'ROI/New/938_HE.png',\n",
       "   'ROI/New/947_HE.png',\n",
       "   'ROI/New/950_HE.png',\n",
       "   'ROI/New/953_HE.png',\n",
       "   'ROI/New/966_HE.png',\n",
       "   'ROI/New/967_HE.png',\n",
       "   'ROI/New/973_HE.png',\n",
       "   'ROI/New/977_HE.png',\n",
       "   'ROI/New/984_HE.png',\n",
       "   'ROI/New/988_HE.png',\n",
       "   'ROI/New/991_HE.png',\n",
       "   'ROI/New/993_HE.png',\n",
       "   'ROI/New/1005_HE.png',\n",
       "   'ROI/New/1009_HE.png',\n",
       "   'ROI/New/1010_HE.png',\n",
       "   'ROI/New/1016_HE.png',\n",
       "   'ROI/New/1022_HE.png',\n",
       "   'ROI/New/1035_HE.png',\n",
       "   'ROI/New/1039_HE.png',\n",
       "   'ROI/New/1060_HE.png',\n",
       "   'ROI/New/1068_HE.png',\n",
       "   'ROI/New/1071_HE.png',\n",
       "   'ROI/New/1084_HE.png',\n",
       "   'ROI/New/1085_HE.png',\n",
       "   'ROI/New/1086_HE.png',\n",
       "   'ROI/New/1091_HE.png',\n",
       "   'ROI/New/1102_HE.png',\n",
       "   'ROI/New/1105_HE.png',\n",
       "   'ROI/New/1109_HE.png',\n",
       "   'ROI/New/1116_HE.png',\n",
       "   'ROI/New/1139_HE.png',\n",
       "   'ROI/New/1142_HE.png',\n",
       "   'ROI/New/1148_HE.png',\n",
       "   'ROI/New/1154_HE.png',\n",
       "   'ROI/New/1160_HE.png',\n",
       "   'ROI/New/1162_HE.png',\n",
       "   'ROI/New/1182_HE.png',\n",
       "   'ROI/New/1186_HE.png',\n",
       "   'ROI/New/1192_HE.png',\n",
       "   'ROI/New/160000_HE.png',\n",
       "   'ROI/New/1620000_HE.png',\n",
       "   'ROI/New/1970000_HE.png',\n",
       "   'ROI/New/2250000_HE.png',\n",
       "   'ROI/New/2340000_HE.png',\n",
       "   'ROI/New/201640000_HE.png',\n",
       "   'ROI/New/201670000_HE.png',\n",
       "   'ROI/New/201840000_HE.png',\n",
       "   'ROI/New/201890000_HE.png',\n",
       "   'ROI/New/201930000_HE.png',\n",
       "   'ROI/New/202230000_HE.png',\n",
       "   'ROI/New/202260000_HE.png',\n",
       "   'ROI/New/202290000_HE.png',\n",
       "   'ROI/New/2018170000_HE.png',\n",
       "   'ROI/New/2022130000_HE.png',\n",
       "   'ROI/New/2022180000_HE.png',\n",
       "   'ROI/New/4_HE.png',\n",
       "   'ROI/New/6_HE.png',\n",
       "   'ROI/New/11_HE.png',\n",
       "   'ROI/New/36_HE.png',\n",
       "   'ROI/New/39_HE.png',\n",
       "   'ROI/New/46_HE.png',\n",
       "   'ROI/New/49_HE.png',\n",
       "   'ROI/New/51_HE.png',\n",
       "   'ROI/New/52_HE.png',\n",
       "   'ROI/New/56_HE.png',\n",
       "   'ROI/New/97_HE.png',\n",
       "   'ROI/New/107_HE.png',\n",
       "   'ROI/New/118_HE.png',\n",
       "   'ROI/New/123_HE.png',\n",
       "   'ROI/New/129_HE.png',\n",
       "   'ROI/New/136_HE.png',\n",
       "   'ROI/New/138_HE.png',\n",
       "   'ROI/New/147_HE.png',\n",
       "   'ROI/New/156_HE.png',\n",
       "   'ROI/New/169_HE.png',\n",
       "   'ROI/New/174_HE.png',\n",
       "   'ROI/New/196_HE.png',\n",
       "   'ROI/New/199_HE.png',\n",
       "   'ROI/New/202_HE.png',\n",
       "   'ROI/New/208_HE.png',\n",
       "   'ROI/New/217_HE.png',\n",
       "   'ROI/New/221_HE.png',\n",
       "   'ROI/New/237_HE.png',\n",
       "   'ROI/New/238_HE.png',\n",
       "   'ROI/New/240_HE.png',\n",
       "   'ROI/New/251_HE.png',\n",
       "   'ROI/New/252_HE.png',\n",
       "   'ROI/New/255_HE.png',\n",
       "   'ROI/New/263_HE.png',\n",
       "   'ROI/New/264_HE.png',\n",
       "   'ROI/New/276_HE.png',\n",
       "   'ROI/New/277_HE.png',\n",
       "   'ROI/New/286_HE.png',\n",
       "   'ROI/New/301_HE.png',\n",
       "   'ROI/New/310_HE.png',\n",
       "   'ROI/New/311_HE.png',\n",
       "   'ROI/New/312_HE.png',\n",
       "   'ROI/New/313_HE.png',\n",
       "   'ROI/New/319_HE.png',\n",
       "   'ROI/New/322_HE.png',\n",
       "   'ROI/New/323_HE.png',\n",
       "   'ROI/New/325_HE.png',\n",
       "   'ROI/New/328_HE.png',\n",
       "   'ROI/New/333_HE.png',\n",
       "   'ROI/New/336_HE.png',\n",
       "   'ROI/New/344_HE.png',\n",
       "   'ROI/New/345_HE.png',\n",
       "   'ROI/New/355_HE.png',\n",
       "   'ROI/New/372_HE.png',\n",
       "   'ROI/New/380_HE.png',\n",
       "   'ROI/New/384_HE.png',\n",
       "   'ROI/New/394_HE.png',\n",
       "   'ROI/New/397_HE.png',\n",
       "   'ROI/New/401_HE.png',\n",
       "   'ROI/New/402_HE.png',\n",
       "   'ROI/New/403_HE.png',\n",
       "   'ROI/New/404_HE.png',\n",
       "   'ROI/New/414_HE.png',\n",
       "   'ROI/New/420_HE.png',\n",
       "   'ROI/New/427_HE.png',\n",
       "   'ROI/New/431_HE.png',\n",
       "   'ROI/New/435_HE.png',\n",
       "   'ROI/New/443_HE.png',\n",
       "   'ROI/New/444_HE.png',\n",
       "   'ROI/New/446_HE.png',\n",
       "   'ROI/New/448_HE.png',\n",
       "   'ROI/New/452_HE.png',\n",
       "   'ROI/New/459_HE.png',\n",
       "   'ROI/New/464_HE.png',\n",
       "   'ROI/New/469_HE.png',\n",
       "   'ROI/New/483_HE.png',\n",
       "   'ROI/New/486_HE.png',\n",
       "   'ROI/New/499_HE.png',\n",
       "   'ROI/New/507_HE.png',\n",
       "   'ROI/New/509_HE.png',\n",
       "   'ROI/New/526_HE.png',\n",
       "   'ROI/New/529_HE.png',\n",
       "   'ROI/New/530_HE.png',\n",
       "   'ROI/New/532_HE.png',\n",
       "   'ROI/New/537_HE.png',\n",
       "   'ROI/New/542_HE.png']],\n",
       " [['ROI/New/248_HE.png',\n",
       "   'ROI/New/1059_HE.png',\n",
       "   'ROI/New/1013_HE.png',\n",
       "   'ROI/New/620_HE.png',\n",
       "   'ROI/New/1075_HE.png',\n",
       "   'ROI/New/1043_HE.png',\n",
       "   'ROI/New/191_HE.png',\n",
       "   'ROI/New/1125_HE.png',\n",
       "   'ROI/New/1138_HE.png',\n",
       "   'ROI/New/1161_HE.png',\n",
       "   'ROI/New/840_HE.png',\n",
       "   'ROI/New/543_HE.png',\n",
       "   'ROI/New/622_HE.png',\n",
       "   'ROI/New/650_HE.png',\n",
       "   'ROI/New/228_HE.png',\n",
       "   'ROI/New/225_HE.png',\n",
       "   'ROI/New/242_HE.png',\n",
       "   'ROI/New/259_HE.png',\n",
       "   'ROI/New/261_HE.png',\n",
       "   'ROI/New/268_HE.png',\n",
       "   'ROI/New/275_HE.png',\n",
       "   'ROI/New/266_HE.png',\n",
       "   'ROI/New/306_HE.png',\n",
       "   'ROI/New/353_HE.png',\n",
       "   'ROI/New/373_HE.png',\n",
       "   'ROI/New/362_HE.png',\n",
       "   'ROI/New/378_HE.png',\n",
       "   'ROI/New/142_HE.png',\n",
       "   'ROI/New/398_HE.png',\n",
       "   'ROI/New/35_HE.png',\n",
       "   'ROI/New/31_HE.png',\n",
       "   'ROI/New/44_HE.png',\n",
       "   'ROI/New/61_HE.png',\n",
       "   'ROI/New/80_HE.png',\n",
       "   'ROI/New/124_HE.png',\n",
       "   'ROI/New/149_HE.png',\n",
       "   'ROI/New/179_HE.png',\n",
       "   'ROI/New/165_HE.png',\n",
       "   'ROI/New/902_HE.png',\n",
       "   'ROI/New/1210000_HE.png',\n",
       "   'ROI/New/430000_HE.png',\n",
       "   'ROI/New/1580000_HE.png',\n",
       "   'ROI/New/790000_HE.png',\n",
       "   'ROI/New/730000_HE.png',\n",
       "   'ROI/New/2270000_HE.png',\n",
       "   'ROI/New/440000_HE.png',\n",
       "   'ROI/New/620000_HE.png',\n",
       "   'ROI/New/2290000_HE.png',\n",
       "   'ROI/New/2140000_HE.png',\n",
       "   'ROI/New/6200000_HE.png',\n",
       "   'ROI/New/360000_HE.png',\n",
       "   'ROI/New/10900000_HE.png',\n",
       "   'ROI/New/940000_HE.png',\n",
       "   'ROI/New/830000_HE.png',\n",
       "   'ROI/New/1440000_HE.png',\n",
       "   'ROI/New/1040000_HE.png',\n",
       "   'ROI/New/1070000_HE.png',\n",
       "   'ROI/New/330000_HE.png',\n",
       "   'ROI/New/1320000_HE.png',\n",
       "   'ROI/New/660000_HE.png',\n",
       "   'ROI/New/8100000_HE.png',\n",
       "   'ROI/New/1310000_HE.png',\n",
       "   'ROI/New/820000_HE.png',\n",
       "   'ROI/New/202020000_HE.png',\n",
       "   'ROI/New/2022160000_HE.png',\n",
       "   'ROI/New/2230000_HE.png',\n",
       "   'ROI/New/490000_HE.png',\n",
       "   'ROI/New/1470000_HE.png',\n",
       "   'ROI/New/390000_HE.png',\n",
       "   'ROI/New/9500000_HE.png',\n",
       "   'ROI/New/1270000_HE.png',\n",
       "   'ROI/New/2022110000_HE.png',\n",
       "   'ROI/New/650000_HE.png',\n",
       "   'ROI/New/1000000_HE.png',\n",
       "   'ROI/New/2220000_HE.png',\n",
       "   'ROI/New/970000_HE.png',\n",
       "   'ROI/New/950000_HE.png',\n",
       "   'ROI/New/530000_HE.png',\n",
       "   'ROI/New/1940000_HE.png',\n",
       "   'ROI/New/2022140000_HE.png',\n",
       "   'ROI/New/2022190000_HE.png',\n",
       "   'ROI/New/640000_HE.png',\n",
       "   'ROI/New/1510000_HE.png',\n",
       "   'ROI/New/2017160000_HE.png',\n",
       "   'ROI/New/1100000_HE.png',\n",
       "   'ROI/New/2017110000_HE.png',\n",
       "   'ROI/New/450000_HE.png',\n",
       "   'ROI/New/1060000_HE.png',\n",
       "   'ROI/New/3010000_HE.png',\n",
       "   'ROI/New/202050000_HE.png',\n",
       "   'ROI/New/1230000_HE.png',\n",
       "   'ROI/New/50000_HE.png',\n",
       "   'ROI/New/100000_HE.png',\n",
       "   'ROI/New/110000_HE.png',\n",
       "   'ROI/New/300000_HE.png',\n",
       "   'ROI/New/420000_HE.png',\n",
       "   'ROI/New/840000_HE.png',\n",
       "   'ROI/New/880000_HE.png',\n",
       "   'ROI/New/890000_HE.png',\n",
       "   'ROI/New/930000_HE.png',\n",
       "   'ROI/New/1080000_HE.png',\n",
       "   'ROI/New/1650000_HE.png',\n",
       "   'ROI/New/1920000_HE.png',\n",
       "   'ROI/New/2010000_HE.png',\n",
       "   'ROI/New/7900000_HE.png',\n",
       "   'ROI/New/810000_HE.png',\n",
       "   'ROI/New/1140000_HE.png',\n",
       "   'ROI/New/1150000_HE.png',\n",
       "   'ROI/New/1400000_HE.png',\n",
       "   'ROI/New/1460000_HE.png',\n",
       "   'ROI/New/14700000_HE.png',\n",
       "   'ROI/New/1860000_HE.png',\n",
       "   'ROI/New/1870000_HE.png',\n",
       "   'ROI/New/2510000_HE.png',\n",
       "   'ROI/New/120000_HE.png',\n",
       "   'ROI/New/200000_HE.png',\n",
       "   'ROI/New/630000_HE.png',\n",
       "   'ROI/New/2017100000_HE.png',\n",
       "   'ROI/New/2016100000_HE.png',\n",
       "   'ROI/New/544_HE.png',\n",
       "   'ROI/New/545_HE.png',\n",
       "   'ROI/New/546_HE.png',\n",
       "   'ROI/New/547_HE.png',\n",
       "   'ROI/New/550_HE.png',\n",
       "   'ROI/New/551_HE.png',\n",
       "   'ROI/New/553_HE.png',\n",
       "   'ROI/New/554_HE.png',\n",
       "   'ROI/New/555_HE.png',\n",
       "   'ROI/New/558_HE.png',\n",
       "   'ROI/New/559_HE.png',\n",
       "   'ROI/New/560_HE.png',\n",
       "   'ROI/New/561_HE.png',\n",
       "   'ROI/New/562_HE.png',\n",
       "   'ROI/New/563_HE.png',\n",
       "   'ROI/New/564_HE.png',\n",
       "   'ROI/New/567_HE.png',\n",
       "   'ROI/New/569_HE.png',\n",
       "   'ROI/New/571_HE.png',\n",
       "   'ROI/New/574_HE.png',\n",
       "   'ROI/New/576_HE.png',\n",
       "   'ROI/New/579_HE.png',\n",
       "   'ROI/New/580_HE.png',\n",
       "   'ROI/New/583_HE.png',\n",
       "   'ROI/New/585_HE.png',\n",
       "   'ROI/New/586_HE.png',\n",
       "   'ROI/New/587_HE.png',\n",
       "   'ROI/New/588_HE.png',\n",
       "   'ROI/New/589_HE.png',\n",
       "   'ROI/New/590_HE.png',\n",
       "   'ROI/New/592_HE.png',\n",
       "   'ROI/New/594_HE.png',\n",
       "   'ROI/New/596_HE.png',\n",
       "   'ROI/New/597_HE.png',\n",
       "   'ROI/New/598_HE.png',\n",
       "   'ROI/New/599_HE.png',\n",
       "   'ROI/New/600_HE.png',\n",
       "   'ROI/New/601_HE.png',\n",
       "   'ROI/New/602_HE.png',\n",
       "   'ROI/New/603_HE.png',\n",
       "   'ROI/New/605_HE.png',\n",
       "   'ROI/New/609_HE.png',\n",
       "   'ROI/New/610_HE.png',\n",
       "   'ROI/New/611_HE.png',\n",
       "   'ROI/New/614_HE.png',\n",
       "   'ROI/New/615_HE.png',\n",
       "   'ROI/New/616_HE.png',\n",
       "   'ROI/New/617_HE.png',\n",
       "   'ROI/New/623_HE.png',\n",
       "   'ROI/New/625_HE.png',\n",
       "   'ROI/New/627_HE.png',\n",
       "   'ROI/New/629_HE.png',\n",
       "   'ROI/New/630_HE.png',\n",
       "   'ROI/New/633_HE.png',\n",
       "   'ROI/New/635_HE.png',\n",
       "   'ROI/New/637_HE.png',\n",
       "   'ROI/New/638_HE.png',\n",
       "   'ROI/New/639_HE.png',\n",
       "   'ROI/New/641_HE.png',\n",
       "   'ROI/New/643_HE.png',\n",
       "   'ROI/New/645_HE.png',\n",
       "   'ROI/New/647_HE.png',\n",
       "   'ROI/New/648_HE.png',\n",
       "   'ROI/New/649_HE.png',\n",
       "   'ROI/New/651_HE.png',\n",
       "   'ROI/New/652_HE.png',\n",
       "   'ROI/New/654_HE.png',\n",
       "   'ROI/New/655_HE.png',\n",
       "   'ROI/New/656_HE.png',\n",
       "   'ROI/New/657_HE.png',\n",
       "   'ROI/New/659_HE.png',\n",
       "   'ROI/New/661_HE.png',\n",
       "   'ROI/New/662_HE.png',\n",
       "   'ROI/New/664_HE.png',\n",
       "   'ROI/New/665_HE.png',\n",
       "   'ROI/New/666_HE.png',\n",
       "   'ROI/New/668_HE.png',\n",
       "   'ROI/New/669_HE.png',\n",
       "   'ROI/New/670_HE.png',\n",
       "   'ROI/New/674_HE.png',\n",
       "   'ROI/New/676_HE.png',\n",
       "   'ROI/New/677_HE.png',\n",
       "   'ROI/New/679_HE.png',\n",
       "   'ROI/New/680_HE.png',\n",
       "   'ROI/New/682_HE.png',\n",
       "   'ROI/New/687_HE.png',\n",
       "   'ROI/New/688_HE.png',\n",
       "   'ROI/New/690_HE.png',\n",
       "   'ROI/New/692_HE.png',\n",
       "   'ROI/New/694_HE.png',\n",
       "   'ROI/New/695_HE.png',\n",
       "   'ROI/New/698_HE.png',\n",
       "   'ROI/New/700_HE.png',\n",
       "   'ROI/New/702_HE.png',\n",
       "   'ROI/New/703_HE.png',\n",
       "   'ROI/New/704_HE.png',\n",
       "   'ROI/New/705_HE.png',\n",
       "   'ROI/New/707_HE.png',\n",
       "   'ROI/New/708_HE.png',\n",
       "   'ROI/New/710_HE.png',\n",
       "   'ROI/New/713_HE.png',\n",
       "   'ROI/New/714_HE.png',\n",
       "   'ROI/New/716_HE.png',\n",
       "   'ROI/New/717_HE.png',\n",
       "   'ROI/New/721_HE.png',\n",
       "   'ROI/New/722_HE.png',\n",
       "   'ROI/New/724_HE.png',\n",
       "   'ROI/New/725_HE.png',\n",
       "   'ROI/New/727_HE.png',\n",
       "   'ROI/New/728_HE.png',\n",
       "   'ROI/New/729_HE.png',\n",
       "   'ROI/New/730_HE.png',\n",
       "   'ROI/New/731_HE.png',\n",
       "   'ROI/New/732_HE.png',\n",
       "   'ROI/New/733_HE.png',\n",
       "   'ROI/New/734_HE.png',\n",
       "   'ROI/New/735_HE.png',\n",
       "   'ROI/New/736_HE.png',\n",
       "   'ROI/New/737_HE.png',\n",
       "   'ROI/New/738_HE.png',\n",
       "   'ROI/New/741_HE.png',\n",
       "   'ROI/New/742_HE.png',\n",
       "   'ROI/New/743_HE.png',\n",
       "   'ROI/New/745_HE.png',\n",
       "   'ROI/New/746_HE.png',\n",
       "   'ROI/New/747_HE.png',\n",
       "   'ROI/New/749_HE.png',\n",
       "   'ROI/New/750_HE.png',\n",
       "   'ROI/New/753_HE.png',\n",
       "   'ROI/New/754_HE.png',\n",
       "   'ROI/New/755_HE.png',\n",
       "   'ROI/New/757_HE.png',\n",
       "   'ROI/New/758_HE.png',\n",
       "   'ROI/New/759_HE.png',\n",
       "   'ROI/New/761_HE.png',\n",
       "   'ROI/New/762_HE.png',\n",
       "   'ROI/New/763_HE.png',\n",
       "   'ROI/New/764_HE.png',\n",
       "   'ROI/New/765_HE.png',\n",
       "   'ROI/New/766_HE.png',\n",
       "   'ROI/New/767_HE.png',\n",
       "   'ROI/New/769_HE.png',\n",
       "   'ROI/New/770_HE.png',\n",
       "   'ROI/New/772_HE.png',\n",
       "   'ROI/New/774_HE.png',\n",
       "   'ROI/New/776_HE.png',\n",
       "   'ROI/New/777_HE.png',\n",
       "   'ROI/New/778_HE.png',\n",
       "   'ROI/New/779_HE.png',\n",
       "   'ROI/New/781_HE.png',\n",
       "   'ROI/New/782_HE.png',\n",
       "   'ROI/New/783_HE.png',\n",
       "   'ROI/New/785_HE.png',\n",
       "   'ROI/New/786_HE.png',\n",
       "   'ROI/New/787_HE.png',\n",
       "   'ROI/New/788_HE.png',\n",
       "   'ROI/New/789_HE.png',\n",
       "   'ROI/New/792_HE.png',\n",
       "   'ROI/New/793_HE.png',\n",
       "   'ROI/New/794_HE.png',\n",
       "   'ROI/New/795_HE.png',\n",
       "   'ROI/New/796_HE.png',\n",
       "   'ROI/New/798_HE.png',\n",
       "   'ROI/New/799_HE.png',\n",
       "   'ROI/New/800_HE.png',\n",
       "   'ROI/New/801_HE.png',\n",
       "   'ROI/New/803_HE.png',\n",
       "   'ROI/New/804_HE.png',\n",
       "   'ROI/New/808_HE.png',\n",
       "   'ROI/New/809_HE.png',\n",
       "   'ROI/New/810_HE.png',\n",
       "   'ROI/New/812_HE.png',\n",
       "   'ROI/New/813_HE.png',\n",
       "   'ROI/New/815_HE.png',\n",
       "   'ROI/New/816_HE.png',\n",
       "   'ROI/New/817_HE.png',\n",
       "   'ROI/New/818_HE.png',\n",
       "   'ROI/New/820_HE.png',\n",
       "   'ROI/New/824_HE.png',\n",
       "   'ROI/New/826_HE.png',\n",
       "   'ROI/New/827_HE.png',\n",
       "   'ROI/New/829_HE.png',\n",
       "   'ROI/New/830_HE.png',\n",
       "   'ROI/New/832_HE.png',\n",
       "   'ROI/New/833_HE.png',\n",
       "   'ROI/New/836_HE.png',\n",
       "   'ROI/New/837_HE.png',\n",
       "   'ROI/New/841_HE.png',\n",
       "   'ROI/New/842_HE.png',\n",
       "   'ROI/New/846_HE.png',\n",
       "   'ROI/New/848_HE.png',\n",
       "   'ROI/New/850_HE.png',\n",
       "   'ROI/New/851_HE.png',\n",
       "   'ROI/New/852_HE.png',\n",
       "   'ROI/New/854_HE.png',\n",
       "   'ROI/New/856_HE.png',\n",
       "   'ROI/New/857_HE.png',\n",
       "   'ROI/New/862_HE.png',\n",
       "   'ROI/New/863_HE.png',\n",
       "   'ROI/New/864_HE.png',\n",
       "   'ROI/New/867_HE.png',\n",
       "   'ROI/New/872_HE.png',\n",
       "   'ROI/New/875_HE.png',\n",
       "   'ROI/New/876_HE.png',\n",
       "   'ROI/New/879_HE.png',\n",
       "   'ROI/New/880_HE.png',\n",
       "   'ROI/New/881_HE.png',\n",
       "   'ROI/New/882_HE.png',\n",
       "   'ROI/New/883_HE.png',\n",
       "   'ROI/New/884_HE.png',\n",
       "   'ROI/New/885_HE.png',\n",
       "   'ROI/New/886_HE.png',\n",
       "   'ROI/New/887_HE.png',\n",
       "   'ROI/New/888_HE.png',\n",
       "   'ROI/New/891_HE.png',\n",
       "   'ROI/New/893_HE.png',\n",
       "   'ROI/New/896_HE.png',\n",
       "   'ROI/New/897_HE.png',\n",
       "   'ROI/New/899_HE.png',\n",
       "   'ROI/New/903_HE.png',\n",
       "   'ROI/New/904_HE.png',\n",
       "   'ROI/New/905_HE.png',\n",
       "   'ROI/New/906_HE.png',\n",
       "   'ROI/New/907_HE.png',\n",
       "   'ROI/New/909_HE.png',\n",
       "   'ROI/New/910_HE.png',\n",
       "   'ROI/New/911_HE.png',\n",
       "   'ROI/New/912_HE.png',\n",
       "   'ROI/New/914_HE.png',\n",
       "   'ROI/New/918_HE.png',\n",
       "   'ROI/New/919_HE.png',\n",
       "   'ROI/New/922_HE.png',\n",
       "   'ROI/New/923_HE.png',\n",
       "   'ROI/New/925_HE.png',\n",
       "   'ROI/New/927_HE.png',\n",
       "   'ROI/New/928_HE.png',\n",
       "   'ROI/New/930_HE.png',\n",
       "   'ROI/New/931_HE.png',\n",
       "   'ROI/New/932_HE.png',\n",
       "   'ROI/New/933_HE.png',\n",
       "   'ROI/New/934_HE.png',\n",
       "   'ROI/New/937_HE.png',\n",
       "   'ROI/New/938_HE.png',\n",
       "   'ROI/New/939_HE.png',\n",
       "   'ROI/New/940_HE.png',\n",
       "   'ROI/New/941_HE.png',\n",
       "   'ROI/New/943_HE.png',\n",
       "   'ROI/New/944_HE.png',\n",
       "   'ROI/New/947_HE.png',\n",
       "   'ROI/New/948_HE.png',\n",
       "   'ROI/New/949_HE.png',\n",
       "   'ROI/New/950_HE.png',\n",
       "   'ROI/New/951_HE.png',\n",
       "   'ROI/New/953_HE.png',\n",
       "   'ROI/New/954_HE.png',\n",
       "   'ROI/New/959_HE.png',\n",
       "   'ROI/New/960_HE.png',\n",
       "   'ROI/New/961_HE.png',\n",
       "   'ROI/New/962_HE.png',\n",
       "   'ROI/New/963_HE.png',\n",
       "   'ROI/New/964_HE.png',\n",
       "   'ROI/New/966_HE.png',\n",
       "   'ROI/New/967_HE.png',\n",
       "   'ROI/New/968_HE.png',\n",
       "   'ROI/New/969_HE.png',\n",
       "   'ROI/New/971_HE.png',\n",
       "   'ROI/New/972_HE.png',\n",
       "   'ROI/New/973_HE.png',\n",
       "   'ROI/New/976_HE.png',\n",
       "   'ROI/New/977_HE.png',\n",
       "   'ROI/New/978_HE.png',\n",
       "   'ROI/New/979_HE.png',\n",
       "   'ROI/New/982_HE.png',\n",
       "   'ROI/New/984_HE.png',\n",
       "   'ROI/New/985_HE.png',\n",
       "   'ROI/New/986_HE.png',\n",
       "   'ROI/New/987_HE.png',\n",
       "   'ROI/New/988_HE.png',\n",
       "   'ROI/New/989_HE.png',\n",
       "   'ROI/New/990_HE.png',\n",
       "   'ROI/New/991_HE.png',\n",
       "   'ROI/New/993_HE.png',\n",
       "   'ROI/New/994_HE.png',\n",
       "   'ROI/New/995_HE.png',\n",
       "   'ROI/New/997_HE.png',\n",
       "   'ROI/New/998_HE.png',\n",
       "   'ROI/New/999_HE.png',\n",
       "   'ROI/New/1002_HE.png',\n",
       "   'ROI/New/1004_HE.png',\n",
       "   'ROI/New/1005_HE.png',\n",
       "   'ROI/New/1006_HE.png',\n",
       "   'ROI/New/1007_HE.png',\n",
       "   'ROI/New/1008_HE.png',\n",
       "   'ROI/New/1009_HE.png',\n",
       "   'ROI/New/1010_HE.png',\n",
       "   'ROI/New/1012_HE.png',\n",
       "   'ROI/New/1014_HE.png',\n",
       "   'ROI/New/1015_HE.png',\n",
       "   'ROI/New/1016_HE.png',\n",
       "   'ROI/New/1022_HE.png',\n",
       "   'ROI/New/1024_HE.png',\n",
       "   'ROI/New/1025_HE.png',\n",
       "   'ROI/New/1026_HE.png',\n",
       "   'ROI/New/1028_HE.png',\n",
       "   'ROI/New/1029_HE.png',\n",
       "   'ROI/New/1032_HE.png',\n",
       "   'ROI/New/1033_HE.png',\n",
       "   'ROI/New/1035_HE.png',\n",
       "   'ROI/New/1037_HE.png',\n",
       "   'ROI/New/1039_HE.png',\n",
       "   'ROI/New/1040_HE.png',\n",
       "   'ROI/New/1045_HE.png',\n",
       "   'ROI/New/1046_HE.png',\n",
       "   'ROI/New/1047_HE.png',\n",
       "   'ROI/New/1049_HE.png',\n",
       "   'ROI/New/1058_HE.png',\n",
       "   'ROI/New/1060_HE.png',\n",
       "   'ROI/New/1061_HE.png',\n",
       "   'ROI/New/1062_HE.png',\n",
       "   'ROI/New/1063_HE.png',\n",
       "   'ROI/New/1065_HE.png',\n",
       "   'ROI/New/1066_HE.png',\n",
       "   'ROI/New/1067_HE.png',\n",
       "   'ROI/New/1068_HE.png',\n",
       "   'ROI/New/1069_HE.png',\n",
       "   'ROI/New/1071_HE.png',\n",
       "   'ROI/New/1072_HE.png',\n",
       "   'ROI/New/1073_HE.png',\n",
       "   'ROI/New/1074_HE.png',\n",
       "   'ROI/New/1076_HE.png',\n",
       "   'ROI/New/1078_HE.png',\n",
       "   'ROI/New/1081_HE.png',\n",
       "   'ROI/New/1082_HE.png',\n",
       "   'ROI/New/1084_HE.png',\n",
       "   'ROI/New/1085_HE.png',\n",
       "   'ROI/New/1086_HE.png',\n",
       "   'ROI/New/1087_HE.png',\n",
       "   'ROI/New/1088_HE.png',\n",
       "   'ROI/New/1089_HE.png',\n",
       "   'ROI/New/1091_HE.png',\n",
       "   'ROI/New/1096_HE.png',\n",
       "   'ROI/New/1097_HE.png',\n",
       "   'ROI/New/1098_HE.png',\n",
       "   'ROI/New/1099_HE.png',\n",
       "   'ROI/New/1100_HE.png',\n",
       "   'ROI/New/1102_HE.png',\n",
       "   'ROI/New/1103_HE.png',\n",
       "   'ROI/New/1105_HE.png',\n",
       "   'ROI/New/1106_HE.png',\n",
       "   'ROI/New/1107_HE.png',\n",
       "   'ROI/New/1109_HE.png',\n",
       "   'ROI/New/1111_HE.png',\n",
       "   'ROI/New/1112_HE.png',\n",
       "   'ROI/New/1114_HE.png',\n",
       "   'ROI/New/1115_HE.png',\n",
       "   'ROI/New/1116_HE.png',\n",
       "   'ROI/New/1117_HE.png',\n",
       "   'ROI/New/1122_HE.png',\n",
       "   'ROI/New/1123_HE.png',\n",
       "   'ROI/New/1127_HE.png',\n",
       "   'ROI/New/1128_HE.png',\n",
       "   'ROI/New/1129_HE.png',\n",
       "   'ROI/New/1130_HE.png',\n",
       "   'ROI/New/1132_HE.png',\n",
       "   'ROI/New/1136_HE.png',\n",
       "   'ROI/New/1139_HE.png',\n",
       "   'ROI/New/1141_HE.png',\n",
       "   'ROI/New/1142_HE.png',\n",
       "   'ROI/New/1143_HE.png',\n",
       "   'ROI/New/1144_HE.png',\n",
       "   'ROI/New/1145_HE.png',\n",
       "   'ROI/New/1146_HE.png',\n",
       "   'ROI/New/1148_HE.png',\n",
       "   'ROI/New/1150_HE.png',\n",
       "   'ROI/New/1152_HE.png',\n",
       "   'ROI/New/1154_HE.png',\n",
       "   'ROI/New/1157_HE.png',\n",
       "   'ROI/New/1159_HE.png',\n",
       "   'ROI/New/1160_HE.png',\n",
       "   'ROI/New/1162_HE.png',\n",
       "   'ROI/New/1163_HE.png',\n",
       "   'ROI/New/1167_HE.png',\n",
       "   'ROI/New/1168_HE.png',\n",
       "   'ROI/New/1169_HE.png',\n",
       "   'ROI/New/1170_HE.png',\n",
       "   'ROI/New/1171_HE.png',\n",
       "   'ROI/New/1172_HE.png',\n",
       "   'ROI/New/1174_HE.png',\n",
       "   'ROI/New/1175_HE.png',\n",
       "   'ROI/New/1176_HE.png',\n",
       "   'ROI/New/1177_HE.png',\n",
       "   'ROI/New/1180_HE.png',\n",
       "   'ROI/New/1182_HE.png',\n",
       "   'ROI/New/1184_HE.png',\n",
       "   'ROI/New/1186_HE.png',\n",
       "   'ROI/New/1187_HE.png',\n",
       "   'ROI/New/1188_HE.png',\n",
       "   'ROI/New/1190_HE.png',\n",
       "   'ROI/New/1191_HE.png',\n",
       "   'ROI/New/1192_HE.png',\n",
       "   'ROI/New/1193_HE.png',\n",
       "   'ROI/New/150000_HE.png',\n",
       "   'ROI/New/160000_HE.png',\n",
       "   'ROI/New/210000_HE.png',\n",
       "   'ROI/New/280000_HE.png',\n",
       "   'ROI/New/290000_HE.png',\n",
       "   'ROI/New/410000_HE.png',\n",
       "   'ROI/New/1520000_HE.png',\n",
       "   'ROI/New/1600000_HE.png',\n",
       "   'ROI/New/1620000_HE.png',\n",
       "   'ROI/New/1670000_HE.png',\n",
       "   'ROI/New/1950000_HE.png',\n",
       "   'ROI/New/1970000_HE.png',\n",
       "   'ROI/New/2020000_HE.png',\n",
       "   'ROI/New/2110000_HE.png',\n",
       "   'ROI/New/2190000_HE.png',\n",
       "   'ROI/New/2250000_HE.png',\n",
       "   'ROI/New/2300000_HE.png',\n",
       "   'ROI/New/2340000_HE.png',\n",
       "   'ROI/New/2370000_HE.png',\n",
       "   'ROI/New/201610000_HE.png',\n",
       "   'ROI/New/201640000_HE.png',\n",
       "   'ROI/New/201670000_HE.png',\n",
       "   'ROI/New/201680000_HE.png',\n",
       "   'ROI/New/201730000_HE.png',\n",
       "   'ROI/New/201740000_HE.png',\n",
       "   'ROI/New/201750000_HE.png',\n",
       "   'ROI/New/201760000_HE.png',\n",
       "   'ROI/New/201770000_HE.png',\n",
       "   'ROI/New/201780000_HE.png',\n",
       "   'ROI/New/201810000_HE.png',\n",
       "   'ROI/New/201820000_HE.png',\n",
       "   'ROI/New/201830000_HE.png',\n",
       "   'ROI/New/201840000_HE.png',\n",
       "   'ROI/New/201850000_HE.png',\n",
       "   'ROI/New/201860000_HE.png',\n",
       "   'ROI/New/201870000_HE.png',\n",
       "   'ROI/New/201880000_HE.png',\n",
       "   'ROI/New/201890000_HE.png',\n",
       "   'ROI/New/201910000_HE.png',\n",
       "   'ROI/New/201930000_HE.png',\n",
       "   'ROI/New/201940000_HE.png',\n",
       "   'ROI/New/201950000_HE.png',\n",
       "   'ROI/New/201960000_HE.png',\n",
       "   'ROI/New/201970000_HE.png',\n",
       "   'ROI/New/201990000_HE.png',\n",
       "   'ROI/New/202010000_HE.png',\n",
       "   'ROI/New/202030000_HE.png',\n",
       "   'ROI/New/202220000_HE.png',\n",
       "   'ROI/New/202230000_HE.png',\n",
       "   'ROI/New/202240000_HE.png',\n",
       "   'ROI/New/202250000_HE.png',\n",
       "   'ROI/New/202260000_HE.png',\n",
       "   'ROI/New/202270000_HE.png',\n",
       "   'ROI/New/202290000_HE.png',\n",
       "   'ROI/New/2016110000_HE.png',\n",
       "   'ROI/New/2017120000_HE.png',\n",
       "   'ROI/New/2017130000_HE.png',\n",
       "   'ROI/New/2017140000_HE.png',\n",
       "   'ROI/New/2017150000_HE.png',\n",
       "   'ROI/New/2018100000_HE.png',\n",
       "   'ROI/New/2018130000_HE.png',\n",
       "   'ROI/New/2018140000_HE.png',\n",
       "   'ROI/New/2018150000_HE.png',\n",
       "   'ROI/New/2018170000_HE.png',\n",
       "   'ROI/New/2019110000_HE.png',\n",
       "   'ROI/New/2019130000_HE.png',\n",
       "   'ROI/New/2019140000_HE.png',\n",
       "   'ROI/New/2019150000_HE.png',\n",
       "   'ROI/New/2019160000_HE.png',\n",
       "   'ROI/New/2019170000_HE.png',\n",
       "   'ROI/New/2019190000_HE.png',\n",
       "   'ROI/New/2022100000_HE.png',\n",
       "   'ROI/New/2022120000_HE.png',\n",
       "   'ROI/New/2022130000_HE.png',\n",
       "   'ROI/New/2022150000_HE.png',\n",
       "   'ROI/New/2022180000_HE.png',\n",
       "   'ROI/New/2022200000_HE.png',\n",
       "   'ROI/New/2022210000_HE.png',\n",
       "   'ROI/New/2022240000_HE.png',\n",
       "   'ROI/New/1_HE.png',\n",
       "   'ROI/New/2_HE.png',\n",
       "   'ROI/New/3_HE.png',\n",
       "   'ROI/New/4_HE.png',\n",
       "   'ROI/New/6_HE.png',\n",
       "   'ROI/New/9_HE.png',\n",
       "   'ROI/New/10_HE.png',\n",
       "   'ROI/New/11_HE.png',\n",
       "   'ROI/New/12_HE.png',\n",
       "   'ROI/New/13_HE.png',\n",
       "   'ROI/New/15_HE.png',\n",
       "   'ROI/New/16_HE.png',\n",
       "   'ROI/New/18_HE.png',\n",
       "   'ROI/New/20_HE.png',\n",
       "   'ROI/New/21_HE.png',\n",
       "   'ROI/New/23_HE.png',\n",
       "   'ROI/New/25_HE.png',\n",
       "   'ROI/New/27_HE.png',\n",
       "   'ROI/New/33_HE.png',\n",
       "   'ROI/New/34_HE.png',\n",
       "   'ROI/New/36_HE.png',\n",
       "   'ROI/New/37_HE.png',\n",
       "   'ROI/New/39_HE.png',\n",
       "   'ROI/New/40_HE.png',\n",
       "   'ROI/New/43_HE.png',\n",
       "   'ROI/New/45_HE.png',\n",
       "   'ROI/New/46_HE.png',\n",
       "   'ROI/New/47_HE.png',\n",
       "   'ROI/New/48_HE.png',\n",
       "   'ROI/New/49_HE.png',\n",
       "   'ROI/New/50_HE.png',\n",
       "   'ROI/New/51_HE.png',\n",
       "   'ROI/New/52_HE.png',\n",
       "   'ROI/New/54_HE.png',\n",
       "   'ROI/New/55_HE.png',\n",
       "   'ROI/New/56_HE.png',\n",
       "   'ROI/New/57_HE.png',\n",
       "   'ROI/New/58_HE.png',\n",
       "   'ROI/New/59_HE.png',\n",
       "   'ROI/New/60_HE.png',\n",
       "   'ROI/New/62_HE.png',\n",
       "   'ROI/New/63_HE.png',\n",
       "   'ROI/New/64_HE.png',\n",
       "   'ROI/New/65_HE.png',\n",
       "   'ROI/New/68_HE.png',\n",
       "   'ROI/New/70_HE.png',\n",
       "   'ROI/New/72_HE.png',\n",
       "   'ROI/New/73_HE.png',\n",
       "   'ROI/New/74_HE.png',\n",
       "   'ROI/New/76_HE.png',\n",
       "   'ROI/New/78_HE.png',\n",
       "   'ROI/New/79_HE.png',\n",
       "   'ROI/New/81_HE.png',\n",
       "   'ROI/New/82_HE.png',\n",
       "   'ROI/New/84_HE.png',\n",
       "   'ROI/New/85_HE.png',\n",
       "   'ROI/New/86_HE.png',\n",
       "   'ROI/New/87_HE.png',\n",
       "   'ROI/New/88_HE.png',\n",
       "   'ROI/New/90_HE.png',\n",
       "   'ROI/New/91_HE.png',\n",
       "   'ROI/New/92_HE.png',\n",
       "   'ROI/New/93_HE.png',\n",
       "   'ROI/New/94_HE.png',\n",
       "   'ROI/New/95_HE.png',\n",
       "   'ROI/New/96_HE.png',\n",
       "   'ROI/New/97_HE.png',\n",
       "   'ROI/New/99_HE.png',\n",
       "   'ROI/New/101_HE.png',\n",
       "   'ROI/New/102_HE.png',\n",
       "   'ROI/New/103_HE.png',\n",
       "   'ROI/New/104_HE.png',\n",
       "   'ROI/New/105_HE.png',\n",
       "   'ROI/New/106_HE.png',\n",
       "   'ROI/New/107_HE.png',\n",
       "   'ROI/New/111_HE.png',\n",
       "   'ROI/New/112_HE.png',\n",
       "   'ROI/New/113_HE.png',\n",
       "   'ROI/New/114_HE.png',\n",
       "   'ROI/New/115_HE.png',\n",
       "   'ROI/New/116_HE.png',\n",
       "   'ROI/New/118_HE.png',\n",
       "   'ROI/New/120_HE.png',\n",
       "   'ROI/New/122_HE.png',\n",
       "   'ROI/New/123_HE.png',\n",
       "   'ROI/New/125_HE.png',\n",
       "   'ROI/New/127_HE.png',\n",
       "   'ROI/New/129_HE.png',\n",
       "   'ROI/New/132_HE.png',\n",
       "   'ROI/New/133_HE.png',\n",
       "   'ROI/New/134_HE.png',\n",
       "   'ROI/New/136_HE.png',\n",
       "   'ROI/New/137_HE.png',\n",
       "   'ROI/New/138_HE.png',\n",
       "   'ROI/New/140_HE.png',\n",
       "   'ROI/New/144_HE.png',\n",
       "   'ROI/New/146_HE.png',\n",
       "   'ROI/New/147_HE.png',\n",
       "   'ROI/New/151_HE.png',\n",
       "   'ROI/New/152_HE.png',\n",
       "   'ROI/New/153_HE.png',\n",
       "   'ROI/New/155_HE.png',\n",
       "   'ROI/New/156_HE.png',\n",
       "   'ROI/New/157_HE.png',\n",
       "   'ROI/New/158_HE.png',\n",
       "   'ROI/New/159_HE.png',\n",
       "   'ROI/New/160_HE.png',\n",
       "   'ROI/New/161_HE.png',\n",
       "   'ROI/New/163_HE.png',\n",
       "   'ROI/New/167_HE.png',\n",
       "   'ROI/New/169_HE.png',\n",
       "   'ROI/New/170_HE.png',\n",
       "   'ROI/New/171_HE.png',\n",
       "   'ROI/New/172_HE.png',\n",
       "   'ROI/New/174_HE.png',\n",
       "   'ROI/New/175_HE.png',\n",
       "   'ROI/New/178_HE.png',\n",
       "   'ROI/New/180_HE.png',\n",
       "   'ROI/New/188_HE.png',\n",
       "   'ROI/New/190_HE.png',\n",
       "   'ROI/New/192_HE.png',\n",
       "   'ROI/New/193_HE.png',\n",
       "   'ROI/New/194_HE.png',\n",
       "   'ROI/New/195_HE.png',\n",
       "   'ROI/New/196_HE.png',\n",
       "   'ROI/New/197_HE.png',\n",
       "   'ROI/New/198_HE.png',\n",
       "   'ROI/New/199_HE.png',\n",
       "   'ROI/New/201_HE.png',\n",
       "   'ROI/New/202_HE.png',\n",
       "   'ROI/New/203_HE.png',\n",
       "   'ROI/New/205_HE.png',\n",
       "   'ROI/New/207_HE.png',\n",
       "   'ROI/New/208_HE.png',\n",
       "   'ROI/New/209_HE.png',\n",
       "   'ROI/New/212_HE.png',\n",
       "   'ROI/New/213_HE.png',\n",
       "   'ROI/New/214_HE.png',\n",
       "   'ROI/New/215_HE.png',\n",
       "   'ROI/New/216_HE.png',\n",
       "   'ROI/New/217_HE.png',\n",
       "   'ROI/New/221_HE.png',\n",
       "   'ROI/New/222_HE.png',\n",
       "   'ROI/New/224_HE.png',\n",
       "   'ROI/New/227_HE.png',\n",
       "   'ROI/New/229_HE.png',\n",
       "   'ROI/New/233_HE.png',\n",
       "   'ROI/New/235_HE.png',\n",
       "   'ROI/New/236_HE.png',\n",
       "   'ROI/New/237_HE.png',\n",
       "   'ROI/New/238_HE.png',\n",
       "   'ROI/New/240_HE.png',\n",
       "   'ROI/New/244_HE.png',\n",
       "   'ROI/New/247_HE.png',\n",
       "   'ROI/New/249_HE.png',\n",
       "   'ROI/New/250_HE.png',\n",
       "   'ROI/New/251_HE.png',\n",
       "   'ROI/New/252_HE.png',\n",
       "   'ROI/New/255_HE.png',\n",
       "   'ROI/New/256_HE.png',\n",
       "   'ROI/New/257_HE.png',\n",
       "   'ROI/New/260_HE.png',\n",
       "   'ROI/New/263_HE.png',\n",
       "   'ROI/New/264_HE.png',\n",
       "   'ROI/New/267_HE.png',\n",
       "   'ROI/New/272_HE.png',\n",
       "   'ROI/New/276_HE.png',\n",
       "   'ROI/New/277_HE.png',\n",
       "   'ROI/New/278_HE.png',\n",
       "   'ROI/New/279_HE.png',\n",
       "   'ROI/New/280_HE.png',\n",
       "   'ROI/New/283_HE.png',\n",
       "   'ROI/New/286_HE.png',\n",
       "   'ROI/New/287_HE.png',\n",
       "   'ROI/New/289_HE.png',\n",
       "   'ROI/New/290_HE.png',\n",
       "   'ROI/New/292_HE.png',\n",
       "   'ROI/New/294_HE.png',\n",
       "   'ROI/New/296_HE.png',\n",
       "   'ROI/New/298_HE.png',\n",
       "   'ROI/New/300_HE.png',\n",
       "   'ROI/New/301_HE.png',\n",
       "   'ROI/New/302_HE.png',\n",
       "   'ROI/New/304_HE.png',\n",
       "   'ROI/New/305_HE.png',\n",
       "   'ROI/New/307_HE.png',\n",
       "   'ROI/New/310_HE.png',\n",
       "   'ROI/New/311_HE.png',\n",
       "   'ROI/New/312_HE.png',\n",
       "   'ROI/New/313_HE.png',\n",
       "   'ROI/New/314_HE.png',\n",
       "   'ROI/New/315_HE.png',\n",
       "   'ROI/New/317_HE.png',\n",
       "   'ROI/New/318_HE.png',\n",
       "   'ROI/New/319_HE.png',\n",
       "   'ROI/New/322_HE.png',\n",
       "   'ROI/New/323_HE.png',\n",
       "   'ROI/New/324_HE.png',\n",
       "   'ROI/New/325_HE.png',\n",
       "   'ROI/New/327_HE.png',\n",
       "   'ROI/New/328_HE.png',\n",
       "   'ROI/New/329_HE.png',\n",
       "   'ROI/New/332_HE.png',\n",
       "   'ROI/New/333_HE.png',\n",
       "   'ROI/New/336_HE.png',\n",
       "   'ROI/New/337_HE.png',\n",
       "   'ROI/New/340_HE.png',\n",
       "   'ROI/New/341_HE.png',\n",
       "   'ROI/New/342_HE.png',\n",
       "   'ROI/New/343_HE.png',\n",
       "   'ROI/New/344_HE.png',\n",
       "   'ROI/New/345_HE.png',\n",
       "   'ROI/New/346_HE.png',\n",
       "   'ROI/New/351_HE.png',\n",
       "   'ROI/New/352_HE.png',\n",
       "   'ROI/New/355_HE.png',\n",
       "   'ROI/New/356_HE.png',\n",
       "   'ROI/New/358_HE.png',\n",
       "   'ROI/New/360_HE.png',\n",
       "   'ROI/New/361_HE.png',\n",
       "   'ROI/New/363_HE.png',\n",
       "   'ROI/New/364_HE.png',\n",
       "   'ROI/New/365_HE.png',\n",
       "   'ROI/New/366_HE.png',\n",
       "   'ROI/New/371_HE.png',\n",
       "   'ROI/New/372_HE.png',\n",
       "   'ROI/New/374_HE.png',\n",
       "   'ROI/New/375_HE.png',\n",
       "   'ROI/New/377_HE.png',\n",
       "   'ROI/New/379_HE.png',\n",
       "   'ROI/New/380_HE.png',\n",
       "   'ROI/New/381_HE.png',\n",
       "   'ROI/New/383_HE.png',\n",
       "   'ROI/New/384_HE.png',\n",
       "   'ROI/New/385_HE.png',\n",
       "   'ROI/New/387_HE.png',\n",
       "   'ROI/New/388_HE.png',\n",
       "   'ROI/New/390_HE.png',\n",
       "   'ROI/New/391_HE.png',\n",
       "   'ROI/New/392_HE.png',\n",
       "   'ROI/New/394_HE.png',\n",
       "   'ROI/New/396_HE.png',\n",
       "   'ROI/New/397_HE.png',\n",
       "   'ROI/New/400_HE.png',\n",
       "   'ROI/New/401_HE.png',\n",
       "   'ROI/New/402_HE.png',\n",
       "   'ROI/New/403_HE.png',\n",
       "   'ROI/New/404_HE.png',\n",
       "   'ROI/New/406_HE.png',\n",
       "   'ROI/New/407_HE.png',\n",
       "   'ROI/New/409_HE.png',\n",
       "   'ROI/New/410_HE.png',\n",
       "   'ROI/New/412_HE.png',\n",
       "   'ROI/New/414_HE.png',\n",
       "   'ROI/New/415_HE.png',\n",
       "   'ROI/New/417_HE.png',\n",
       "   'ROI/New/418_HE.png',\n",
       "   'ROI/New/420_HE.png',\n",
       "   'ROI/New/421_HE.png',\n",
       "   'ROI/New/423_HE.png',\n",
       "   'ROI/New/424_HE.png',\n",
       "   'ROI/New/425_HE.png',\n",
       "   'ROI/New/426_HE.png',\n",
       "   'ROI/New/427_HE.png',\n",
       "   'ROI/New/428_HE.png',\n",
       "   'ROI/New/429_HE.png',\n",
       "   'ROI/New/430_HE.png',\n",
       "   'ROI/New/431_HE.png',\n",
       "   'ROI/New/432_HE.png',\n",
       "   'ROI/New/435_HE.png',\n",
       "   'ROI/New/439_HE.png',\n",
       "   'ROI/New/440_HE.png',\n",
       "   'ROI/New/441_HE.png',\n",
       "   'ROI/New/443_HE.png',\n",
       "   'ROI/New/444_HE.png',\n",
       "   'ROI/New/445_HE.png',\n",
       "   'ROI/New/446_HE.png',\n",
       "   'ROI/New/447_HE.png',\n",
       "   'ROI/New/448_HE.png',\n",
       "   'ROI/New/449_HE.png',\n",
       "   'ROI/New/450_HE.png',\n",
       "   'ROI/New/451_HE.png',\n",
       "   'ROI/New/452_HE.png',\n",
       "   'ROI/New/453_HE.png',\n",
       "   'ROI/New/455_HE.png',\n",
       "   'ROI/New/457_HE.png',\n",
       "   'ROI/New/459_HE.png',\n",
       "   'ROI/New/460_HE.png',\n",
       "   'ROI/New/464_HE.png',\n",
       "   'ROI/New/465_HE.png',\n",
       "   'ROI/New/466_HE.png',\n",
       "   'ROI/New/467_HE.png',\n",
       "   'ROI/New/469_HE.png',\n",
       "   'ROI/New/470_HE.png',\n",
       "   'ROI/New/475_HE.png',\n",
       "   'ROI/New/477_HE.png',\n",
       "   'ROI/New/479_HE.png',\n",
       "   'ROI/New/480_HE.png',\n",
       "   'ROI/New/481_HE.png',\n",
       "   'ROI/New/482_HE.png',\n",
       "   'ROI/New/483_HE.png',\n",
       "   'ROI/New/485_HE.png',\n",
       "   'ROI/New/486_HE.png',\n",
       "   'ROI/New/487_HE.png',\n",
       "   'ROI/New/488_HE.png',\n",
       "   'ROI/New/490_HE.png',\n",
       "   'ROI/New/491_HE.png',\n",
       "   'ROI/New/493_HE.png',\n",
       "   'ROI/New/494_HE.png',\n",
       "   'ROI/New/495_HE.png',\n",
       "   'ROI/New/496_HE.png',\n",
       "   'ROI/New/499_HE.png',\n",
       "   'ROI/New/500_HE.png',\n",
       "   'ROI/New/501_HE.png',\n",
       "   'ROI/New/502_HE.png',\n",
       "   'ROI/New/503_HE.png',\n",
       "   'ROI/New/505_HE.png',\n",
       "   'ROI/New/507_HE.png',\n",
       "   'ROI/New/509_HE.png',\n",
       "   'ROI/New/510_HE.png',\n",
       "   'ROI/New/512_HE.png',\n",
       "   'ROI/New/517_HE.png',\n",
       "   'ROI/New/518_HE.png',\n",
       "   'ROI/New/519_HE.png',\n",
       "   'ROI/New/520_HE.png',\n",
       "   'ROI/New/521_HE.png',\n",
       "   'ROI/New/522_HE.png',\n",
       "   'ROI/New/524_HE.png',\n",
       "   'ROI/New/525_HE.png',\n",
       "   'ROI/New/526_HE.png',\n",
       "   'ROI/New/529_HE.png',\n",
       "   'ROI/New/530_HE.png',\n",
       "   'ROI/New/532_HE.png',\n",
       "   'ROI/New/534_HE.png',\n",
       "   'ROI/New/535_HE.png',\n",
       "   'ROI/New/536_HE.png',\n",
       "   'ROI/New/537_HE.png',\n",
       "   'ROI/New/538_HE.png',\n",
       "   'ROI/New/539_HE.png',\n",
       "   'ROI/New/540_HE.png',\n",
       "   'ROI/New/542_HE.png'],\n",
       "  ['ROI/New/357_HE.png',\n",
       "   'ROI/New/89_HE.png',\n",
       "   'ROI/New/269_HE.png',\n",
       "   'ROI/New/845_HE.png',\n",
       "   'ROI/New/246_HE.png',\n",
       "   'ROI/New/288_HE.png',\n",
       "   'ROI/New/297_HE.png',\n",
       "   'ROI/New/369_HE.png',\n",
       "   'ROI/New/389_HE.png',\n",
       "   'ROI/New/67_HE.png',\n",
       "   'ROI/New/143_HE.png',\n",
       "   'ROI/New/340000_HE.png',\n",
       "   'ROI/New/1590000_HE.png',\n",
       "   'ROI/New/1050000_HE.png',\n",
       "   'ROI/New/9700000_HE.png',\n",
       "   'ROI/New/15200000_HE.png',\n",
       "   'ROI/New/370000_HE.png',\n",
       "   'ROI/New/460000_HE.png',\n",
       "   'ROI/New/310000_HE.png',\n",
       "   'ROI/New/1290000_HE.png',\n",
       "   'ROI/New/2016120000_HE.png',\n",
       "   'ROI/New/201620000_HE.png',\n",
       "   'ROI/New/2019180000_HE.png',\n",
       "   'ROI/New/1020000_HE.png',\n",
       "   'ROI/New/1570000_HE.png',\n",
       "   'ROI/New/1090000_HE.png',\n",
       "   'ROI/New/670000_HE.png',\n",
       "   'ROI/New/16000000_HE.png',\n",
       "   'ROI/New/470000_HE.png',\n",
       "   'ROI/New/740000_HE.png',\n",
       "   'ROI/New/8400000_HE.png',\n",
       "   'ROI/New/548_HE.png',\n",
       "   'ROI/New/566_HE.png',\n",
       "   'ROI/New/568_HE.png',\n",
       "   'ROI/New/570_HE.png',\n",
       "   'ROI/New/572_HE.png',\n",
       "   'ROI/New/575_HE.png',\n",
       "   'ROI/New/577_HE.png',\n",
       "   'ROI/New/581_HE.png',\n",
       "   'ROI/New/582_HE.png',\n",
       "   'ROI/New/584_HE.png',\n",
       "   'ROI/New/591_HE.png',\n",
       "   'ROI/New/593_HE.png',\n",
       "   'ROI/New/604_HE.png',\n",
       "   'ROI/New/606_HE.png',\n",
       "   'ROI/New/607_HE.png',\n",
       "   'ROI/New/608_HE.png',\n",
       "   'ROI/New/612_HE.png',\n",
       "   'ROI/New/613_HE.png',\n",
       "   'ROI/New/618_HE.png',\n",
       "   'ROI/New/621_HE.png',\n",
       "   'ROI/New/636_HE.png',\n",
       "   'ROI/New/640_HE.png',\n",
       "   'ROI/New/646_HE.png',\n",
       "   'ROI/New/658_HE.png',\n",
       "   'ROI/New/660_HE.png',\n",
       "   'ROI/New/667_HE.png',\n",
       "   'ROI/New/671_HE.png',\n",
       "   'ROI/New/675_HE.png',\n",
       "   'ROI/New/684_HE.png',\n",
       "   'ROI/New/685_HE.png',\n",
       "   'ROI/New/686_HE.png',\n",
       "   'ROI/New/693_HE.png',\n",
       "   'ROI/New/699_HE.png',\n",
       "   'ROI/New/701_HE.png',\n",
       "   'ROI/New/712_HE.png',\n",
       "   'ROI/New/715_HE.png',\n",
       "   'ROI/New/718_HE.png',\n",
       "   'ROI/New/720_HE.png',\n",
       "   'ROI/New/723_HE.png',\n",
       "   'ROI/New/756_HE.png',\n",
       "   'ROI/New/760_HE.png',\n",
       "   'ROI/New/768_HE.png',\n",
       "   'ROI/New/771_HE.png',\n",
       "   'ROI/New/811_HE.png',\n",
       "   'ROI/New/814_HE.png',\n",
       "   'ROI/New/819_HE.png',\n",
       "   'ROI/New/822_HE.png',\n",
       "   'ROI/New/823_HE.png',\n",
       "   'ROI/New/825_HE.png',\n",
       "   'ROI/New/828_HE.png',\n",
       "   'ROI/New/838_HE.png',\n",
       "   'ROI/New/847_HE.png',\n",
       "   'ROI/New/849_HE.png',\n",
       "   'ROI/New/855_HE.png',\n",
       "   'ROI/New/858_HE.png',\n",
       "   'ROI/New/859_HE.png',\n",
       "   'ROI/New/860_HE.png',\n",
       "   'ROI/New/865_HE.png',\n",
       "   'ROI/New/866_HE.png',\n",
       "   'ROI/New/868_HE.png',\n",
       "   'ROI/New/869_HE.png',\n",
       "   'ROI/New/870_HE.png',\n",
       "   'ROI/New/873_HE.png',\n",
       "   'ROI/New/874_HE.png',\n",
       "   'ROI/New/878_HE.png',\n",
       "   'ROI/New/892_HE.png',\n",
       "   'ROI/New/900_HE.png',\n",
       "   'ROI/New/929_HE.png',\n",
       "   'ROI/New/936_HE.png',\n",
       "   'ROI/New/942_HE.png',\n",
       "   'ROI/New/952_HE.png',\n",
       "   'ROI/New/957_HE.png',\n",
       "   'ROI/New/970_HE.png',\n",
       "   'ROI/New/975_HE.png',\n",
       "   'ROI/New/980_HE.png',\n",
       "   'ROI/New/981_HE.png',\n",
       "   'ROI/New/992_HE.png',\n",
       "   'ROI/New/996_HE.png',\n",
       "   'ROI/New/1003_HE.png',\n",
       "   'ROI/New/1018_HE.png',\n",
       "   'ROI/New/1031_HE.png',\n",
       "   'ROI/New/1036_HE.png',\n",
       "   'ROI/New/1044_HE.png',\n",
       "   'ROI/New/1048_HE.png',\n",
       "   'ROI/New/1056_HE.png',\n",
       "   'ROI/New/1079_HE.png',\n",
       "   'ROI/New/1083_HE.png',\n",
       "   'ROI/New/1104_HE.png',\n",
       "   'ROI/New/1124_HE.png',\n",
       "   'ROI/New/1126_HE.png',\n",
       "   'ROI/New/1131_HE.png',\n",
       "   'ROI/New/1135_HE.png',\n",
       "   'ROI/New/1156_HE.png',\n",
       "   'ROI/New/1164_HE.png',\n",
       "   'ROI/New/1165_HE.png',\n",
       "   'ROI/New/1173_HE.png',\n",
       "   'ROI/New/1181_HE.png',\n",
       "   'ROI/New/1183_HE.png',\n",
       "   'ROI/New/1189_HE.png',\n",
       "   'ROI/New/1660000_HE.png',\n",
       "   'ROI/New/2450000_HE.png',\n",
       "   'ROI/New/20200000_HE.png',\n",
       "   'ROI/New/201690000_HE.png',\n",
       "   'ROI/New/201710000_HE.png',\n",
       "   'ROI/New/201720000_HE.png',\n",
       "   'ROI/New/201790000_HE.png',\n",
       "   'ROI/New/202040000_HE.png',\n",
       "   'ROI/New/202210000_HE.png',\n",
       "   'ROI/New/202280000_HE.png',\n",
       "   'ROI/New/2017170000_HE.png',\n",
       "   'ROI/New/2018120000_HE.png',\n",
       "   'ROI/New/2018160000_HE.png',\n",
       "   'ROI/New/2019100000_HE.png',\n",
       "   'ROI/New/2019120000_HE.png',\n",
       "   'ROI/New/2022170000_HE.png',\n",
       "   'ROI/New/2022220000_HE.png',\n",
       "   'ROI/New/2022230000_HE.png',\n",
       "   'ROI/New/5_HE.png',\n",
       "   'ROI/New/14_HE.png',\n",
       "   'ROI/New/17_HE.png',\n",
       "   'ROI/New/22_HE.png',\n",
       "   'ROI/New/26_HE.png',\n",
       "   'ROI/New/28_HE.png',\n",
       "   'ROI/New/29_HE.png',\n",
       "   'ROI/New/41_HE.png',\n",
       "   'ROI/New/66_HE.png',\n",
       "   'ROI/New/69_HE.png',\n",
       "   'ROI/New/71_HE.png',\n",
       "   'ROI/New/77_HE.png',\n",
       "   'ROI/New/100_HE.png',\n",
       "   'ROI/New/108_HE.png',\n",
       "   'ROI/New/109_HE.png',\n",
       "   'ROI/New/110_HE.png',\n",
       "   'ROI/New/121_HE.png',\n",
       "   'ROI/New/126_HE.png',\n",
       "   'ROI/New/130_HE.png',\n",
       "   'ROI/New/139_HE.png',\n",
       "   'ROI/New/141_HE.png',\n",
       "   'ROI/New/145_HE.png',\n",
       "   'ROI/New/148_HE.png',\n",
       "   'ROI/New/150_HE.png',\n",
       "   'ROI/New/162_HE.png',\n",
       "   'ROI/New/164_HE.png',\n",
       "   'ROI/New/166_HE.png',\n",
       "   'ROI/New/168_HE.png',\n",
       "   'ROI/New/173_HE.png',\n",
       "   'ROI/New/176_HE.png',\n",
       "   'ROI/New/177_HE.png',\n",
       "   'ROI/New/181_HE.png',\n",
       "   'ROI/New/182_HE.png',\n",
       "   'ROI/New/183_HE.png',\n",
       "   'ROI/New/184_HE.png',\n",
       "   'ROI/New/185_HE.png',\n",
       "   'ROI/New/186_HE.png',\n",
       "   'ROI/New/187_HE.png',\n",
       "   'ROI/New/189_HE.png',\n",
       "   'ROI/New/200_HE.png',\n",
       "   'ROI/New/204_HE.png',\n",
       "   'ROI/New/206_HE.png',\n",
       "   'ROI/New/218_HE.png',\n",
       "   'ROI/New/220_HE.png',\n",
       "   'ROI/New/230_HE.png',\n",
       "   'ROI/New/245_HE.png',\n",
       "   'ROI/New/253_HE.png',\n",
       "   'ROI/New/270_HE.png',\n",
       "   'ROI/New/271_HE.png',\n",
       "   'ROI/New/281_HE.png',\n",
       "   'ROI/New/293_HE.png',\n",
       "   'ROI/New/295_HE.png',\n",
       "   'ROI/New/299_HE.png',\n",
       "   'ROI/New/308_HE.png',\n",
       "   'ROI/New/309_HE.png',\n",
       "   'ROI/New/316_HE.png',\n",
       "   'ROI/New/320_HE.png',\n",
       "   'ROI/New/321_HE.png',\n",
       "   'ROI/New/347_HE.png',\n",
       "   'ROI/New/348_HE.png',\n",
       "   'ROI/New/350_HE.png',\n",
       "   'ROI/New/368_HE.png',\n",
       "   'ROI/New/376_HE.png',\n",
       "   'ROI/New/382_HE.png',\n",
       "   'ROI/New/386_HE.png',\n",
       "   'ROI/New/395_HE.png',\n",
       "   'ROI/New/399_HE.png',\n",
       "   'ROI/New/411_HE.png',\n",
       "   'ROI/New/413_HE.png',\n",
       "   'ROI/New/419_HE.png',\n",
       "   'ROI/New/433_HE.png',\n",
       "   'ROI/New/436_HE.png',\n",
       "   'ROI/New/437_HE.png',\n",
       "   'ROI/New/454_HE.png',\n",
       "   'ROI/New/458_HE.png',\n",
       "   'ROI/New/462_HE.png',\n",
       "   'ROI/New/463_HE.png',\n",
       "   'ROI/New/472_HE.png',\n",
       "   'ROI/New/474_HE.png',\n",
       "   'ROI/New/476_HE.png',\n",
       "   'ROI/New/478_HE.png',\n",
       "   'ROI/New/484_HE.png',\n",
       "   'ROI/New/489_HE.png',\n",
       "   'ROI/New/492_HE.png',\n",
       "   'ROI/New/497_HE.png',\n",
       "   'ROI/New/506_HE.png',\n",
       "   'ROI/New/541_HE.png']]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T08:33:54.630766Z",
     "start_time": "2022-01-13T08:33:54.623019Z"
    }
   },
   "outputs": [],
   "source": [
    "# # train_patient = ['2120737','2091197','2181633','2219487','2013713','2202545','2169164','2228384','2204600','2167546','2097782','2213245','2205867','2195929','2108941','2197912','2232197','2091069','0867365','2172317']\n",
    "# # val_patient = ['2098098','2132226','2022898','2090880','2213752']\n",
    "# # test_patient = ['0790305','2200290','2103280','2192712','2193810','2075521','2206976']\n",
    "\n",
    "# # train_patient,test_patient = train_test_split(all_patient,test_size=0.2)\n",
    "# kf = KFold(n_splits=5, random_state=5, shuffle=True)\n",
    "# fold = []\n",
    "# for train_index, test_index in kf.split(all_patient):\n",
    "#     train_patient, test_patient = all_patient[train_index.astype(int)], all_patient[test_index.astype(int)]\n",
    "#     train_patient, val_patient = train_test_split(train_patient,test_size=0.2)\n",
    "#     testset = [npy_path+'{}_mask.npy'.format(p) for p in test_patient]\n",
    "#     print(test_patient, train_patient)\n",
    "#     trainset = [npy_path+'{}_mask.npy'.format(p) for p in train_patient]\n",
    "#     valset = [npy_path+'{}_mask.npy'.format(p) for p in val_patient]\n",
    "#     fold.append({'trainset':trainset, 'valset':valset, 'testset':testset})\n",
    "#     print(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict(rotation_range=10.,\n",
    "                    width_shift_range=0.1,\n",
    "                    height_shift_range=0.1,\n",
    "                    zoom_range=0.2, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T05:57:24.532325Z",
     "start_time": "2022-01-24T05:57:24.523232Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (940, 512, 512, 3) \n",
      "masks : (940, 512, 512)\n",
      "------------------------------\n",
      "img :  253.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "==============================\n",
      "------------------------------\n",
      "load unet model\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3098183/3082630395.py:38: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"get_att_unet\" failed type inference due to: Untyped global name 'Input': Cannot determine Numba type of <class 'function'>\n",
      "\n",
      "File \"../../../../../../tmp/ipykernel_3098183/3082630395.py\", line 40:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  @jit\n",
      "/data01/anaconda3/envs/jeon2/lib/python3.7/site-packages/numba/core/object_mode_passes.py:152: NumbaWarning: Function \"get_att_unet\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"../../../../../../tmp/ipykernel_3098183/3082630395.py\", line 38:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/data01/anaconda3/envs/jeon2/lib/python3.7/site-packages/numba/core/object_mode_passes.py:162: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../../../../../../tmp/ipykernel_3098183/3082630395.py\", line 38:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/tmp/ipykernel_3098183/3082630395.py:4: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"AttnBlock2D\" failed type inference due to: Untyped global name 'Conv2D': Cannot determine Numba type of <class 'type'>\n",
      "\n",
      "File \"../../../../../../tmp/ipykernel_3098183/3082630395.py\", line 7:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  @jit\n",
      "/data01/anaconda3/envs/jeon2/lib/python3.7/site-packages/numba/core/object_mode_passes.py:152: NumbaWarning: Function \"AttnBlock2D\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"../../../../../../tmp/ipykernel_3098183/3082630395.py\", line 4:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/data01/anaconda3/envs/jeon2/lib/python3.7/site-packages/numba/core/object_mode_passes.py:162: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../../../../../../tmp/ipykernel_3098183/3082630395.py\", line 4:\n",
      "<source missing, REPL/exec in use?>\n",
      "\n",
      "  state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "start training\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 10:33:59.534377: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 10:34:02.107215: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 43s 156ms/step - loss: 0.2856 - acc: 0.8581 - binary_crossentropy: 0.4262 - recall: 0.9091 - val_loss: 0.5170 - val_acc: 0.4546 - val_binary_crossentropy: 1.9878 - val_recall: 0.9987\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.51696, saving model to 6_result/exp_fold0/model/best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data01/anaconda3/envs/jeon2/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "188/188 [==============================] - 28s 148ms/step - loss: 0.1649 - acc: 0.9413 - binary_crossentropy: 0.2289 - recall: 0.9440 - val_loss: 0.3964 - val_acc: 0.6874 - val_binary_crossentropy: 1.3804 - val_recall: 0.9877\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.51696 to 0.39641, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.1217 - acc: 0.9603 - binary_crossentropy: 0.1634 - recall: 0.9537 - val_loss: 0.1674 - val_acc: 0.9256 - val_binary_crossentropy: 0.3235 - val_recall: 0.9552\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.39641 to 0.16740, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 29s 152ms/step - loss: 0.0941 - acc: 0.9700 - binary_crossentropy: 0.1265 - recall: 0.9592 - val_loss: 0.1394 - val_acc: 0.9494 - val_binary_crossentropy: 0.1717 - val_recall: 0.8468\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.16740 to 0.13935, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0772 - acc: 0.9743 - binary_crossentropy: 0.1103 - recall: 0.9625 - val_loss: 0.1132 - val_acc: 0.9576 - val_binary_crossentropy: 0.1534 - val_recall: 0.8803\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.13935 to 0.11322, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 29s 152ms/step - loss: 0.0648 - acc: 0.9775 - binary_crossentropy: 0.0985 - recall: 0.9665 - val_loss: 0.1094 - val_acc: 0.9487 - val_binary_crossentropy: 0.2598 - val_recall: 0.9801\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.11322 to 0.10942, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0571 - acc: 0.9792 - binary_crossentropy: 0.0927 - recall: 0.9668 - val_loss: 0.0642 - val_acc: 0.9748 - val_binary_crossentropy: 0.1101 - val_recall: 0.9512\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.10942 to 0.06421, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 29s 154ms/step - loss: 0.0501 - acc: 0.9809 - binary_crossentropy: 0.0856 - recall: 0.9698 - val_loss: 0.0582 - val_acc: 0.9760 - val_binary_crossentropy: 0.1100 - val_recall: 0.9667\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.06421 to 0.05821, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 29s 156ms/step - loss: 0.0450 - acc: 0.9825 - binary_crossentropy: 0.0807 - recall: 0.9701 - val_loss: 0.0979 - val_acc: 0.9566 - val_binary_crossentropy: 0.1862 - val_recall: 0.8650\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05821\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 29s 156ms/step - loss: 0.0440 - acc: 0.9818 - binary_crossentropy: 0.0854 - recall: 0.9697 - val_loss: 0.0733 - val_acc: 0.9670 - val_binary_crossentropy: 0.1534 - val_recall: 0.9186\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05821\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 29s 154ms/step - loss: 0.0395 - acc: 0.9833 - binary_crossentropy: 0.0795 - recall: 0.9707 - val_loss: 0.0567 - val_acc: 0.9735 - val_binary_crossentropy: 0.1339 - val_recall: 0.9573\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.05821 to 0.05670, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 30s 160ms/step - loss: 0.0354 - acc: 0.9848 - binary_crossentropy: 0.0740 - recall: 0.9739 - val_loss: 0.0519 - val_acc: 0.9753 - val_binary_crossentropy: 0.1291 - val_recall: 0.9660\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.05670 to 0.05188, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 30s 158ms/step - loss: 0.0319 - acc: 0.9863 - binary_crossentropy: 0.0686 - recall: 0.9754 - val_loss: 0.0438 - val_acc: 0.9794 - val_binary_crossentropy: 0.1070 - val_recall: 0.9660\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.05188 to 0.04382, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 29s 156ms/step - loss: 0.0289 - acc: 0.9873 - binary_crossentropy: 0.0634 - recall: 0.9779 - val_loss: 0.0619 - val_acc: 0.9683 - val_binary_crossentropy: 0.1892 - val_recall: 0.9732\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.04382\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0281 - acc: 0.9874 - binary_crossentropy: 0.0642 - recall: 0.9768 - val_loss: 0.0514 - val_acc: 0.9752 - val_binary_crossentropy: 0.1308 - val_recall: 0.9394\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.04382\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 29s 152ms/step - loss: 0.0272 - acc: 0.9875 - binary_crossentropy: 0.0639 - recall: 0.9780 - val_loss: 0.1405 - val_acc: 0.9357 - val_binary_crossentropy: 0.3291 - val_recall: 0.7770\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.04382\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0317 - acc: 0.9849 - binary_crossentropy: 0.0802 - recall: 0.9732 - val_loss: 0.2515 - val_acc: 0.8924 - val_binary_crossentropy: 0.5879 - val_recall: 0.6303\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.04382\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0300 - acc: 0.9857 - binary_crossentropy: 0.0778 - recall: 0.9732 - val_loss: 0.0435 - val_acc: 0.9783 - val_binary_crossentropy: 0.1241 - val_recall: 0.9604\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.04382 to 0.04347, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 29s 154ms/step - loss: 0.0244 - acc: 0.9884 - binary_crossentropy: 0.0629 - recall: 0.9780 - val_loss: 0.0417 - val_acc: 0.9789 - val_binary_crossentropy: 0.1283 - val_recall: 0.9642\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.04347 to 0.04175, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0224 - acc: 0.9893 - binary_crossentropy: 0.0582 - recall: 0.9793 - val_loss: 0.0406 - val_acc: 0.9795 - val_binary_crossentropy: 0.1247 - val_recall: 0.9572\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.04175 to 0.04065, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0215 - acc: 0.9897 - binary_crossentropy: 0.0560 - recall: 0.9798 - val_loss: 0.0410 - val_acc: 0.9790 - val_binary_crossentropy: 0.1372 - val_recall: 0.9687\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.04065\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0212 - acc: 0.9897 - binary_crossentropy: 0.0558 - recall: 0.9799 - val_loss: 0.1781 - val_acc: 0.9186 - val_binary_crossentropy: 0.4516 - val_recall: 0.7255\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.04065\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0225 - acc: 0.9889 - binary_crossentropy: 0.0632 - recall: 0.9792 - val_loss: 0.1158 - val_acc: 0.9448 - val_binary_crossentropy: 0.3321 - val_recall: 0.8161\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.04065\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 29s 155ms/step - loss: 0.0203 - acc: 0.9901 - binary_crossentropy: 0.0581 - recall: 0.9802 - val_loss: 0.0409 - val_acc: 0.9791 - val_binary_crossentropy: 0.1334 - val_recall: 0.9544\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.04065\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0189 - acc: 0.9907 - binary_crossentropy: 0.0536 - recall: 0.9813 - val_loss: 0.0382 - val_acc: 0.9803 - val_binary_crossentropy: 0.1329 - val_recall: 0.9634\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.04065 to 0.03819, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 28s 148ms/step - loss: 0.0177 - acc: 0.9912 - binary_crossentropy: 0.0515 - recall: 0.9832 - val_loss: 0.0390 - val_acc: 0.9800 - val_binary_crossentropy: 0.1348 - val_recall: 0.9546\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.03819\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0236 - acc: 0.9880 - binary_crossentropy: 0.0725 - recall: 0.9770 - val_loss: 0.0780 - val_acc: 0.9611 - val_binary_crossentropy: 0.2449 - val_recall: 0.8874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00027: val_loss did not improve from 0.03819\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0231 - acc: 0.9883 - binary_crossentropy: 0.0727 - recall: 0.9776 - val_loss: 0.1341 - val_acc: 0.9203 - val_binary_crossentropy: 0.6205 - val_recall: 0.9750\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.03819\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0259 - acc: 0.9866 - binary_crossentropy: 0.0835 - recall: 0.9752 - val_loss: 0.0764 - val_acc: 0.9614 - val_binary_crossentropy: 0.2563 - val_recall: 0.8994\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.03819\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0205 - acc: 0.9896 - binary_crossentropy: 0.0673 - recall: 0.9793 - val_loss: 0.0435 - val_acc: 0.9769 - val_binary_crossentropy: 0.1718 - val_recall: 0.9728\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.03819\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0177 - acc: 0.9910 - binary_crossentropy: 0.0578 - recall: 0.9819 - val_loss: 0.0367 - val_acc: 0.9808 - val_binary_crossentropy: 0.1393 - val_recall: 0.9660\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.03819 to 0.03671, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0173 - acc: 0.9913 - binary_crossentropy: 0.0557 - recall: 0.9821 - val_loss: 0.0366 - val_acc: 0.9809 - val_binary_crossentropy: 0.1391 - val_recall: 0.9648\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.03671 to 0.03662, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - 29s 152ms/step - loss: 0.0168 - acc: 0.9915 - binary_crossentropy: 0.0548 - recall: 0.9828 - val_loss: 0.0365 - val_acc: 0.9810 - val_binary_crossentropy: 0.1394 - val_recall: 0.9648\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.03662 to 0.03649, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 28s 148ms/step - loss: 0.0165 - acc: 0.9917 - binary_crossentropy: 0.0537 - recall: 0.9831 - val_loss: 0.0363 - val_acc: 0.9810 - val_binary_crossentropy: 0.1398 - val_recall: 0.9648\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.03649 to 0.03634, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 28s 148ms/step - loss: 0.0163 - acc: 0.9918 - binary_crossentropy: 0.0530 - recall: 0.9832 - val_loss: 0.0364 - val_acc: 0.9810 - val_binary_crossentropy: 0.1412 - val_recall: 0.9649\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.03634\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0160 - acc: 0.9919 - binary_crossentropy: 0.0526 - recall: 0.9835 - val_loss: 0.0366 - val_acc: 0.9809 - val_binary_crossentropy: 0.1422 - val_recall: 0.9646\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.03634\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0158 - acc: 0.9920 - binary_crossentropy: 0.0518 - recall: 0.9836 - val_loss: 0.0366 - val_acc: 0.9809 - val_binary_crossentropy: 0.1430 - val_recall: 0.9640\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.03634\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0156 - acc: 0.9921 - binary_crossentropy: 0.0512 - recall: 0.9838 - val_loss: 0.0364 - val_acc: 0.9810 - val_binary_crossentropy: 0.1440 - val_recall: 0.9652\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.03634\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0154 - acc: 0.9922 - binary_crossentropy: 0.0506 - recall: 0.9840 - val_loss: 0.0365 - val_acc: 0.9809 - val_binary_crossentropy: 0.1449 - val_recall: 0.9645\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.03634\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0150 - acc: 0.9924 - binary_crossentropy: 0.0500 - recall: 0.9844 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1460 - val_recall: 0.9655\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.03634\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0152 - acc: 0.9924 - binary_crossentropy: 0.0495 - recall: 0.9841 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1461 - val_recall: 0.9656\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.03634\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0151 - acc: 0.9924 - binary_crossentropy: 0.0494 - recall: 0.9842 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1462 - val_recall: 0.9655\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.03634\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0150 - acc: 0.9924 - binary_crossentropy: 0.0493 - recall: 0.9844 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1463 - val_recall: 0.9654\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.03634\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0151 - acc: 0.9924 - binary_crossentropy: 0.0492 - recall: 0.9842 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1468 - val_recall: 0.9657\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.03634\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0151 - acc: 0.9924 - binary_crossentropy: 0.0492 - recall: 0.9843 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1468 - val_recall: 0.9656\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.03634\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0151 - acc: 0.9924 - binary_crossentropy: 0.0494 - recall: 0.9843 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1468 - val_recall: 0.9655\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.03634\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0150 - acc: 0.9924 - binary_crossentropy: 0.0492 - recall: 0.9844 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1470 - val_recall: 0.9657\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.03634\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - 28s 148ms/step - loss: 0.0151 - acc: 0.9925 - binary_crossentropy: 0.0489 - recall: 0.9842 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1468 - val_recall: 0.9655\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.03634\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0151 - acc: 0.9924 - binary_crossentropy: 0.0491 - recall: 0.9842 - val_loss: 0.0365 - val_acc: 0.9809 - val_binary_crossentropy: 0.1469 - val_recall: 0.9656\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.03634\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0150 - acc: 0.9924 - binary_crossentropy: 0.0493 - recall: 0.9844 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1468 - val_recall: 0.9655\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.03634\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0152 - acc: 0.9924 - binary_crossentropy: 0.0487 - recall: 0.9840 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1468 - val_recall: 0.9657\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.03634\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0150 - acc: 0.9924 - binary_crossentropy: 0.0492 - recall: 0.9844 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1469 - val_recall: 0.9655\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.03634\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0150 - acc: 0.9924 - binary_crossentropy: 0.0492 - recall: 0.9843 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1469 - val_recall: 0.9657\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.03634\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0151 - acc: 0.9924 - binary_crossentropy: 0.0494 - recall: 0.9842 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1468 - val_recall: 0.9654\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.03634\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 00054: early stopping\n",
      "save model\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (940, 512, 512, 3) \n",
      "masks : (940, 512, 512)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "==============================\n",
      "------------------------------\n",
      "load unet model\n",
      "------------------------------\n",
      "------------------------------\n",
      "start training\n",
      "------------------------------\n",
      "Epoch 1/100\n",
      "188/188 [==============================] - 30s 151ms/step - loss: 0.2823 - acc: 0.8543 - binary_crossentropy: 0.4711 - recall: 0.9247 - val_loss: 0.5332 - val_acc: 0.4069 - val_binary_crossentropy: 2.5183 - val_recall: 0.9997\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.53324, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 28s 147ms/step - loss: 0.1727 - acc: 0.9400 - binary_crossentropy: 0.2538 - recall: 0.9548 - val_loss: 0.4582 - val_acc: 0.5807 - val_binary_crossentropy: 2.5404 - val_recall: 0.9883\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.53324 to 0.45819, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.1290 - acc: 0.9623 - binary_crossentropy: 0.1732 - recall: 0.9616 - val_loss: 0.2017 - val_acc: 0.9298 - val_binary_crossentropy: 0.2294 - val_recall: 0.8150\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.45819 to 0.20172, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 29s 156ms/step - loss: 0.1042 - acc: 0.9700 - binary_crossentropy: 0.1428 - recall: 0.9655 - val_loss: 0.1396 - val_acc: 0.9479 - val_binary_crossentropy: 0.2381 - val_recall: 0.9459\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.20172 to 0.13964, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 29s 153ms/step - loss: 0.0853 - acc: 0.9753 - binary_crossentropy: 0.1201 - recall: 0.9675 - val_loss: 0.1041 - val_acc: 0.9643 - val_binary_crossentropy: 0.1789 - val_recall: 0.9620\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.13964 to 0.10413, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 30s 159ms/step - loss: 0.0722 - acc: 0.9782 - binary_crossentropy: 0.1068 - recall: 0.9686 - val_loss: 0.0947 - val_acc: 0.9661 - val_binary_crossentropy: 0.1640 - val_recall: 0.9493\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.10413 to 0.09472, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0622 - acc: 0.9801 - binary_crossentropy: 0.0973 - recall: 0.9709 - val_loss: 0.3491 - val_acc: 0.7315 - val_binary_crossentropy: 1.9727 - val_recall: 0.9857\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09472\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 29s 153ms/step - loss: 0.0604 - acc: 0.9785 - binary_crossentropy: 0.1064 - recall: 0.9664 - val_loss: 0.1186 - val_acc: 0.9451 - val_binary_crossentropy: 0.2902 - val_recall: 0.9366\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09472\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0501 - acc: 0.9823 - binary_crossentropy: 0.0892 - recall: 0.9710 - val_loss: 0.0717 - val_acc: 0.9713 - val_binary_crossentropy: 0.1382 - val_recall: 0.9357\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.09472 to 0.07169, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0451 - acc: 0.9834 - binary_crossentropy: 0.0850 - recall: 0.9736 - val_loss: 0.0629 - val_acc: 0.9745 - val_binary_crossentropy: 0.1256 - val_recall: 0.9423\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.07169 to 0.06294, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0395 - acc: 0.9853 - binary_crossentropy: 0.0768 - recall: 0.9752 - val_loss: 0.0696 - val_acc: 0.9702 - val_binary_crossentropy: 0.1487 - val_recall: 0.9294\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.06294\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0365 - acc: 0.9859 - binary_crossentropy: 0.0743 - recall: 0.9757 - val_loss: 0.0936 - val_acc: 0.9529 - val_binary_crossentropy: 0.3079 - val_recall: 0.9603\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.06294\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0353 - acc: 0.9858 - binary_crossentropy: 0.0746 - recall: 0.9746 - val_loss: 0.1609 - val_acc: 0.9287 - val_binary_crossentropy: 0.3348 - val_recall: 0.7605\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.06294\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0362 - acc: 0.9845 - binary_crossentropy: 0.0834 - recall: 0.9729 - val_loss: 0.0702 - val_acc: 0.9662 - val_binary_crossentropy: 0.2092 - val_recall: 0.9543\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.06294\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 29s 153ms/step - loss: 0.0300 - acc: 0.9874 - binary_crossentropy: 0.0682 - recall: 0.9772 - val_loss: 0.0651 - val_acc: 0.9686 - val_binary_crossentropy: 0.1932 - val_recall: 0.9584\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.06294\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 28s 148ms/step - loss: 0.0277 - acc: 0.9883 - binary_crossentropy: 0.0647 - recall: 0.9808 - val_loss: 0.0517 - val_acc: 0.9759 - val_binary_crossentropy: 0.1511 - val_recall: 0.9634\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.06294 to 0.05174, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0264 - acc: 0.9890 - binary_crossentropy: 0.0599 - recall: 0.9798 - val_loss: 0.0498 - val_acc: 0.9772 - val_binary_crossentropy: 0.1355 - val_recall: 0.9555\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.05174 to 0.04982, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 29s 153ms/step - loss: 0.0259 - acc: 0.9893 - binary_crossentropy: 0.0585 - recall: 0.9801 - val_loss: 0.0495 - val_acc: 0.9772 - val_binary_crossentropy: 0.1378 - val_recall: 0.9577\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.04982 to 0.04952, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0255 - acc: 0.9895 - binary_crossentropy: 0.0571 - recall: 0.9804 - val_loss: 0.0498 - val_acc: 0.9770 - val_binary_crossentropy: 0.1394 - val_recall: 0.9568\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.04952\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0247 - acc: 0.9897 - binary_crossentropy: 0.0552 - recall: 0.9818 - val_loss: 0.0512 - val_acc: 0.9760 - val_binary_crossentropy: 0.1531 - val_recall: 0.9628\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.04952\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0245 - acc: 0.9898 - binary_crossentropy: 0.0554 - recall: 0.9809 - val_loss: 0.0492 - val_acc: 0.9773 - val_binary_crossentropy: 0.1375 - val_recall: 0.9560\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.04952 to 0.04923, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0241 - acc: 0.9900 - binary_crossentropy: 0.0546 - recall: 0.9812 - val_loss: 0.0491 - val_acc: 0.9773 - val_binary_crossentropy: 0.1391 - val_recall: 0.9568\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.04923 to 0.04912, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 29s 152ms/step - loss: 0.0237 - acc: 0.9902 - binary_crossentropy: 0.0535 - recall: 0.9813 - val_loss: 0.0493 - val_acc: 0.9770 - val_binary_crossentropy: 0.1437 - val_recall: 0.9594\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.04912\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 28s 148ms/step - loss: 0.0234 - acc: 0.9904 - binary_crossentropy: 0.0524 - recall: 0.9815 - val_loss: 0.0490 - val_acc: 0.9771 - val_binary_crossentropy: 0.1419 - val_recall: 0.9572\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.04912 to 0.04903, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0229 - acc: 0.9905 - binary_crossentropy: 0.0517 - recall: 0.9818 - val_loss: 0.0492 - val_acc: 0.9771 - val_binary_crossentropy: 0.1432 - val_recall: 0.9560\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.04903\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0225 - acc: 0.9907 - binary_crossentropy: 0.0508 - recall: 0.9820 - val_loss: 0.0492 - val_acc: 0.9770 - val_binary_crossentropy: 0.1446 - val_recall: 0.9560\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.04903\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0220 - acc: 0.9908 - binary_crossentropy: 0.0497 - recall: 0.9823 - val_loss: 0.0490 - val_acc: 0.9770 - val_binary_crossentropy: 0.1447 - val_recall: 0.9557\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.04903 to 0.04896, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0220 - acc: 0.9907 - binary_crossentropy: 0.0502 - recall: 0.9832 - val_loss: 0.0493 - val_acc: 0.9767 - val_binary_crossentropy: 0.1490 - val_recall: 0.9574\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.04896\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0214 - acc: 0.9910 - binary_crossentropy: 0.0490 - recall: 0.9826 - val_loss: 0.0491 - val_acc: 0.9769 - val_binary_crossentropy: 0.1443 - val_recall: 0.9538\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.04896\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0211 - acc: 0.9912 - binary_crossentropy: 0.0481 - recall: 0.9825 - val_loss: 0.0490 - val_acc: 0.9768 - val_binary_crossentropy: 0.1485 - val_recall: 0.9560\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.04896\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0208 - acc: 0.9913 - binary_crossentropy: 0.0477 - recall: 0.9828 - val_loss: 0.0490 - val_acc: 0.9768 - val_binary_crossentropy: 0.1500 - val_recall: 0.9557\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.04896\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0201 - acc: 0.9915 - binary_crossentropy: 0.0471 - recall: 0.9833 - val_loss: 0.0488 - val_acc: 0.9768 - val_binary_crossentropy: 0.1513 - val_recall: 0.9565\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.04896 to 0.04875, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0200 - acc: 0.9915 - binary_crossentropy: 0.0465 - recall: 0.9841 - val_loss: 0.0570 - val_acc: 0.9724 - val_binary_crossentropy: 0.1796 - val_recall: 0.9500\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.04875\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0203 - acc: 0.9912 - binary_crossentropy: 0.0488 - recall: 0.9837 - val_loss: 0.0489 - val_acc: 0.9766 - val_binary_crossentropy: 0.1536 - val_recall: 0.9558\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.04875\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0196 - acc: 0.9916 - binary_crossentropy: 0.0465 - recall: 0.9833 - val_loss: 0.0489 - val_acc: 0.9767 - val_binary_crossentropy: 0.1512 - val_recall: 0.9517\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.04875\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0194 - acc: 0.9918 - binary_crossentropy: 0.0446 - recall: 0.9833 - val_loss: 0.0491 - val_acc: 0.9766 - val_binary_crossentropy: 0.1513 - val_recall: 0.9499\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.04875\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0190 - acc: 0.9919 - binary_crossentropy: 0.0430 - recall: 0.9836 - val_loss: 0.0498 - val_acc: 0.9762 - val_binary_crossentropy: 0.1538 - val_recall: 0.9474\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.04875\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0185 - acc: 0.9922 - binary_crossentropy: 0.0404 - recall: 0.9860 - val_loss: 0.0485 - val_acc: 0.9766 - val_binary_crossentropy: 0.1574 - val_recall: 0.9553\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.04875 to 0.04852, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0183 - acc: 0.9922 - binary_crossentropy: 0.0402 - recall: 0.9862 - val_loss: 0.0484 - val_acc: 0.9766 - val_binary_crossentropy: 0.1595 - val_recall: 0.9566\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.04852 to 0.04841, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0180 - acc: 0.9922 - binary_crossentropy: 0.0401 - recall: 0.9861 - val_loss: 0.0484 - val_acc: 0.9767 - val_binary_crossentropy: 0.1582 - val_recall: 0.9550\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.04841 to 0.04836, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0179 - acc: 0.9923 - binary_crossentropy: 0.0399 - recall: 0.9872 - val_loss: 0.0483 - val_acc: 0.9767 - val_binary_crossentropy: 0.1592 - val_recall: 0.9553\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.04836 to 0.04835, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0178 - acc: 0.9924 - binary_crossentropy: 0.0398 - recall: 0.9873 - val_loss: 0.0485 - val_acc: 0.9766 - val_binary_crossentropy: 0.1612 - val_recall: 0.9563\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.04835\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0177 - acc: 0.9923 - binary_crossentropy: 0.0399 - recall: 0.9864 - val_loss: 0.0484 - val_acc: 0.9766 - val_binary_crossentropy: 0.1599 - val_recall: 0.9548\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.04835\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0177 - acc: 0.9923 - binary_crossentropy: 0.0400 - recall: 0.9872 - val_loss: 0.0484 - val_acc: 0.9767 - val_binary_crossentropy: 0.1589 - val_recall: 0.9541\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.04835\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0178 - acc: 0.9922 - binary_crossentropy: 0.0408 - recall: 0.9883 - val_loss: 0.0484 - val_acc: 0.9766 - val_binary_crossentropy: 0.1603 - val_recall: 0.9551\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.04835\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0176 - acc: 0.9923 - binary_crossentropy: 0.0405 - recall: 0.9884 - val_loss: 0.0484 - val_acc: 0.9766 - val_binary_crossentropy: 0.1602 - val_recall: 0.9552\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.04835\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0175 - acc: 0.9923 - binary_crossentropy: 0.0403 - recall: 0.9884 - val_loss: 0.0484 - val_acc: 0.9766 - val_binary_crossentropy: 0.1603 - val_recall: 0.9551\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.04835\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0174 - acc: 0.9925 - binary_crossentropy: 0.0398 - recall: 0.9884 - val_loss: 0.0484 - val_acc: 0.9767 - val_binary_crossentropy: 0.1602 - val_recall: 0.9551\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.04835\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0174 - acc: 0.9925 - binary_crossentropy: 0.0398 - recall: 0.9884 - val_loss: 0.0484 - val_acc: 0.9767 - val_binary_crossentropy: 0.1600 - val_recall: 0.9548\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.04835\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0175 - acc: 0.9925 - binary_crossentropy: 0.0399 - recall: 0.9882 - val_loss: 0.0484 - val_acc: 0.9767 - val_binary_crossentropy: 0.1599 - val_recall: 0.9548\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.04835\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0175 - acc: 0.9924 - binary_crossentropy: 0.0402 - recall: 0.9881 - val_loss: 0.0484 - val_acc: 0.9767 - val_binary_crossentropy: 0.1602 - val_recall: 0.9551\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.04835\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0175 - acc: 0.9924 - binary_crossentropy: 0.0401 - recall: 0.9883 - val_loss: 0.0484 - val_acc: 0.9766 - val_binary_crossentropy: 0.1602 - val_recall: 0.9550\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.04835\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0174 - acc: 0.9924 - binary_crossentropy: 0.0398 - recall: 0.9881 - val_loss: 0.0484 - val_acc: 0.9767 - val_binary_crossentropy: 0.1602 - val_recall: 0.9551\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.04835\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0175 - acc: 0.9924 - binary_crossentropy: 0.0401 - recall: 0.9874 - val_loss: 0.0484 - val_acc: 0.9767 - val_binary_crossentropy: 0.1603 - val_recall: 0.9552\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.04835\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0175 - acc: 0.9924 - binary_crossentropy: 0.0399 - recall: 0.9884 - val_loss: 0.0484 - val_acc: 0.9767 - val_binary_crossentropy: 0.1600 - val_recall: 0.9548\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.04835\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0175 - acc: 0.9924 - binary_crossentropy: 0.0402 - recall: 0.9883 - val_loss: 0.0484 - val_acc: 0.9767 - val_binary_crossentropy: 0.1602 - val_recall: 0.9549\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.04835\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0175 - acc: 0.9924 - binary_crossentropy: 0.0399 - recall: 0.9883 - val_loss: 0.0484 - val_acc: 0.9767 - val_binary_crossentropy: 0.1602 - val_recall: 0.9550\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.04835\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0174 - acc: 0.9925 - binary_crossentropy: 0.0397 - recall: 0.9884 - val_loss: 0.0484 - val_acc: 0.9767 - val_binary_crossentropy: 0.1600 - val_recall: 0.9549\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.04835\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0174 - acc: 0.9925 - binary_crossentropy: 0.0396 - recall: 0.9883 - val_loss: 0.0484 - val_acc: 0.9766 - val_binary_crossentropy: 0.1600 - val_recall: 0.9547\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.04835\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0175 - acc: 0.9924 - binary_crossentropy: 0.0400 - recall: 0.9884 - val_loss: 0.0484 - val_acc: 0.9767 - val_binary_crossentropy: 0.1600 - val_recall: 0.9549\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.04835\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0173 - acc: 0.9925 - binary_crossentropy: 0.0395 - recall: 0.9882 - val_loss: 0.0484 - val_acc: 0.9767 - val_binary_crossentropy: 0.1603 - val_recall: 0.9551\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.04835\n",
      "Epoch 00061: early stopping\n",
      "save model\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (940, 512, 512, 3) \n",
      "masks : (940, 512, 512)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "==============================\n",
      "------------------------------\n",
      "load unet model\n",
      "------------------------------\n",
      "------------------------------\n",
      "start training\n",
      "------------------------------\n",
      "Epoch 1/100\n",
      "188/188 [==============================] - 30s 151ms/step - loss: 0.2950 - acc: 0.8588 - binary_crossentropy: 0.4388 - recall: 0.9171 - val_loss: 0.5434 - val_acc: 0.3864 - val_binary_crossentropy: 2.1674 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.54344, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.1747 - acc: 0.9438 - binary_crossentropy: 0.2269 - recall: 0.9440 - val_loss: 0.4575 - val_acc: 0.8021 - val_binary_crossentropy: 0.5256 - val_recall: 0.5337\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.54344 to 0.45748, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 28s 152ms/step - loss: 0.1284 - acc: 0.9630 - binary_crossentropy: 0.1595 - recall: 0.9565 - val_loss: 0.1576 - val_acc: 0.9404 - val_binary_crossentropy: 0.2540 - val_recall: 0.9651\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.45748 to 0.15763, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0998 - acc: 0.9720 - binary_crossentropy: 0.1247 - recall: 0.9640 - val_loss: 0.2483 - val_acc: 0.9069 - val_binary_crossentropy: 0.2645 - val_recall: 0.6721\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15763\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 29s 152ms/step - loss: 0.0912 - acc: 0.9706 - binary_crossentropy: 0.1296 - recall: 0.9591 - val_loss: 0.1145 - val_acc: 0.9603 - val_binary_crossentropy: 0.1696 - val_recall: 0.9210\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15763 to 0.11449, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0734 - acc: 0.9765 - binary_crossentropy: 0.1048 - recall: 0.9648 - val_loss: 0.0763 - val_acc: 0.9748 - val_binary_crossentropy: 0.1141 - val_recall: 0.9642\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.11449 to 0.07633, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 29s 153ms/step - loss: 0.0636 - acc: 0.9783 - binary_crossentropy: 0.0997 - recall: 0.9689 - val_loss: 0.1047 - val_acc: 0.9573 - val_binary_crossentropy: 0.1767 - val_recall: 0.9198\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07633\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0558 - acc: 0.9805 - binary_crossentropy: 0.0900 - recall: 0.9686 - val_loss: 0.0701 - val_acc: 0.9713 - val_binary_crossentropy: 0.1440 - val_recall: 0.9704\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.07633 to 0.07008, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0565 - acc: 0.9779 - binary_crossentropy: 0.1022 - recall: 0.9650 - val_loss: 0.1366 - val_acc: 0.9257 - val_binary_crossentropy: 0.4311 - val_recall: 0.9880\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07008\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 28s 148ms/step - loss: 0.0467 - acc: 0.9820 - binary_crossentropy: 0.0845 - recall: 0.9704 - val_loss: 0.0629 - val_acc: 0.9732 - val_binary_crossentropy: 0.1249 - val_recall: 0.9495\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.07008 to 0.06292, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0445 - acc: 0.9820 - binary_crossentropy: 0.0872 - recall: 0.9693 - val_loss: 0.0581 - val_acc: 0.9737 - val_binary_crossentropy: 0.1351 - val_recall: 0.9722\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.06292 to 0.05808, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0392 - acc: 0.9841 - binary_crossentropy: 0.0783 - recall: 0.9715 - val_loss: 0.0484 - val_acc: 0.9787 - val_binary_crossentropy: 0.1104 - val_recall: 0.9667\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.05808 to 0.04839, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0365 - acc: 0.9847 - binary_crossentropy: 0.0737 - recall: 0.9744 - val_loss: 0.1171 - val_acc: 0.9476 - val_binary_crossentropy: 0.2122 - val_recall: 0.8211\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.04839\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0338 - acc: 0.9855 - binary_crossentropy: 0.0737 - recall: 0.9744 - val_loss: 0.0447 - val_acc: 0.9793 - val_binary_crossentropy: 0.1075 - val_recall: 0.9589\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.04839 to 0.04471, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 28s 148ms/step - loss: 0.0304 - acc: 0.9869 - binary_crossentropy: 0.0672 - recall: 0.9755 - val_loss: 0.0428 - val_acc: 0.9799 - val_binary_crossentropy: 0.1099 - val_recall: 0.9653\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.04471 to 0.04281, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0285 - acc: 0.9876 - binary_crossentropy: 0.0641 - recall: 0.9766 - val_loss: 0.0463 - val_acc: 0.9780 - val_binary_crossentropy: 0.1208 - val_recall: 0.9530\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.04281\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0398 - acc: 0.9809 - binary_crossentropy: 0.1015 - recall: 0.9684 - val_loss: 0.1159 - val_acc: 0.9414 - val_binary_crossentropy: 0.3636 - val_recall: 0.9029\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.04281\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 29s 153ms/step - loss: 0.0358 - acc: 0.9831 - binary_crossentropy: 0.0913 - recall: 0.9686 - val_loss: 0.0498 - val_acc: 0.9757 - val_binary_crossentropy: 0.1315 - val_recall: 0.9417\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.04281\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0290 - acc: 0.9864 - binary_crossentropy: 0.0739 - recall: 0.9751 - val_loss: 0.0412 - val_acc: 0.9797 - val_binary_crossentropy: 0.1201 - val_recall: 0.9635\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.04281 to 0.04124, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0260 - acc: 0.9878 - binary_crossentropy: 0.0669 - recall: 0.9764 - val_loss: 0.0483 - val_acc: 0.9762 - val_binary_crossentropy: 0.1349 - val_recall: 0.9399\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.04124\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0256 - acc: 0.9878 - binary_crossentropy: 0.0681 - recall: 0.9774 - val_loss: 0.0769 - val_acc: 0.9622 - val_binary_crossentropy: 0.2085 - val_recall: 0.8887\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.04124\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0240 - acc: 0.9885 - binary_crossentropy: 0.0648 - recall: 0.9776 - val_loss: 0.0412 - val_acc: 0.9794 - val_binary_crossentropy: 0.1250 - val_recall: 0.9525\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.04124 to 0.04118, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0244 - acc: 0.9882 - binary_crossentropy: 0.0658 - recall: 0.9779 - val_loss: 0.0392 - val_acc: 0.9801 - val_binary_crossentropy: 0.1279 - val_recall: 0.9630\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.04118 to 0.03924, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 29s 154ms/step - loss: 0.0232 - acc: 0.9889 - binary_crossentropy: 0.0656 - recall: 0.9776 - val_loss: 0.0405 - val_acc: 0.9792 - val_binary_crossentropy: 0.1408 - val_recall: 0.9694\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.03924\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0215 - acc: 0.9896 - binary_crossentropy: 0.0609 - recall: 0.9789 - val_loss: 0.0393 - val_acc: 0.9800 - val_binary_crossentropy: 0.1329 - val_recall: 0.9577\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.03924\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0317 - acc: 0.9838 - binary_crossentropy: 0.1024 - recall: 0.9707 - val_loss: 0.0467 - val_acc: 0.9763 - val_binary_crossentropy: 0.1529 - val_recall: 0.9434\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.03924\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0234 - acc: 0.9884 - binary_crossentropy: 0.0726 - recall: 0.9768 - val_loss: 0.0389 - val_acc: 0.9800 - val_binary_crossentropy: 0.1392 - val_recall: 0.9616\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.03924 to 0.03890, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0248 - acc: 0.9877 - binary_crossentropy: 0.0768 - recall: 0.9752 - val_loss: 0.0697 - val_acc: 0.9649 - val_binary_crossentropy: 0.2368 - val_recall: 0.9004\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.03890\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0213 - acc: 0.9892 - binary_crossentropy: 0.0693 - recall: 0.9795 - val_loss: 0.0597 - val_acc: 0.9682 - val_binary_crossentropy: 0.2421 - val_recall: 0.9661\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.03890\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0202 - acc: 0.9899 - binary_crossentropy: 0.0655 - recall: 0.9794 - val_loss: 0.0554 - val_acc: 0.9720 - val_binary_crossentropy: 0.1920 - val_recall: 0.9190\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.03890\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0209 - acc: 0.9894 - binary_crossentropy: 0.0708 - recall: 0.9799 - val_loss: 0.0380 - val_acc: 0.9803 - val_binary_crossentropy: 0.1460 - val_recall: 0.9600\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.03890 to 0.03803, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 29s 152ms/step - loss: 0.0187 - acc: 0.9906 - binary_crossentropy: 0.0632 - recall: 0.9806 - val_loss: 0.0366 - val_acc: 0.9810 - val_binary_crossentropy: 0.1473 - val_recall: 0.9641\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.03803 to 0.03656, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0180 - acc: 0.9910 - binary_crossentropy: 0.0611 - recall: 0.9812 - val_loss: 0.0373 - val_acc: 0.9806 - val_binary_crossentropy: 0.1503 - val_recall: 0.9605\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.03656\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0173 - acc: 0.9912 - binary_crossentropy: 0.0613 - recall: 0.9818 - val_loss: 0.0366 - val_acc: 0.9809 - val_binary_crossentropy: 0.1545 - val_recall: 0.9647\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.03656\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0178 - acc: 0.9910 - binary_crossentropy: 0.0633 - recall: 0.9811 - val_loss: 0.1424 - val_acc: 0.9321 - val_binary_crossentropy: 0.5128 - val_recall: 0.7912\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.03656\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0250 - acc: 0.9872 - binary_crossentropy: 0.0942 - recall: 0.9748 - val_loss: 0.0419 - val_acc: 0.9781 - val_binary_crossentropy: 0.1748 - val_recall: 0.9553\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.03656\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0211 - acc: 0.9892 - binary_crossentropy: 0.0805 - recall: 0.9787 - val_loss: 0.0569 - val_acc: 0.9707 - val_binary_crossentropy: 0.2279 - val_recall: 0.9274\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.03656\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0195 - acc: 0.9901 - binary_crossentropy: 0.0742 - recall: 0.9793 - val_loss: 0.0375 - val_acc: 0.9804 - val_binary_crossentropy: 0.1631 - val_recall: 0.9621\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.03656\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0178 - acc: 0.9909 - binary_crossentropy: 0.0672 - recall: 0.9810 - val_loss: 0.0369 - val_acc: 0.9807 - val_binary_crossentropy: 0.1630 - val_recall: 0.9638\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.03656\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0172 - acc: 0.9912 - binary_crossentropy: 0.0644 - recall: 0.9816 - val_loss: 0.0367 - val_acc: 0.9808 - val_binary_crossentropy: 0.1615 - val_recall: 0.9630\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.03656\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0168 - acc: 0.9914 - binary_crossentropy: 0.0631 - recall: 0.9821 - val_loss: 0.0365 - val_acc: 0.9809 - val_binary_crossentropy: 0.1617 - val_recall: 0.9634\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.03656 to 0.03647, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0165 - acc: 0.9916 - binary_crossentropy: 0.0617 - recall: 0.9823 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1625 - val_recall: 0.9631\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.03647 to 0.03644, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - 28s 148ms/step - loss: 0.0164 - acc: 0.9918 - binary_crossentropy: 0.0606 - recall: 0.9823 - val_loss: 0.0363 - val_acc: 0.9810 - val_binary_crossentropy: 0.1637 - val_recall: 0.9639\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.03644 to 0.03633, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - 28s 148ms/step - loss: 0.0159 - acc: 0.9919 - binary_crossentropy: 0.0601 - recall: 0.9830 - val_loss: 0.0364 - val_acc: 0.9810 - val_binary_crossentropy: 0.1646 - val_recall: 0.9632\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.03633\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0158 - acc: 0.9920 - binary_crossentropy: 0.0597 - recall: 0.9830 - val_loss: 0.0364 - val_acc: 0.9810 - val_binary_crossentropy: 0.1657 - val_recall: 0.9631\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.03633\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0157 - acc: 0.9921 - binary_crossentropy: 0.0588 - recall: 0.9830 - val_loss: 0.0364 - val_acc: 0.9810 - val_binary_crossentropy: 0.1668 - val_recall: 0.9632\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.03633\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0156 - acc: 0.9922 - binary_crossentropy: 0.0584 - recall: 0.9831 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1690 - val_recall: 0.9635\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.03633\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0152 - acc: 0.9923 - binary_crossentropy: 0.0578 - recall: 0.9836 - val_loss: 0.0363 - val_acc: 0.9810 - val_binary_crossentropy: 0.1693 - val_recall: 0.9635\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.03633 to 0.03630, saving model to 6_result/exp_fold2/model/best.h5\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0150 - acc: 0.9924 - binary_crossentropy: 0.0572 - recall: 0.9837 - val_loss: 0.0363 - val_acc: 0.9810 - val_binary_crossentropy: 0.1708 - val_recall: 0.9642\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.03630\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - 28s 148ms/step - loss: 0.0151 - acc: 0.9924 - binary_crossentropy: 0.0572 - recall: 0.9836 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1710 - val_recall: 0.9639\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.03630\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0154 - acc: 0.9924 - binary_crossentropy: 0.0559 - recall: 0.9834 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1708 - val_recall: 0.9636\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.03630\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0150 - acc: 0.9924 - binary_crossentropy: 0.0565 - recall: 0.9837 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1713 - val_recall: 0.9640\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.03630\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0150 - acc: 0.9924 - binary_crossentropy: 0.0567 - recall: 0.9838 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1711 - val_recall: 0.9637\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.03630\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0149 - acc: 0.9925 - binary_crossentropy: 0.0563 - recall: 0.9838 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1713 - val_recall: 0.9639\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.03630\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0149 - acc: 0.9925 - binary_crossentropy: 0.0567 - recall: 0.9838 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1715 - val_recall: 0.9639\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.03630\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0150 - acc: 0.9925 - binary_crossentropy: 0.0564 - recall: 0.9837 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1714 - val_recall: 0.9638\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.03630\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0150 - acc: 0.9925 - binary_crossentropy: 0.0562 - recall: 0.9837 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1714 - val_recall: 0.9640\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.03630\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0149 - acc: 0.9925 - binary_crossentropy: 0.0559 - recall: 0.9837 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1715 - val_recall: 0.9639\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.03630\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - 28s 148ms/step - loss: 0.0149 - acc: 0.9925 - binary_crossentropy: 0.0565 - recall: 0.9838 - val_loss: 0.0364 - val_acc: 0.9810 - val_binary_crossentropy: 0.1716 - val_recall: 0.9639\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.03630\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - 28s 148ms/step - loss: 0.0148 - acc: 0.9925 - binary_crossentropy: 0.0566 - recall: 0.9840 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1715 - val_recall: 0.9639\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.03630\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0149 - acc: 0.9925 - binary_crossentropy: 0.0559 - recall: 0.9838 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1713 - val_recall: 0.9638\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.03630\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - 28s 148ms/step - loss: 0.0151 - acc: 0.9925 - binary_crossentropy: 0.0560 - recall: 0.9836 - val_loss: 0.0364 - val_acc: 0.9810 - val_binary_crossentropy: 0.1715 - val_recall: 0.9639\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.03630\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - 28s 148ms/step - loss: 0.0149 - acc: 0.9925 - binary_crossentropy: 0.0562 - recall: 0.9838 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1717 - val_recall: 0.9640\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.03630\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0147 - acc: 0.9925 - binary_crossentropy: 0.0565 - recall: 0.9841 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1716 - val_recall: 0.9639\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.03630\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - 28s 148ms/step - loss: 0.0148 - acc: 0.9925 - binary_crossentropy: 0.0563 - recall: 0.9839 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1715 - val_recall: 0.9639\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.03630\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0153 - acc: 0.9924 - binary_crossentropy: 0.0546 - recall: 0.9835 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1715 - val_recall: 0.9639\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.03630\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0148 - acc: 0.9925 - binary_crossentropy: 0.0566 - recall: 0.9840 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1714 - val_recall: 0.9638\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.03630\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0150 - acc: 0.9925 - binary_crossentropy: 0.0561 - recall: 0.9837 - val_loss: 0.0364 - val_acc: 0.9809 - val_binary_crossentropy: 0.1714 - val_recall: 0.9638\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.03630\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "Epoch 00068: early stopping\n",
      "save model\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (940, 512, 512, 3) \n",
      "masks : (940, 512, 512)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "==============================\n",
      "------------------------------\n",
      "load unet model\n",
      "------------------------------\n",
      "------------------------------\n",
      "start training\n",
      "------------------------------\n",
      "Epoch 1/100\n",
      "188/188 [==============================] - 31s 156ms/step - loss: 0.2931 - acc: 0.8564 - binary_crossentropy: 0.4517 - recall: 0.9123 - val_loss: 0.5217 - val_acc: 0.4578 - val_binary_crossentropy: 1.7727 - val_recall: 0.9999\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52175, saving model to 6_result/exp_fold3/model/best.h5\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.1805 - acc: 0.9372 - binary_crossentropy: 0.2507 - recall: 0.9404 - val_loss: 0.4018 - val_acc: 0.6869 - val_binary_crossentropy: 1.4230 - val_recall: 0.9678\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.52175 to 0.40181, saving model to 6_result/exp_fold3/model/best.h5\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.1332 - acc: 0.9592 - binary_crossentropy: 0.1755 - recall: 0.9519 - val_loss: 0.1612 - val_acc: 0.9407 - val_binary_crossentropy: 0.2376 - val_recall: 0.9300\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.40181 to 0.16124, saving model to 6_result/exp_fold3/model/best.h5\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.1052 - acc: 0.9678 - binary_crossentropy: 0.1426 - recall: 0.9600 - val_loss: 0.1125 - val_acc: 0.9622 - val_binary_crossentropy: 0.1589 - val_recall: 0.9484\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.16124 to 0.11248, saving model to 6_result/exp_fold3/model/best.h5\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0854 - acc: 0.9737 - binary_crossentropy: 0.1187 - recall: 0.9635 - val_loss: 0.0914 - val_acc: 0.9692 - val_binary_crossentropy: 0.1443 - val_recall: 0.9664\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.11248 to 0.09138, saving model to 6_result/exp_fold3/model/best.h5\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0730 - acc: 0.9763 - binary_crossentropy: 0.1070 - recall: 0.9650 - val_loss: 0.1251 - val_acc: 0.9496 - val_binary_crossentropy: 0.1937 - val_recall: 0.8704\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09138\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0693 - acc: 0.9751 - binary_crossentropy: 0.1131 - recall: 0.9628 - val_loss: 0.0850 - val_acc: 0.9661 - val_binary_crossentropy: 0.1602 - val_recall: 0.9556\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.09138 to 0.08502, saving model to 6_result/exp_fold3/model/best.h5\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0601 - acc: 0.9780 - binary_crossentropy: 0.1016 - recall: 0.9660 - val_loss: 0.1244 - val_acc: 0.9386 - val_binary_crossentropy: 0.2874 - val_recall: 0.9601\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08502\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 29s 152ms/step - loss: 0.0530 - acc: 0.9801 - binary_crossentropy: 0.0941 - recall: 0.9678 - val_loss: 0.0945 - val_acc: 0.9544 - val_binary_crossentropy: 0.2443 - val_recall: 0.9604\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08502\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0466 - acc: 0.9819 - binary_crossentropy: 0.0860 - recall: 0.9707 - val_loss: 0.0744 - val_acc: 0.9673 - val_binary_crossentropy: 0.1510 - val_recall: 0.9380\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.08502 to 0.07436, saving model to 6_result/exp_fold3/model/best.h5\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0439 - acc: 0.9822 - binary_crossentropy: 0.0853 - recall: 0.9710 - val_loss: 0.0619 - val_acc: 0.9723 - val_binary_crossentropy: 0.1488 - val_recall: 0.9653\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.07436 to 0.06185, saving model to 6_result/exp_fold3/model/best.h5\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0414 - acc: 0.9827 - binary_crossentropy: 0.0868 - recall: 0.9712 - val_loss: 0.0711 - val_acc: 0.9672 - val_binary_crossentropy: 0.1574 - val_recall: 0.9350\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.06185\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0364 - acc: 0.9847 - binary_crossentropy: 0.0774 - recall: 0.9729 - val_loss: 0.0479 - val_acc: 0.9786 - val_binary_crossentropy: 0.1105 - val_recall: 0.9546\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.06185 to 0.04789, saving model to 6_result/exp_fold3/model/best.h5\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0340 - acc: 0.9853 - binary_crossentropy: 0.0734 - recall: 0.9748 - val_loss: 0.0463 - val_acc: 0.9789 - val_binary_crossentropy: 0.1142 - val_recall: 0.9610\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.04789 to 0.04632, saving model to 6_result/exp_fold3/model/best.h5\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0312 - acc: 0.9864 - binary_crossentropy: 0.0696 - recall: 0.9763 - val_loss: 0.0503 - val_acc: 0.9765 - val_binary_crossentropy: 0.1265 - val_recall: 0.9499\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.04632\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0304 - acc: 0.9865 - binary_crossentropy: 0.0707 - recall: 0.9761 - val_loss: 0.0871 - val_acc: 0.9536 - val_binary_crossentropy: 0.3193 - val_recall: 0.9721\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.04632\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0312 - acc: 0.9858 - binary_crossentropy: 0.0761 - recall: 0.9739 - val_loss: 0.0496 - val_acc: 0.9758 - val_binary_crossentropy: 0.1513 - val_recall: 0.9624\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.04632\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0297 - acc: 0.9862 - binary_crossentropy: 0.0733 - recall: 0.9743 - val_loss: 0.0573 - val_acc: 0.9722 - val_binary_crossentropy: 0.1516 - val_recall: 0.9297\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.04632\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0306 - acc: 0.9855 - binary_crossentropy: 0.0785 - recall: 0.9738 - val_loss: 0.1077 - val_acc: 0.9393 - val_binary_crossentropy: 0.3768 - val_recall: 0.9700\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.04632\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 29s 153ms/step - loss: 0.0267 - acc: 0.9874 - binary_crossentropy: 0.0718 - recall: 0.9772 - val_loss: 0.0408 - val_acc: 0.9802 - val_binary_crossentropy: 0.1214 - val_recall: 0.9640\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.04632 to 0.04076, saving model to 6_result/exp_fold3/model/best.h5\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0250 - acc: 0.9884 - binary_crossentropy: 0.0653 - recall: 0.9777 - val_loss: 0.0399 - val_acc: 0.9806 - val_binary_crossentropy: 0.1189 - val_recall: 0.9629\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.04076 to 0.03993, saving model to 6_result/exp_fold3/model/best.h5\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0242 - acc: 0.9887 - binary_crossentropy: 0.0629 - recall: 0.9794 - val_loss: 0.0398 - val_acc: 0.9806 - val_binary_crossentropy: 0.1207 - val_recall: 0.9645\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.03993 to 0.03981, saving model to 6_result/exp_fold3/model/best.h5\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0238 - acc: 0.9889 - binary_crossentropy: 0.0617 - recall: 0.9787 - val_loss: 0.0398 - val_acc: 0.9806 - val_binary_crossentropy: 0.1201 - val_recall: 0.9628\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.03981\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0234 - acc: 0.9892 - binary_crossentropy: 0.0606 - recall: 0.9791 - val_loss: 0.0398 - val_acc: 0.9806 - val_binary_crossentropy: 0.1206 - val_recall: 0.9623\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.03981\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0229 - acc: 0.9894 - binary_crossentropy: 0.0588 - recall: 0.9795 - val_loss: 0.0399 - val_acc: 0.9806 - val_binary_crossentropy: 0.1219 - val_recall: 0.9628\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.03981\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0225 - acc: 0.9895 - binary_crossentropy: 0.0598 - recall: 0.9815 - val_loss: 0.0400 - val_acc: 0.9805 - val_binary_crossentropy: 0.1228 - val_recall: 0.9626\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.03981\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0223 - acc: 0.9897 - binary_crossentropy: 0.0568 - recall: 0.9797 - val_loss: 0.0397 - val_acc: 0.9806 - val_binary_crossentropy: 0.1232 - val_recall: 0.9628\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.03981 to 0.03973, saving model to 6_result/exp_fold3/model/best.h5\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0219 - acc: 0.9899 - binary_crossentropy: 0.0551 - recall: 0.9802 - val_loss: 0.0396 - val_acc: 0.9806 - val_binary_crossentropy: 0.1233 - val_recall: 0.9627\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.03973 to 0.03965, saving model to 6_result/exp_fold3/model/best.h5\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0218 - acc: 0.9899 - binary_crossentropy: 0.0552 - recall: 0.9803 - val_loss: 0.0396 - val_acc: 0.9806 - val_binary_crossentropy: 0.1238 - val_recall: 0.9630\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.03965\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0217 - acc: 0.9899 - binary_crossentropy: 0.0550 - recall: 0.9803 - val_loss: 0.0397 - val_acc: 0.9806 - val_binary_crossentropy: 0.1238 - val_recall: 0.9628\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.03965\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0218 - acc: 0.9899 - binary_crossentropy: 0.0546 - recall: 0.9801 - val_loss: 0.0397 - val_acc: 0.9806 - val_binary_crossentropy: 0.1241 - val_recall: 0.9629\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.03965\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0216 - acc: 0.9900 - binary_crossentropy: 0.0556 - recall: 0.9805 - val_loss: 0.0397 - val_acc: 0.9806 - val_binary_crossentropy: 0.1242 - val_recall: 0.9627\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.03965\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0216 - acc: 0.9900 - binary_crossentropy: 0.0542 - recall: 0.9805 - val_loss: 0.0397 - val_acc: 0.9806 - val_binary_crossentropy: 0.1243 - val_recall: 0.9625\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.03965\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0215 - acc: 0.9900 - binary_crossentropy: 0.0538 - recall: 0.9803 - val_loss: 0.0397 - val_acc: 0.9805 - val_binary_crossentropy: 0.1245 - val_recall: 0.9626\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.03965\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0215 - acc: 0.9900 - binary_crossentropy: 0.0541 - recall: 0.9804 - val_loss: 0.0397 - val_acc: 0.9805 - val_binary_crossentropy: 0.1246 - val_recall: 0.9627\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.03965\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0213 - acc: 0.9901 - binary_crossentropy: 0.0539 - recall: 0.9807 - val_loss: 0.0397 - val_acc: 0.9805 - val_binary_crossentropy: 0.1247 - val_recall: 0.9628\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.03965\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0215 - acc: 0.9900 - binary_crossentropy: 0.0540 - recall: 0.9804 - val_loss: 0.0397 - val_acc: 0.9805 - val_binary_crossentropy: 0.1247 - val_recall: 0.9628\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.03965\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0215 - acc: 0.9900 - binary_crossentropy: 0.0541 - recall: 0.9806 - val_loss: 0.0397 - val_acc: 0.9806 - val_binary_crossentropy: 0.1246 - val_recall: 0.9627\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.03965\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0216 - acc: 0.9901 - binary_crossentropy: 0.0538 - recall: 0.9803 - val_loss: 0.0397 - val_acc: 0.9805 - val_binary_crossentropy: 0.1248 - val_recall: 0.9629\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.03965\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - 29s 152ms/step - loss: 0.0217 - acc: 0.9901 - binary_crossentropy: 0.0537 - recall: 0.9804 - val_loss: 0.0397 - val_acc: 0.9805 - val_binary_crossentropy: 0.1249 - val_recall: 0.9630\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.03965\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - 29s 152ms/step - loss: 0.0214 - acc: 0.9901 - binary_crossentropy: 0.0539 - recall: 0.9806 - val_loss: 0.0397 - val_acc: 0.9805 - val_binary_crossentropy: 0.1248 - val_recall: 0.9629\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.03965\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0218 - acc: 0.9900 - binary_crossentropy: 0.0543 - recall: 0.9802 - val_loss: 0.0397 - val_acc: 0.9805 - val_binary_crossentropy: 0.1248 - val_recall: 0.9629\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.03965\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0214 - acc: 0.9901 - binary_crossentropy: 0.0542 - recall: 0.9807 - val_loss: 0.0397 - val_acc: 0.9805 - val_binary_crossentropy: 0.1249 - val_recall: 0.9630\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.03965\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - 28s 152ms/step - loss: 0.0213 - acc: 0.9901 - binary_crossentropy: 0.0543 - recall: 0.9807 - val_loss: 0.0397 - val_acc: 0.9805 - val_binary_crossentropy: 0.1248 - val_recall: 0.9628\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.03965\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0215 - acc: 0.9901 - binary_crossentropy: 0.0538 - recall: 0.9804 - val_loss: 0.0397 - val_acc: 0.9805 - val_binary_crossentropy: 0.1248 - val_recall: 0.9629\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.03965\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0219 - acc: 0.9900 - binary_crossentropy: 0.0542 - recall: 0.9801 - val_loss: 0.0397 - val_acc: 0.9805 - val_binary_crossentropy: 0.1249 - val_recall: 0.9630\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.03965\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0215 - acc: 0.9901 - binary_crossentropy: 0.0538 - recall: 0.9805 - val_loss: 0.0397 - val_acc: 0.9805 - val_binary_crossentropy: 0.1249 - val_recall: 0.9630\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.03965\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0214 - acc: 0.9900 - binary_crossentropy: 0.0538 - recall: 0.9806 - val_loss: 0.0397 - val_acc: 0.9805 - val_binary_crossentropy: 0.1247 - val_recall: 0.9629\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.03965\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "Epoch 00048: early stopping\n",
      "save model\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (940, 512, 512, 3) \n",
      "masks : (940, 512, 512)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "==============================\n",
      "------------------------------\n",
      "load unet model\n",
      "------------------------------\n",
      "------------------------------\n",
      "start training\n",
      "------------------------------\n",
      "Epoch 1/100\n",
      "188/188 [==============================] - 32s 160ms/step - loss: 0.2871 - acc: 0.8705 - binary_crossentropy: 0.3283 - recall: 0.9062 - val_loss: 0.5507 - val_acc: 0.3634 - val_binary_crossentropy: 1.6417 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.55072, saving model to 6_result/exp_fold4/model/best.h5\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.1605 - acc: 0.9510 - binary_crossentropy: 0.1686 - recall: 0.9470 - val_loss: 0.3243 - val_acc: 0.8167 - val_binary_crossentropy: 0.5547 - val_recall: 0.9082\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.55072 to 0.32431, saving model to 6_result/exp_fold4/model/best.h5\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.1179 - acc: 0.9664 - binary_crossentropy: 0.1246 - recall: 0.9567 - val_loss: 0.1455 - val_acc: 0.9502 - val_binary_crossentropy: 0.1726 - val_recall: 0.9325\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32431 to 0.14549, saving model to 6_result/exp_fold4/model/best.h5\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 29s 152ms/step - loss: 0.0924 - acc: 0.9732 - binary_crossentropy: 0.1020 - recall: 0.9620 - val_loss: 0.1142 - val_acc: 0.9578 - val_binary_crossentropy: 0.1577 - val_recall: 0.9737\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.14549 to 0.11423, saving model to 6_result/exp_fold4/model/best.h5\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 29s 152ms/step - loss: 0.0769 - acc: 0.9762 - binary_crossentropy: 0.0923 - recall: 0.9641 - val_loss: 0.1048 - val_acc: 0.9597 - val_binary_crossentropy: 0.1474 - val_recall: 0.9404\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.11423 to 0.10481, saving model to 6_result/exp_fold4/model/best.h5\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0666 - acc: 0.9779 - binary_crossentropy: 0.0876 - recall: 0.9647 - val_loss: 0.1183 - val_acc: 0.9435 - val_binary_crossentropy: 0.2326 - val_recall: 0.9785\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10481\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 29s 152ms/step - loss: 0.0574 - acc: 0.9801 - binary_crossentropy: 0.0803 - recall: 0.9671 - val_loss: 0.0654 - val_acc: 0.9746 - val_binary_crossentropy: 0.1042 - val_recall: 0.9648\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.10481 to 0.06543, saving model to 6_result/exp_fold4/model/best.h5\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0489 - acc: 0.9826 - binary_crossentropy: 0.0718 - recall: 0.9705 - val_loss: 0.0583 - val_acc: 0.9773 - val_binary_crossentropy: 0.0938 - val_recall: 0.9523\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.06543 to 0.05825, saving model to 6_result/exp_fold4/model/best.h5\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0433 - acc: 0.9841 - binary_crossentropy: 0.0669 - recall: 0.9724 - val_loss: 0.0538 - val_acc: 0.9778 - val_binary_crossentropy: 0.0923 - val_recall: 0.9588\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.05825 to 0.05382, saving model to 6_result/exp_fold4/model/best.h5\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 29s 152ms/step - loss: 0.0433 - acc: 0.9828 - binary_crossentropy: 0.0724 - recall: 0.9696 - val_loss: 0.0574 - val_acc: 0.9751 - val_binary_crossentropy: 0.1080 - val_recall: 0.9462\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05382\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0378 - acc: 0.9846 - binary_crossentropy: 0.0674 - recall: 0.9741 - val_loss: 0.0567 - val_acc: 0.9746 - val_binary_crossentropy: 0.1124 - val_recall: 0.9440\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.05382\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0331 - acc: 0.9865 - binary_crossentropy: 0.0601 - recall: 0.9755 - val_loss: 0.0492 - val_acc: 0.9779 - val_binary_crossentropy: 0.1005 - val_recall: 0.9491\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.05382 to 0.04924, saving model to 6_result/exp_fold4/model/best.h5\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0303 - acc: 0.9874 - binary_crossentropy: 0.0563 - recall: 0.9769 - val_loss: 0.0446 - val_acc: 0.9793 - val_binary_crossentropy: 0.0998 - val_recall: 0.9733\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.04924 to 0.04461, saving model to 6_result/exp_fold4/model/best.h5\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0315 - acc: 0.9863 - binary_crossentropy: 0.0628 - recall: 0.9749 - val_loss: 0.0495 - val_acc: 0.9768 - val_binary_crossentropy: 0.1106 - val_recall: 0.9470\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.04461\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0298 - acc: 0.9867 - binary_crossentropy: 0.0616 - recall: 0.9764 - val_loss: 0.0520 - val_acc: 0.9752 - val_binary_crossentropy: 0.1209 - val_recall: 0.9373\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.04461\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0265 - acc: 0.9882 - binary_crossentropy: 0.0553 - recall: 0.9778 - val_loss: 0.1386 - val_acc: 0.9175 - val_binary_crossentropy: 0.5030 - val_recall: 0.9904\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.04461\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0265 - acc: 0.9878 - binary_crossentropy: 0.0587 - recall: 0.9769 - val_loss: 0.0407 - val_acc: 0.9803 - val_binary_crossentropy: 0.1014 - val_recall: 0.9619\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.04461 to 0.04074, saving model to 6_result/exp_fold4/model/best.h5\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 28s 152ms/step - loss: 0.0236 - acc: 0.9892 - binary_crossentropy: 0.0524 - recall: 0.9792 - val_loss: 0.0554 - val_acc: 0.9718 - val_binary_crossentropy: 0.1508 - val_recall: 0.9585\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.04074\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0275 - acc: 0.9869 - binary_crossentropy: 0.0651 - recall: 0.9759 - val_loss: 0.0522 - val_acc: 0.9742 - val_binary_crossentropy: 0.1393 - val_recall: 0.9377\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.04074\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0259 - acc: 0.9875 - binary_crossentropy: 0.0638 - recall: 0.9772 - val_loss: 0.0510 - val_acc: 0.9747 - val_binary_crossentropy: 0.1380 - val_recall: 0.9348\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.04074\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0215 - acc: 0.9898 - binary_crossentropy: 0.0528 - recall: 0.9800 - val_loss: 0.0391 - val_acc: 0.9804 - val_binary_crossentropy: 0.1118 - val_recall: 0.9630\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.04074 to 0.03909, saving model to 6_result/exp_fold4/model/best.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0198 - acc: 0.9905 - binary_crossentropy: 0.0496 - recall: 0.9813 - val_loss: 0.0383 - val_acc: 0.9806 - val_binary_crossentropy: 0.1145 - val_recall: 0.9629\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.03909 to 0.03834, saving model to 6_result/exp_fold4/model/best.h5\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0188 - acc: 0.9910 - binary_crossentropy: 0.0475 - recall: 0.9819 - val_loss: 0.0386 - val_acc: 0.9803 - val_binary_crossentropy: 0.1192 - val_recall: 0.9633\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.03834\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0180 - acc: 0.9913 - binary_crossentropy: 0.0456 - recall: 0.9824 - val_loss: 0.0385 - val_acc: 0.9803 - val_binary_crossentropy: 0.1229 - val_recall: 0.9643\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.03834\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0173 - acc: 0.9915 - binary_crossentropy: 0.0463 - recall: 0.9829 - val_loss: 0.0380 - val_acc: 0.9805 - val_binary_crossentropy: 0.1242 - val_recall: 0.9644\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.03834 to 0.03798, saving model to 6_result/exp_fold4/model/best.h5\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0189 - acc: 0.9908 - binary_crossentropy: 0.0491 - recall: 0.9812 - val_loss: 0.0412 - val_acc: 0.9788 - val_binary_crossentropy: 0.1342 - val_recall: 0.9579\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.03798\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0184 - acc: 0.9909 - binary_crossentropy: 0.0524 - recall: 0.9814 - val_loss: 0.2039 - val_acc: 0.9110 - val_binary_crossentropy: 0.6104 - val_recall: 0.6794\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.03798\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0187 - acc: 0.9906 - binary_crossentropy: 0.0549 - recall: 0.9811 - val_loss: 0.0420 - val_acc: 0.9781 - val_binary_crossentropy: 0.1449 - val_recall: 0.9633\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.03798\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0173 - acc: 0.9913 - binary_crossentropy: 0.0520 - recall: 0.9824 - val_loss: 0.0474 - val_acc: 0.9752 - val_binary_crossentropy: 0.1652 - val_recall: 0.9550\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.03798\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0165 - acc: 0.9918 - binary_crossentropy: 0.0494 - recall: 0.9828 - val_loss: 0.0380 - val_acc: 0.9804 - val_binary_crossentropy: 0.1324 - val_recall: 0.9583\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.03798\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0149 - acc: 0.9926 - binary_crossentropy: 0.0444 - recall: 0.9845 - val_loss: 0.0358 - val_acc: 0.9814 - val_binary_crossentropy: 0.1296 - val_recall: 0.9682\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.03798 to 0.03580, saving model to 6_result/exp_fold4/model/best.h5\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0148 - acc: 0.9926 - binary_crossentropy: 0.0425 - recall: 0.9846 - val_loss: 0.0394 - val_acc: 0.9794 - val_binary_crossentropy: 0.1403 - val_recall: 0.9649\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.03580\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0144 - acc: 0.9928 - binary_crossentropy: 0.0435 - recall: 0.9850 - val_loss: 0.0360 - val_acc: 0.9813 - val_binary_crossentropy: 0.1312 - val_recall: 0.9665\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.03580\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0140 - acc: 0.9930 - binary_crossentropy: 0.0416 - recall: 0.9862 - val_loss: 0.0703 - val_acc: 0.9609 - val_binary_crossentropy: 0.2885 - val_recall: 0.9802\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.03580\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0141 - acc: 0.9929 - binary_crossentropy: 0.0424 - recall: 0.9853 - val_loss: 0.0364 - val_acc: 0.9810 - val_binary_crossentropy: 0.1339 - val_recall: 0.9658\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.03580\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0139 - acc: 0.9931 - binary_crossentropy: 0.0410 - recall: 0.9854 - val_loss: 0.0361 - val_acc: 0.9813 - val_binary_crossentropy: 0.1321 - val_recall: 0.9648\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.03580\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0136 - acc: 0.9933 - binary_crossentropy: 0.0401 - recall: 0.9858 - val_loss: 0.0360 - val_acc: 0.9813 - val_binary_crossentropy: 0.1330 - val_recall: 0.9660\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.03580\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0136 - acc: 0.9933 - binary_crossentropy: 0.0399 - recall: 0.9857 - val_loss: 0.0360 - val_acc: 0.9813 - val_binary_crossentropy: 0.1331 - val_recall: 0.9661\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.03580\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0137 - acc: 0.9933 - binary_crossentropy: 0.0399 - recall: 0.9856 - val_loss: 0.0360 - val_acc: 0.9813 - val_binary_crossentropy: 0.1332 - val_recall: 0.9664\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.03580\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0135 - acc: 0.9933 - binary_crossentropy: 0.0404 - recall: 0.9859 - val_loss: 0.0359 - val_acc: 0.9813 - val_binary_crossentropy: 0.1329 - val_recall: 0.9657\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.03580\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0135 - acc: 0.9933 - binary_crossentropy: 0.0399 - recall: 0.9858 - val_loss: 0.0359 - val_acc: 0.9813 - val_binary_crossentropy: 0.1330 - val_recall: 0.9658\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.03580\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0135 - acc: 0.9933 - binary_crossentropy: 0.0397 - recall: 0.9858 - val_loss: 0.0359 - val_acc: 0.9813 - val_binary_crossentropy: 0.1334 - val_recall: 0.9663\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.03580\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - 28s 151ms/step - loss: 0.0135 - acc: 0.9934 - binary_crossentropy: 0.0396 - recall: 0.9858 - val_loss: 0.0360 - val_acc: 0.9813 - val_binary_crossentropy: 0.1331 - val_recall: 0.9660\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.03580\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0133 - acc: 0.9933 - binary_crossentropy: 0.0401 - recall: 0.9860 - val_loss: 0.0360 - val_acc: 0.9813 - val_binary_crossentropy: 0.1334 - val_recall: 0.9662\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.03580\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0134 - acc: 0.9934 - binary_crossentropy: 0.0399 - recall: 0.9860 - val_loss: 0.0359 - val_acc: 0.9813 - val_binary_crossentropy: 0.1334 - val_recall: 0.9661\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.03580\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0135 - acc: 0.9933 - binary_crossentropy: 0.0397 - recall: 0.9857 - val_loss: 0.0360 - val_acc: 0.9813 - val_binary_crossentropy: 0.1332 - val_recall: 0.9659\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.03580\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0134 - acc: 0.9933 - binary_crossentropy: 0.0399 - recall: 0.9860 - val_loss: 0.0360 - val_acc: 0.9813 - val_binary_crossentropy: 0.1334 - val_recall: 0.9661\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.03580\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0135 - acc: 0.9934 - binary_crossentropy: 0.0395 - recall: 0.9858 - val_loss: 0.0360 - val_acc: 0.9813 - val_binary_crossentropy: 0.1335 - val_recall: 0.9662\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.03580\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 0.0133 - acc: 0.9933 - binary_crossentropy: 0.0401 - recall: 0.9861 - val_loss: 0.0360 - val_acc: 0.9813 - val_binary_crossentropy: 0.1332 - val_recall: 0.9659\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.03580\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0134 - acc: 0.9934 - binary_crossentropy: 0.0395 - recall: 0.9858 - val_loss: 0.0360 - val_acc: 0.9813 - val_binary_crossentropy: 0.1333 - val_recall: 0.9660\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.03580\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - 28s 149ms/step - loss: 0.0132 - acc: 0.9934 - binary_crossentropy: 0.0399 - recall: 0.9862 - val_loss: 0.0360 - val_acc: 0.9813 - val_binary_crossentropy: 0.1335 - val_recall: 0.9662\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.03580\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 00051: early stopping\n",
      "save model\n"
     ]
    }
   ],
   "source": [
    "for foldnum in range(0,5):\n",
    "    trainset = fold[foldnum][0]\n",
    "    testset = fold[foldnum][1]\n",
    "    \n",
    "    sv_model_folder ='6_result/exp_fold{}/model/'.format(foldnum)\n",
    "    mkfolder(sv_model_folder)\n",
    "\n",
    "    sv_pred_folder = '6_result/exp_fold{}/pred/'.format(foldnum)\n",
    "    mkfolder(sv_pred_folder)\n",
    "\n",
    "    imgs_train, imgs_mask_train = load_data(trainset)\n",
    "    print('='*30)\n",
    "    # imgs_test, imgs_mask_test = load_data(testset[:4])\n",
    "    # imgs_add, imgs_mask_add = load_data(testset[4:])\n",
    "    print('-'*30)\n",
    "    print(\"load unet model\")\n",
    "    print('-'*30)\n",
    "\n",
    "    imgs_mask_train = np.expand_dims(imgs_mask_train,axis=-1)\n",
    "    imgs_mask_train.shape\n",
    "\n",
    "    imgs_train,imgs_val,imgs_mask_train,imgs_mask_val = train_test_split(imgs_train,imgs_mask_train,test_size=0.2,random_state=7)\n",
    "\n",
    "#     image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "#     mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "#     val_image_datagen = ImageDataGenerator()\n",
    "#     val_mask_datagen = ImageDataGenerator()\n",
    "\n",
    "#     image_generator = image_datagen.flow(imgs_train,batch_size=1,seed=1)\n",
    "#     mask_generator = mask_datagen.flow(imgs_mask_train,batch_size=1,seed=1)\n",
    "\n",
    "#     valt_generator = val_image_datagen.flow(imgs_val,batch_size=1,seed=1)\n",
    "#     valm_generator = val_mask_datagen.flow(imgs_mask_val,batch_size=1,seed=1)\n",
    "\n",
    "#     train_generator = zip(image_generator, mask_generator)\n",
    "#     validation_generator = zip(valt_generator,valm_generator)\n",
    "    \n",
    "    \n",
    "    img_rows, img_cols=512,512\n",
    "\n",
    "    model = get_att_unet(img_rows, img_cols)\n",
    "#     model = models.swin_unet_2d((512, 512, 3), filter_num_begin=64, n_labels=1, depth=4, stack_num_down=2, stack_num_up=2, \n",
    "#                             patch_size=(2, 2), num_heads=[4, 8, 8, 8], window_size=[4, 2, 2, 2], num_mlp=512, \n",
    "#                             output_activation='Softmax', shift_window=True, name='swin_unet')\n",
    "\n",
    "#     model = models.att_unet_2d((img_rows, img_cols,3), filter_num=[64, 128, 256, 512], n_labels=1, \n",
    "#                                stack_num_down=2, stack_num_up=2, activation='ReLU', \n",
    "#                                atten_activation='ReLU', attention='add', output_activation='Sigmoid', \n",
    "#                                batch_norm=True, pool=False, unpool=False, \n",
    "#                                backbone='ResNet101V2', weights='imagenet', \n",
    "#                                freeze_backbone=True, freeze_batch_norm=True, \n",
    "#                                name='attunet')\n",
    "    #     model = multi_gpu_model(model,gpus=4)\n",
    "\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    # model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "    #               loss=[losses.dice,losses.dice,losses.dice,losses.dice,losses.dice,losses.dice],\n",
    "    #               loss_weights=[0.25,0.25,0.25,0.25,1,0],\n",
    "    #               metrics=['acc', 'binary_crossentropy', recall])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                  loss=[losses.dice],\n",
    "                  metrics=['acc', 'binary_crossentropy', recall])\n",
    "\n",
    "    # reference : https://stackoverflow.com/questions/43782409/how-to-use-modelcheckpoint-with-custom-metrics-in-keras\n",
    "    # print(model.metrics_names)\n",
    "\n",
    "    # sv_model_folder ='../4_result/exp3_RGBE/model/fold{}/'.format(num)\n",
    "    # mkfolder(sv_model_folder)\n",
    "\n",
    "    # sv_pred_folder = '../4_result/exp3_HE/pred/fold{}/'.format(num)\n",
    "    # mkfolder(sv_pred_folder)\n",
    "\n",
    "    save_check_folder = sv_model_folder+'hdf5/'\n",
    "    mkfolder(save_check_folder)\n",
    "\n",
    "    def sch(epoch):\n",
    "        if epoch>30:\n",
    "            return 0.001\n",
    "        else:\n",
    "            return 0.01\n",
    "\n",
    "    epochs = 100\n",
    "    batch_size = 1\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(sv_model_folder+'best.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    sc = LearningRateScheduler(sch)\n",
    "    reduceLROnPlateau = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.1, verbose=1)\n",
    "    earlystopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "\n",
    "    print('-'*30)\n",
    "    print('start training')\n",
    "    print('-'*30)\n",
    "\n",
    "    # imgs_train = np.rollaxis(imgs_train, 3, 1)\n",
    "    # imgs_mask_train = np.rollaxis(imgs_mask_train, 3, 1)\n",
    "    # imgs_validation = np.rollaxis(imgs_validation, 3, 1)\n",
    "    # imgs_mask_validation = np.rollaxis(imgs_mask_validation, 3, 1)\n",
    "\n",
    "#     model.fit([imgs_train,imgs_mask_train], steps_per_epoch=752,epochs=epochs, verbose=1, validation_data=[imgs_val,imgs_mask_val],\n",
    "#               validation_steps = 188,shuffle=True, callbacks=[model_checkpoint,reduceLROnPlateau,earlystopping])\n",
    "    \n",
    "    model.fit(imgs_train, imgs_mask_train, batch_size=4, epochs=epochs, verbose=1, shuffle=True,\n",
    "              validation_data=(imgs_val,imgs_mask_val), callbacks=[model_checkpoint,reduceLROnPlateau,earlystopping])\n",
    "\n",
    "\n",
    "    print('save model')\n",
    "\n",
    "    model.save(sv_model_folder+'last.h5'.format(learning_rate, epochs))\n",
    "\n",
    "    # print('predict test data')\n",
    "    # imgs_mask_test = model.predict(imgs_test, batch_size=4, verbose=1)\n",
    "\n",
    "    # pred_file_name = sv_pred_folder +'exp1.npy'\n",
    "    # np.save(pred_file_name, imgs_mask_test)\n",
    "    # #     num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 512, 512, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T05:57:24.532325Z",
     "start_time": "2022-01-24T05:57:24.523232Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T12:09:07.868398Z",
     "start_time": "2022-01-13T08:34:08.339111Z"
    }
   },
   "outputs": [],
   "source": [
    "# num = 3\n",
    "# for dataset in fold[2:3]:\n",
    "#     trainset = dataset['trainset']\n",
    "#     valset = dataset['valset']\n",
    "#     testset = dataset['testset']\n",
    "# # load datasets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T01:45:17.268953Z",
     "start_time": "2022-01-24T01:42:57.977664Z"
    }
   },
   "outputs": [],
   "source": [
    "# imgs_test, imgs_mask_test = 0,0\n",
    "image_generator = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imgs_mask_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3098183/978293549.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimgs_mask_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_mask_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'imgs_mask_test' is not defined"
     ]
    }
   ],
   "source": [
    "imgs_mask_test = np.expand_dims(imgs_mask_test,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T01:45:17.294614Z",
     "start_time": "2022-01-24T01:45:17.291009Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import r2_score\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T00:15:45.948465Z",
     "start_time": "2022-01-25T00:02:25.016182Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (235, 512, 512, 3) \n",
      "masks : (235, 512, 512)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512, 512, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 512, 512, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 32) 9248        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512, 512, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 256, 256, 32) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 64) 18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 256, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256, 256, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 64) 36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256, 256, 64) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256, 256, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 128 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 128, 128 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 128 147584      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 128 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 128 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 256)  590080      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 512)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 512)  2359808     activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 512)  2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 512)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 64, 64, 512)  0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 128)  32896       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 128)  65664       up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64, 64, 128)  0           conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 1)    129         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 1)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 64, 64, 256)  0           activation_7[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 64, 64, 768)  0           up_sampling2d[0][0]              \n",
      "                                                                 multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 256)  1769728     lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 256)  1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  590080      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 256)  1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 256)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 256 0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 64) 8256        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 64) 16448       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 128, 64) 0           conv2d_15[0][0]                  \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 128, 128, 64) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 1)  65          activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 128, 128, 1)  0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 128, 128, 128 0           activation_5[0][0]               \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128, 128, 384 0           up_sampling2d_1[0][0]            \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 128 442496      lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 128, 128, 128 512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 128, 128, 128 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 128 147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 128 512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 128, 128, 128 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 128 0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 32) 2080        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 32) 4128        up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 256, 256, 32) 0           conv2d_20[0][0]                  \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 256, 256, 32) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 1)  33          activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 256, 256, 1)  0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 256, 256, 64) 0           activation_3[0][0]               \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 256, 256, 192 0           up_sampling2d_2[0][0]            \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 64) 110656      lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256, 256, 64) 256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 256, 256, 64) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 256, 256, 64) 36928       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256, 256, 64) 256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 256, 256, 64) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 512, 512, 64) 0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 512, 512, 16) 528         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 512, 512, 16) 1040        up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 512, 512, 16) 0           conv2d_25[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 512, 512, 16) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 512, 512, 1)  17          activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 512, 512, 1)  0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 512, 512, 32) 0           activation_1[0][0]               \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 512, 512, 96) 0           up_sampling2d_3[0][0]            \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 512, 512, 32) 27680       lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 512, 512, 32) 128         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 512, 512, 32) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 512, 512, 32) 9248        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 512, 512, 32) 128         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 512, 512, 32) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 512, 512, 1)  33          activation_25[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 7,989,717\n",
      "Trainable params: 7,983,829\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 2s 37ms/step\n",
      "ROI/New/1059_HE.png\n",
      "(235, 512, 512)\n",
      "(235, 512, 512, 1)\n",
      "complete\n",
      "acc avg : 0.9797\n",
      "sensitivity avg : 0.9574\n",
      "specificity avg : 0.9872\n",
      "dsc avg : 0.9646\n",
      "------------------------------\n",
      "sensitivity min: 0.0\n",
      "specificity min: 0.8520112894489267\n",
      "dsc min: 0.7732653937220476\n",
      "acc min: 0.7928733825683594\n",
      "------------------------------\n",
      "sensitivity max: 0.9918463621671204\n",
      "specificity max: 1.0\n",
      "dsc max: 0.9888226072439278\n",
      "acc max: 0.993743896484375\n",
      "0.09190463434716721\n",
      "0.014677443566516669\n",
      "0.024964006336898714\n",
      "0.021979072558522033\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (235, 512, 512, 3) \n",
      "masks : (235, 512, 512)\n",
      "------------------------------\n",
      "img :  253.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 512, 512, 32) 896         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 512, 512, 32) 128         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 512, 512, 32) 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 512, 512, 32) 9248        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 512, 512, 32) 128         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 512, 512, 32) 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 256, 256, 32) 0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 256, 256, 64) 18496       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 256, 256, 64) 256         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 256, 256, 64) 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 256, 256, 64) 36928       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 256, 256, 64) 256         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 256, 256, 64) 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 128, 128, 64) 0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 128, 128, 128 73856       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 128, 128, 128 512         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 128, 128, 128 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 128, 128, 128 147584      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 128, 128, 128 512         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 128, 128, 128 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 64, 64, 128)  0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 64, 64, 256)  295168      max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 64, 64, 256)  1024        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 64, 64, 256)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 64, 64, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 64, 64, 256)  1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 64, 64, 256)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 32, 32, 256)  0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 32, 32, 512)  1180160     max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 512)  2048        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 32, 32, 512)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 32, 32, 512)  2359808     activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 512)  2048        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 32, 32, 512)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 64, 64, 512)  0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 64, 64, 128)  32896       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 64, 64, 128)  65664       up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 64, 128)  0           conv2d_41[0][0]                  \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 64, 64, 128)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 64, 64, 1)    129         activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 64, 64, 1)    0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 64, 64, 256)  0           activation_33[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 64, 64, 768)  0           up_sampling2d_4[0][0]            \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 64, 64, 256)  1769728     lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 64, 64, 256)  1024        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 64, 64, 256)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 64, 64, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 64, 64, 256)  1024        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 64, 64, 256)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 256 0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 128, 128, 64) 8256        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 128, 128, 64) 16448       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 128, 128, 64) 0           conv2d_46[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 128, 128, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 128, 128, 1)  65          activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 128, 128, 1)  0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 128, 128, 128 0           activation_31[0][0]              \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 128, 128, 384 0           up_sampling2d_5[0][0]            \n",
      "                                                                 multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 128, 128, 128 442496      lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 128, 128, 128 512         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 128, 128, 128 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 128, 128, 128 147584      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 128, 128, 128 512         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 128, 128, 128 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 256, 256, 128 0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 256, 256, 32) 2080        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 256, 256, 32) 4128        up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 256, 32) 0           conv2d_51[0][0]                  \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 256, 256, 32) 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 256, 256, 1)  33          activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 256, 256, 1)  0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 256, 256, 64) 0           activation_29[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 256, 256, 192 0           up_sampling2d_6[0][0]            \n",
      "                                                                 multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 256, 256, 64) 110656      lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 256, 256, 64) 256         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 256, 256, 64) 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 256, 256, 64) 36928       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 256, 256, 64) 256         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 256, 256, 64) 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 512, 512, 64) 0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 512, 512, 16) 528         activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 512, 512, 16) 1040        up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 512, 512, 16) 0           conv2d_56[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 512, 512, 16) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 512, 512, 1)  17          activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 512, 512, 1)  0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 512, 512, 32) 0           activation_27[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 512, 512, 96) 0           up_sampling2d_7[0][0]            \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 512, 512, 32) 27680       lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 512, 512, 32) 128         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 512, 512, 32) 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 512, 512, 32) 9248        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 512, 512, 32) 128         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 512, 512, 32) 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 512, 512, 1)  33          activation_51[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 7,989,717\n",
      "Trainable params: 7,983,829\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 2s 37ms/step\n",
      "ROI/New/1013_HE.png\n",
      "(235, 512, 512)\n",
      "(235, 512, 512, 1)\n",
      "complete\n",
      "acc avg : 0.9799\n",
      "sensitivity avg : 0.9647\n",
      "specificity avg : 0.9856\n",
      "dsc avg : 0.9628\n",
      "------------------------------\n",
      "sensitivity min: 0.8125992985401241\n",
      "specificity min: 0.933319253623147\n",
      "dsc min: 0.8753487421704926\n",
      "acc min: 0.9330596923828125\n",
      "------------------------------\n",
      "sensitivity max: 0.9923507717524929\n",
      "specificity max: 0.998171311159625\n",
      "dsc max: 0.9872812483068755\n",
      "acc max: 0.9932670593261719\n",
      "0.025239487133078355\n",
      "0.012103142396694942\n",
      "0.021711678440218582\n",
      "0.012186228674320702\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (235, 512, 512, 3) \n",
      "masks : (235, 512, 512)\n",
      "------------------------------\n",
      "img :  253.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 512, 512, 32) 896         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 512, 512, 32) 128         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 512, 512, 32) 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 512, 512, 32) 9248        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 512, 512, 32) 128         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 512, 512, 32) 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 256, 256, 32) 0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 256, 256, 64) 18496       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 256, 256, 64) 256         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 256, 256, 64) 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 256, 256, 64) 36928       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 256, 256, 64) 256         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 256, 256, 64) 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 128, 128, 64) 0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 128, 128, 128 73856       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 128, 128, 128 512         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 128, 128, 128 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 128, 128, 128 147584      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 128, 128, 128 512         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 128, 128, 128 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 64, 64, 128)  0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 64, 64, 256)  295168      max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 64, 64, 256)  1024        conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 64, 64, 256)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 64, 64, 256)  590080      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 64, 64, 256)  1024        conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 64, 64, 256)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 32, 32, 256)  0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 32, 32, 512)  1180160     max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 32, 32, 512)  2048        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 32, 32, 512)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 32, 32, 512)  2359808     activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 32, 32, 512)  2048        conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 32, 32, 512)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 64, 64, 512)  0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 64, 64, 128)  32896       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 64, 64, 128)  65664       up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 64, 64, 128)  0           conv2d_72[0][0]                  \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 64, 64, 128)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 64, 64, 1)    129         activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 64, 64, 1)    0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 64, 64, 256)  0           activation_59[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 64, 64, 768)  0           up_sampling2d_8[0][0]            \n",
      "                                                                 multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 64, 64, 256)  1769728     lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 64, 64, 256)  1024        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 64, 64, 256)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 64, 64, 256)  590080      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 64, 64, 256)  1024        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 64, 64, 256)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2D)  (None, 128, 128, 256 0           activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 128, 128, 64) 8256        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 128, 128, 64) 16448       up_sampling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 128, 128, 64) 0           conv2d_77[0][0]                  \n",
      "                                                                 conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 128, 128, 64) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 128, 128, 1)  65          activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 128, 128, 1)  0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 128, 128, 128 0           activation_57[0][0]              \n",
      "                                                                 activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 128, 128, 384 0           up_sampling2d_9[0][0]            \n",
      "                                                                 multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 128, 128, 128 442496      lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 128, 128, 128 512         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 128, 128, 128 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 128, 128, 128 147584      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 128, 128, 128 512         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 128, 128, 128 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling2D) (None, 256, 256, 128 0           activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 256, 256, 32) 2080        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 256, 256, 32) 4128        up_sampling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 256, 256, 32) 0           conv2d_82[0][0]                  \n",
      "                                                                 conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 256, 256, 32) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 256, 256, 1)  33          activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 256, 256, 1)  0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 256, 256, 64) 0           activation_55[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 256, 256, 192 0           up_sampling2d_10[0][0]           \n",
      "                                                                 multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 256, 256, 64) 110656      lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 256, 256, 64) 256         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 256, 256, 64) 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 256, 256, 64) 36928       activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 256, 256, 64) 256         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 256, 256, 64) 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling2D) (None, 512, 512, 64) 0           activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 512, 512, 16) 528         activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 512, 512, 16) 1040        up_sampling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 512, 512, 16) 0           conv2d_87[0][0]                  \n",
      "                                                                 conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 512, 512, 16) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 512, 512, 1)  17          activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 512, 512, 1)  0           conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 512, 512, 32) 0           activation_53[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 512, 512, 96) 0           up_sampling2d_11[0][0]           \n",
      "                                                                 multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 512, 512, 32) 27680       lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 512, 512, 32) 128         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 512, 512, 32) 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 512, 512, 32) 9248        activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 512, 512, 32) 128         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 512, 512, 32) 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 512, 512, 1)  33          activation_77[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 7,989,717\n",
      "Trainable params: 7,983,829\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 3s 37ms/step\n",
      "ROI/New/620_HE.png\n",
      "(235, 512, 512)\n",
      "(235, 512, 512, 1)\n",
      "complete\n",
      "acc avg : 0.9801\n",
      "sensitivity avg : 0.9642\n",
      "specificity avg : 0.9858\n",
      "dsc avg : 0.9647\n",
      "------------------------------\n",
      "sensitivity min: 0.0\n",
      "specificity min: 0.9220816128654775\n",
      "dsc min: 0.8526224585474701\n",
      "acc min: 0.7767143249511719\n",
      "------------------------------\n",
      "sensitivity max: 0.993572708732464\n",
      "specificity max: 1.0\n",
      "dsc max: 0.98816167511545\n",
      "acc max: 0.9939956665039062\n",
      "0.06621864195032522\n",
      "0.011270912653949316\n",
      "0.018968425303324567\n",
      "0.017243892338747544\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (235, 512, 512, 3) \n",
      "masks : (235, 512, 512)\n",
      "------------------------------\n",
      "img :  252.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 512, 512, 32) 896         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 512, 512, 32) 128         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 512, 512, 32) 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 512, 512, 32) 9248        activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 512, 512, 32) 128         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 512, 512, 32) 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 256, 256, 32) 0           activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 256, 256, 64) 18496       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 256, 256, 64) 256         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 256, 256, 64) 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 256, 256, 64) 36928       activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 256, 256, 64) 256         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 256, 256, 64) 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 128, 128, 64) 0           activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 128, 128, 128 73856       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 128, 128, 128 512         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 128, 128, 128 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 128, 128, 128 147584      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 128, 128, 128 512         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 128, 128, 128 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 64, 64, 128)  0           activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 64, 64, 256)  295168      max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 64, 64, 256)  1024        conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 64, 64, 256)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 64, 64, 256)  590080      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 64, 64, 256)  1024        conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 64, 64, 256)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 32, 32, 256)  0           activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 32, 32, 512)  1180160     max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 32, 32, 512)  2048        conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 32, 32, 512)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 32, 32, 512)  2359808     activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 32, 32, 512)  2048        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 32, 32, 512)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling2D) (None, 64, 64, 512)  0           activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 64, 64, 128)  32896       activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 64, 64, 128)  65664       up_sampling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 64, 64, 128)  0           conv2d_103[0][0]                 \n",
      "                                                                 conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 64, 64, 128)  0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 64, 64, 1)    129         activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 64, 64, 1)    0           conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 64, 64, 256)  0           activation_85[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 64, 64, 768)  0           up_sampling2d_12[0][0]           \n",
      "                                                                 multiply_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 64, 64, 256)  1769728     lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 64, 64, 256)  1024        conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 64, 64, 256)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 64, 64, 256)  590080      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 64, 64, 256)  1024        conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 64, 64, 256)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_13 (UpSampling2D) (None, 128, 128, 256 0           activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 128, 128, 64) 8256        activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 128, 128, 64) 16448       up_sampling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 128, 128, 64) 0           conv2d_108[0][0]                 \n",
      "                                                                 conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 128, 128, 64) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 128, 128, 1)  65          activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 128, 128, 1)  0           conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 128, 128, 128 0           activation_83[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 128, 128, 384 0           up_sampling2d_13[0][0]           \n",
      "                                                                 multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 128, 128, 128 442496      lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 128, 128, 128 512         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 128, 128, 128 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 128, 128, 128 147584      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 128, 128, 128 512         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 128, 128, 128 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_14 (UpSampling2D) (None, 256, 256, 128 0           activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 256, 256, 32) 2080        activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 256, 256, 32) 4128        up_sampling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 256, 256, 32) 0           conv2d_113[0][0]                 \n",
      "                                                                 conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 256, 256, 32) 0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 256, 256, 1)  33          activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 256, 256, 1)  0           conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 256, 256, 64) 0           activation_81[0][0]              \n",
      "                                                                 activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 256, 256, 192 0           up_sampling2d_14[0][0]           \n",
      "                                                                 multiply_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 256, 256, 64) 110656      lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 256, 256, 64) 256         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 256, 256, 64) 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 256, 256, 64) 36928       activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 256, 256, 64) 256         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 256, 256, 64) 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_15 (UpSampling2D) (None, 512, 512, 64) 0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 512, 512, 16) 528         activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 512, 512, 16) 1040        up_sampling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 512, 512, 16) 0           conv2d_118[0][0]                 \n",
      "                                                                 conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 512, 512, 16) 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 512, 512, 1)  17          activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 512, 512, 1)  0           conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 512, 512, 32) 0           activation_79[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 512, 512, 96) 0           up_sampling2d_15[0][0]           \n",
      "                                                                 multiply_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 512, 512, 32) 27680       lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 512, 512, 32) 128         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 512, 512, 32) 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 512, 512, 32) 9248        activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 512, 512, 32) 128         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 512, 512, 32) 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 512, 512, 1)  33          activation_103[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 7,989,717\n",
      "Trainable params: 7,983,829\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 3s 38ms/step\n",
      "ROI/New/248_HE.png\n",
      "(235, 512, 512)\n",
      "(235, 512, 512, 1)\n",
      "complete\n",
      "acc avg : 0.9793\n",
      "sensitivity avg : 0.9582\n",
      "specificity avg : 0.9868\n",
      "dsc avg : 0.9630\n",
      "------------------------------\n",
      "sensitivity min: 0.0\n",
      "specificity min: 0.9281976265040383\n",
      "dsc min: 0.8808281099803776\n",
      "acc min: 0.7989082336425781\n",
      "------------------------------\n",
      "sensitivity max: 0.995096419690831\n",
      "specificity max: 1.0\n",
      "dsc max: 0.9877058425445522\n",
      "acc max: 0.9947013854980469\n",
      "0.06836925753970499\n",
      "0.011055987687031324\n",
      "0.02004752686339413\n",
      "0.016349057565449094\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (235, 512, 512, 3) \n",
      "masks : (235, 512, 512)\n",
      "------------------------------\n",
      "img :  252.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 512, 512, 32) 896         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 512, 512, 32) 128         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 512, 512, 32) 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 512, 512, 32) 9248        activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 512, 512, 32) 128         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 512, 512, 32) 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 256, 256, 32) 0           activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 256, 256, 64) 18496       max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 256, 256, 64) 256         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 256, 256, 64) 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 256, 256, 64) 36928       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 256, 256, 64) 256         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 256, 256, 64) 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 128, 128, 64) 0           activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 128, 128, 128 73856       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 128, 128, 128 512         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 128, 128, 128 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 128, 128, 128 147584      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 128, 128, 128 512         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 128, 128, 128 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 64, 64, 128)  0           activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 64, 64, 256)  295168      max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 64, 64, 256)  1024        conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 64, 64, 256)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 64, 64, 256)  590080      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 64, 64, 256)  1024        conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 64, 64, 256)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 32, 32, 256)  0           activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 32, 32, 512)  1180160     max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 32, 32, 512)  2048        conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 32, 32, 512)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 32, 32, 512)  2359808     activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 32, 32, 512)  2048        conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 32, 32, 512)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_16 (UpSampling2D) (None, 64, 64, 512)  0           activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 64, 64, 128)  32896       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 64, 64, 128)  65664       up_sampling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 64, 64, 128)  0           conv2d_134[0][0]                 \n",
      "                                                                 conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 64, 64, 128)  0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 64, 64, 1)    129         activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 64, 64, 1)    0           conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 64, 64, 256)  0           activation_111[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 64, 64, 768)  0           up_sampling2d_16[0][0]           \n",
      "                                                                 multiply_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 64, 64, 256)  1769728     lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 64, 64, 256)  1024        conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 64, 64, 256)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 64, 64, 256)  590080      activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 64, 64, 256)  1024        conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 64, 64, 256)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_17 (UpSampling2D) (None, 128, 128, 256 0           activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 128, 128, 64) 8256        activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 128, 128, 64) 16448       up_sampling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 128, 128, 64) 0           conv2d_139[0][0]                 \n",
      "                                                                 conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 128, 128, 64) 0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 128, 128, 1)  65          activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 128, 128, 1)  0           conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 128, 128, 128 0           activation_109[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 128, 128, 384 0           up_sampling2d_17[0][0]           \n",
      "                                                                 multiply_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 128, 128, 128 442496      lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 128, 128, 128 512         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 128, 128, 128 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 128, 128, 128 147584      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 128, 128, 128 512         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 128, 128, 128 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_18 (UpSampling2D) (None, 256, 256, 128 0           activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 256, 256, 32) 2080        activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 256, 256, 32) 4128        up_sampling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 256, 256, 32) 0           conv2d_144[0][0]                 \n",
      "                                                                 conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 256, 256, 32) 0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 256, 256, 1)  33          activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 256, 256, 1)  0           conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 256, 256, 64) 0           activation_107[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 256, 256, 192 0           up_sampling2d_18[0][0]           \n",
      "                                                                 multiply_18[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 256, 256, 64) 110656      lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 256, 256, 64) 256         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 256, 256, 64) 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 256, 256, 64) 36928       activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 256, 256, 64) 256         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 256, 256, 64) 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_19 (UpSampling2D) (None, 512, 512, 64) 0           activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 512, 512, 16) 528         activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 512, 512, 16) 1040        up_sampling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 512, 512, 16) 0           conv2d_149[0][0]                 \n",
      "                                                                 conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 512, 512, 16) 0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 512, 512, 1)  17          activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 512, 512, 1)  0           conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 512, 512, 32) 0           activation_105[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 512, 512, 96) 0           up_sampling2d_19[0][0]           \n",
      "                                                                 multiply_19[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 512, 512, 32) 27680       lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 512, 512, 32) 128         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 512, 512, 32) 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 512, 512, 32) 9248        activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 512, 512, 32) 128         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 512, 512, 32) 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 512, 512, 1)  33          activation_129[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 7,989,717\n",
      "Trainable params: 7,983,829\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 2s 37ms/step\n",
      "ROI/New/357_HE.png\n",
      "(235, 512, 512)\n",
      "(235, 512, 512, 1)\n",
      "complete\n",
      "acc avg : 0.9799\n",
      "sensitivity avg : 0.9599\n",
      "specificity avg : 0.9868\n",
      "dsc avg : 0.9654\n",
      "------------------------------\n",
      "sensitivity min: 0.0\n",
      "specificity min: 0.9397713943320825\n",
      "dsc min: 0.8507699183358388\n",
      "acc min: 0.7907676696777344\n",
      "------------------------------\n",
      "sensitivity max: 0.993123904543616\n",
      "specificity max: 1.0\n",
      "dsc max: 0.9888142028836779\n",
      "acc max: 0.9941215515136719\n",
      "0.09214175688144088\n",
      "0.010103637504218572\n",
      "0.020030816718856984\n",
      "0.020632770120066226\n"
     ]
    }
   ],
   "source": [
    "for foldnum in range(0,5):\n",
    "    \n",
    "    save = []\n",
    "    \n",
    "    testset = fold[foldnum][1]\n",
    "    imgs_test, imgs_mask_test = load_data(testset)\n",
    "    model = load_model('6_result/exp_fold{}/model/best.h5'.format(foldnum), custom_objects={\"dice\": losses.dice, 'recall':recall})\n",
    "    print(model.summary())\n",
    "    # imgs_test, imgs_mask_test = load_data(testset[:4])\n",
    "    mask_pred = model.predict(imgs_test, batch_size=4, verbose=1)\n",
    "\n",
    "    print(testset[0])\n",
    "    # true_list=np.load(testset[0])\n",
    "    true_list = imgs_mask_test\n",
    "    true_list=true_list.astype('float32')\n",
    "    # true_list = true_list/255.0\n",
    "    # true_list[true_list > 0.5] = 1\n",
    "    # true_list[true_list <= 0.5] = 0\n",
    "    print(true_list.shape)\n",
    "\n",
    "    pred_list=mask_pred\n",
    "    # pred_list=imgs_mask_test\n",
    "    pred_list[pred_list > 0.5] = 1\n",
    "    pred_list[pred_list <= 0.5] = 0\n",
    "    print(pred_list.shape)\n",
    "\n",
    "    # for i in range(pred_list.shape[0]):\n",
    "    #     pred = pred_list[i].astype('uint8')\n",
    "    #     pred[pred <= 0.5] = 0\n",
    "    #     pred[pred > 0.5] = 255\n",
    "    # #     pred = fill_hole_cv(pred)\n",
    "    #     pred_list[i]=pred\n",
    "\n",
    "    # pred_list[pred_list > 127] = 1\n",
    "    # pred_list[pred_list <= 127] = 0\n",
    "\n",
    "    sensitivity=[]\n",
    "    specificity=[]\n",
    "    acc=[]\n",
    "    dsc=[]\n",
    "\n",
    "    for i in range(len(true_list)):\n",
    "        yt=true_list[i].flatten()\n",
    "        yp=pred_list[i].flatten()\n",
    "        mat=confusion_matrix(yt,yp)\n",
    "        if len(mat) == 2:\n",
    "            ac=(mat[1,1]+mat[0,0])/(mat[1,0]+mat[1,1]+mat[0,1]+mat[0,0])\n",
    "            st=mat[1,1]/(mat[1,0]+mat[1,1])\n",
    "            sp=mat[0,0]/(mat[0,1]+mat[0,0])\n",
    "            if mat[1,0]+mat[1,1] == 0:\n",
    "                specificity.append(sp)\n",
    "                acc.append(ac)\n",
    "            else:\n",
    "                sensitivity.append(st)  \n",
    "                specificity.append(sp)\n",
    "                acc.append(ac)\n",
    "        else:\n",
    "            specificity.append(1)\n",
    "            acc.append(1)\n",
    "\n",
    "    for i in range(len(true_list)):\n",
    "        yt=true_list[i]\n",
    "        yp=pred_list[i]\n",
    "        if np.sum(yt) != 0 and np.sum(yp) != 0:\n",
    "            dice = np.sum(yp[yt==1])*2.0 / (np.sum(yt) + np.sum(yp))\n",
    "            dsc.append(dice)\n",
    "\n",
    "    print(\"complete\")      \n",
    "    print(\"acc avg : {0:0.4f}\".format(np.mean(acc)))\n",
    "    print(\"sensitivity avg : {0:0.4f}\".format(np.mean(sensitivity)))\n",
    "    print(\"specificity avg : {0:0.4f}\".format(np.mean(specificity)))\n",
    "    print(\"dsc avg : {0:0.4f}\".format(np.mean(dsc)))\n",
    "    print('-'*30)\n",
    "    print(\"sensitivity min:\",np.min(sensitivity))\n",
    "    print(\"specificity min:\",np.min(specificity))\n",
    "    print(\"dsc min:\",np.min(dsc))\n",
    "    print(\"acc min:\",np.min(acc))\n",
    "    print('-'*30)\n",
    "    print(\"sensitivity max:\",np.max(sensitivity))\n",
    "    print(\"specificity max:\",np.max(specificity))\n",
    "    print(\"dsc max:\",np.max(dsc))\n",
    "    print(\"acc max:\",np.max(acc))\n",
    "    \n",
    "    print(np.std(sensitivity))\n",
    "    print(np.std(specificity))\n",
    "    print(np.std(dsc))\n",
    "    print(np.std(acc))\n",
    "    \n",
    "    imgs_test, imgs_mask_test = 0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
