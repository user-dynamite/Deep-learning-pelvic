{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eaaab57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T02:39:14.811713Z",
     "start_time": "2022-11-16T02:39:09.500068Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from SEResNeXt import SEResNeXt\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0,EfficientNetB4,EfficientNetB7\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.activations import relu,softmax\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tensorflow.keras.initializers import Zeros, Ones\n",
    "# from keras_layer_normalization import LayerNormalization\n",
    "# from keras.utils import multi_gpu_model\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "632f2dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch):\n",
    "    if epoch % 10 == 0:\n",
    "        K.set_value(model.optimizer.lr, K.eval(model.optimizer.lr) * 0.1)\n",
    "        print('LR!')\n",
    "    return K.eval(model.optimizer.lr)\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "    \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed\n",
    "\n",
    "def load_data(npy_path):\n",
    "    print('-'*30)\n",
    "    print('load images...')\n",
    "    print('-'*30)\n",
    "    \n",
    "    for i, path in enumerate(npy_path):\n",
    "#         print(path)\n",
    "        mask_npy_path = path.replace('_HE','_mask')\n",
    "#         mask_npy_path = path.replace('.png','_box.png')\n",
    "        train_npy_path = path\n",
    "    \n",
    "        imgs_tmp = [cv2.imread(train_npy_path)]\n",
    "        imgs_mask_tmp = [np.expand_dims(cv2.imread(mask_npy_path,0),-1)]\n",
    "#         img_weight = tf.where(tf.equal(imgs_mask_tmp, 255), 2, 1)\n",
    "        \n",
    "        if i==0:\n",
    "            imgs = imgs_tmp\n",
    "            imgs_mask = imgs_mask_tmp\n",
    "#             weights = img_weight\n",
    "        else:\n",
    "            imgs = np.append(imgs, imgs_tmp,axis=0)\n",
    "            imgs_mask = np.append(imgs_mask, imgs_mask_tmp,axis=0)\n",
    "#             weights = np.concatenate((weights, img_weight), axis=0)\n",
    "    imgs_tmp,imgs_mask_tmp = 0,0\n",
    "    print('-'*30)\n",
    "    print('imgs : {} \\nmasks : {}'.format(imgs.shape, imgs_mask.shape))    \n",
    "    print('-'*30)\n",
    "    imgs = imgs.astype('float32')\n",
    "    imgs_mask = imgs_mask.astype('float32')\n",
    "    print('img : ', imgs.max())\n",
    "    print('mask : ',imgs_mask.max())\n",
    "\n",
    "    print('-'*30)\n",
    "    print('normalization start...')\n",
    "    print('-'*30)\n",
    "    \n",
    "    imgs = cv2.normalize(imgs, None, 0, 1, cv2.NORM_MINMAX)\n",
    "\n",
    "    imgs_mask[imgs_mask<= 127] = 0\n",
    "    imgs_mask[imgs_mask > 127] = 1\n",
    "    \n",
    "   \n",
    "\n",
    "    print('img : ',imgs.max())\n",
    "    print('mask : ',imgs_mask.max())\n",
    "\n",
    "    return imgs, imgs_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4720d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d7111f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T02:39:28.452705Z",
     "start_time": "2022-11-16T02:39:14.978288Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (601, 512, 512, 3) \n",
      "masks : (601, 512, 512, 1)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (151, 512, 512, 3) \n",
      "masks : (151, 512, 512, 1)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data01/anaconda3/envs/jeon2/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "2023-07-19 09:10:07.394784: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 09:10:07.936672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22325 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:5e:00.0, compute capability: 8.6\n",
      "2023-07-19 09:10:14.340541: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 09:10:25.361911: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n",
      "2023-07-19 09:10:28.147973: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 45s 190ms/step - loss: 1.2539 - accuracy: 0.4592 - auc: 0.6932 - val_loss: 1.3020 - val_accuracy: 0.3642 - val_auc: 0.6431\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.30203, saving model to model/best_seg_0.h5\n",
      "Epoch 2/300\n",
      "151/151 [==============================] - 24s 159ms/step - loss: 1.0759 - accuracy: 0.5341 - auc: 0.7911 - val_loss: 1.3033 - val_accuracy: 0.3113 - val_auc: 0.6449\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.30203\n",
      "Epoch 3/300\n",
      "151/151 [==============================] - 25s 163ms/step - loss: 0.8599 - accuracy: 0.6639 - auc: 0.8764 - val_loss: 1.2637 - val_accuracy: 0.4636 - val_auc: 0.7415\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.30203 to 1.26369, saving model to model/best_seg_0.h5\n",
      "Epoch 4/300\n",
      "151/151 [==============================] - 25s 166ms/step - loss: 0.5538 - accuracy: 0.8020 - auc: 0.9505 - val_loss: 1.6022 - val_accuracy: 0.4834 - val_auc: 0.7404\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.26369\n",
      "Epoch 5/300\n",
      "151/151 [==============================] - 25s 164ms/step - loss: 0.3880 - accuracy: 0.8586 - auc: 0.9743 - val_loss: 1.9948 - val_accuracy: 0.4106 - val_auc: 0.7227\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.26369\n",
      "Epoch 6/300\n",
      "151/151 [==============================] - 25s 164ms/step - loss: 0.3279 - accuracy: 0.8835 - auc: 0.9802 - val_loss: 2.1143 - val_accuracy: 0.2914 - val_auc: 0.5657\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.26369\n",
      "Epoch 7/300\n",
      "151/151 [==============================] - 25s 162ms/step - loss: 0.1992 - accuracy: 0.9351 - auc: 0.9944 - val_loss: 1.9386 - val_accuracy: 0.4172 - val_auc: 0.6837\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.26369\n",
      "Epoch 8/300\n",
      "151/151 [==============================] - 25s 163ms/step - loss: 0.2064 - accuracy: 0.9285 - auc: 0.9924 - val_loss: 2.1926 - val_accuracy: 0.4702 - val_auc: 0.7362\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.26369\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-07.\n",
      "Epoch 9/300\n",
      "151/151 [==============================] - 24s 161ms/step - loss: 0.1666 - accuracy: 0.9501 - auc: 0.9943 - val_loss: 1.6927 - val_accuracy: 0.5099 - val_auc: 0.7613\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.26369\n",
      "Epoch 10/300\n",
      "151/151 [==============================] - 25s 166ms/step - loss: 0.1851 - accuracy: 0.9418 - auc: 0.9937 - val_loss: 1.6556 - val_accuracy: 0.5099 - val_auc: 0.7586\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.26369\n",
      "Epoch 11/300\n",
      "151/151 [==============================] - 24s 159ms/step - loss: 0.1578 - accuracy: 0.9418 - auc: 0.9956 - val_loss: 1.6343 - val_accuracy: 0.5033 - val_auc: 0.7544\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.26369\n",
      "Epoch 12/300\n",
      "151/151 [==============================] - 24s 162ms/step - loss: 0.1318 - accuracy: 0.9601 - auc: 0.9962 - val_loss: 1.6325 - val_accuracy: 0.5099 - val_auc: 0.7548\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.26369\n",
      "Epoch 13/300\n",
      "151/151 [==============================] - 24s 161ms/step - loss: 0.1466 - accuracy: 0.9634 - auc: 0.9955 - val_loss: 1.6192 - val_accuracy: 0.5099 - val_auc: 0.7568\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.26369\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.999999762527296e-09.\n",
      "Epoch 14/300\n",
      "151/151 [==============================] - 25s 162ms/step - loss: 0.1308 - accuracy: 0.9617 - auc: 0.9968 - val_loss: 1.6132 - val_accuracy: 0.5099 - val_auc: 0.7580\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.26369\n",
      "Epoch 15/300\n",
      "151/151 [==============================] - 24s 160ms/step - loss: 0.1599 - accuracy: 0.9534 - auc: 0.9941 - val_loss: 1.6236 - val_accuracy: 0.5033 - val_auc: 0.7561\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.26369\n",
      "Epoch 16/300\n",
      "151/151 [==============================] - 25s 162ms/step - loss: 0.1205 - accuracy: 0.9651 - auc: 0.9970 - val_loss: 1.6138 - val_accuracy: 0.5033 - val_auc: 0.7579\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.26369\n",
      "Epoch 17/300\n",
      "151/151 [==============================] - 24s 160ms/step - loss: 0.1727 - accuracy: 0.9534 - auc: 0.9940 - val_loss: 1.6094 - val_accuracy: 0.5033 - val_auc: 0.7551\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.26369\n",
      "Epoch 18/300\n",
      "151/151 [==============================] - 24s 162ms/step - loss: 0.1390 - accuracy: 0.9634 - auc: 0.9947 - val_loss: 1.6014 - val_accuracy: 0.5033 - val_auc: 0.7581\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.26369\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.9999998868722744e-11.\n",
      "Epoch 19/300\n",
      "151/151 [==============================] - 24s 159ms/step - loss: 0.1908 - accuracy: 0.9384 - auc: 0.9922 - val_loss: 1.6064 - val_accuracy: 0.5033 - val_auc: 0.7571\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.26369\n",
      "Epoch 20/300\n",
      "151/151 [==============================] - 24s 159ms/step - loss: 0.1280 - accuracy: 0.9651 - auc: 0.9975 - val_loss: 1.6156 - val_accuracy: 0.5099 - val_auc: 0.7571\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.26369\n",
      "Epoch 21/300\n",
      "151/151 [==============================] - 24s 158ms/step - loss: 0.1636 - accuracy: 0.9551 - auc: 0.9934 - val_loss: 1.6180 - val_accuracy: 0.5033 - val_auc: 0.7572\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.26369\n",
      "Epoch 22/300\n",
      "151/151 [==============================] - 24s 156ms/step - loss: 0.1534 - accuracy: 0.9551 - auc: 0.9953 - val_loss: 1.6223 - val_accuracy: 0.5099 - val_auc: 0.7560\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.26369\n",
      "Epoch 23/300\n",
      "151/151 [==============================] - 24s 158ms/step - loss: 0.1290 - accuracy: 0.9567 - auc: 0.9971 - val_loss: 1.6182 - val_accuracy: 0.5099 - val_auc: 0.7572\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.26369\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.999999984016789e-13.\n",
      "Epoch 00023: early stopping\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (601, 512, 512, 3) \n",
      "masks : (601, 512, 512, 1)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (151, 512, 512, 3) \n",
      "masks : (151, 512, 512, 1)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data01/anaconda3/envs/jeon2/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "151/151 [==============================] - 38s 178ms/step - loss: 1.2443 - accuracy: 0.4642 - auc_1: 0.6982 - val_loss: 1.3716 - val_accuracy: 0.2318 - val_auc_1: 0.5771\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.37157, saving model to model/best_seg_1.h5\n",
      "Epoch 2/300\n",
      "151/151 [==============================] - 25s 162ms/step - loss: 1.0984 - accuracy: 0.5408 - auc_1: 0.7834 - val_loss: 1.3487 - val_accuracy: 0.3709 - val_auc_1: 0.6598\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.37157 to 1.34873, saving model to model/best_seg_1.h5\n",
      "Epoch 3/300\n",
      "151/151 [==============================] - 25s 164ms/step - loss: 0.8860 - accuracy: 0.6473 - auc_1: 0.8642 - val_loss: 2.5983 - val_accuracy: 0.2185 - val_auc_1: 0.5087\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.34873\n",
      "Epoch 4/300\n",
      "151/151 [==============================] - 25s 164ms/step - loss: 0.5491 - accuracy: 0.7987 - auc_1: 0.9512 - val_loss: 1.4010 - val_accuracy: 0.4570 - val_auc_1: 0.7317\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.34873\n",
      "Epoch 5/300\n",
      "151/151 [==============================] - 25s 166ms/step - loss: 0.3550 - accuracy: 0.8918 - auc_1: 0.9782 - val_loss: 2.3168 - val_accuracy: 0.2649 - val_auc_1: 0.5944\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.34873\n",
      "Epoch 6/300\n",
      "151/151 [==============================] - 25s 165ms/step - loss: 0.2925 - accuracy: 0.9101 - auc_1: 0.9853 - val_loss: 1.8179 - val_accuracy: 0.4570 - val_auc_1: 0.7261\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.34873\n",
      "Epoch 7/300\n",
      "151/151 [==============================] - 25s 164ms/step - loss: 0.2410 - accuracy: 0.9285 - auc_1: 0.9892 - val_loss: 1.7542 - val_accuracy: 0.4238 - val_auc_1: 0.7354\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.34873\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-07.\n",
      "Epoch 8/300\n",
      "151/151 [==============================] - 24s 162ms/step - loss: 0.1489 - accuracy: 0.9468 - auc_1: 0.9966 - val_loss: 1.6109 - val_accuracy: 0.5166 - val_auc_1: 0.7538\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.34873\n",
      "Epoch 9/300\n",
      "151/151 [==============================] - 24s 161ms/step - loss: 0.1771 - accuracy: 0.9368 - auc_1: 0.9949 - val_loss: 1.5912 - val_accuracy: 0.5497 - val_auc_1: 0.7594\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.34873\n",
      "Epoch 10/300\n",
      "151/151 [==============================] - 25s 163ms/step - loss: 0.1541 - accuracy: 0.9468 - auc_1: 0.9962 - val_loss: 1.5823 - val_accuracy: 0.5497 - val_auc_1: 0.7602\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.34873\n",
      "Epoch 11/300\n",
      "151/151 [==============================] - 24s 159ms/step - loss: 0.1962 - accuracy: 0.9351 - auc_1: 0.9924 - val_loss: 1.5775 - val_accuracy: 0.5430 - val_auc_1: 0.7617\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.34873\n",
      "Epoch 12/300\n",
      "151/151 [==============================] - 24s 162ms/step - loss: 0.1298 - accuracy: 0.9634 - auc_1: 0.9980 - val_loss: 1.5797 - val_accuracy: 0.5364 - val_auc_1: 0.7662\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.34873\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.999999762527296e-09.\n",
      "Epoch 13/300\n",
      "151/151 [==============================] - 24s 158ms/step - loss: 0.1328 - accuracy: 0.9667 - auc_1: 0.9979 - val_loss: 1.5804 - val_accuracy: 0.5364 - val_auc_1: 0.7649\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.34873\n",
      "Epoch 14/300\n",
      "151/151 [==============================] - 24s 162ms/step - loss: 0.1191 - accuracy: 0.9601 - auc_1: 0.9983 - val_loss: 1.5786 - val_accuracy: 0.5364 - val_auc_1: 0.7642\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.34873\n",
      "Epoch 15/300\n",
      "151/151 [==============================] - 24s 158ms/step - loss: 0.1236 - accuracy: 0.9617 - auc_1: 0.9979 - val_loss: 1.5746 - val_accuracy: 0.5298 - val_auc_1: 0.7628\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.34873\n",
      "Epoch 16/300\n",
      "151/151 [==============================] - 24s 160ms/step - loss: 0.1281 - accuracy: 0.9634 - auc_1: 0.9977 - val_loss: 1.5754 - val_accuracy: 0.5364 - val_auc_1: 0.7618\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.34873\n",
      "Epoch 17/300\n",
      "151/151 [==============================] - 24s 157ms/step - loss: 0.1191 - accuracy: 0.9700 - auc_1: 0.9986 - val_loss: 1.5716 - val_accuracy: 0.5364 - val_auc_1: 0.7647\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.34873\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.9999998868722744e-11.\n",
      "Epoch 18/300\n",
      "151/151 [==============================] - 24s 158ms/step - loss: 0.1172 - accuracy: 0.9684 - auc_1: 0.9985 - val_loss: 1.5782 - val_accuracy: 0.5364 - val_auc_1: 0.7644\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.34873\n",
      "Epoch 19/300\n",
      "151/151 [==============================] - 24s 160ms/step - loss: 0.1429 - accuracy: 0.9634 - auc_1: 0.9970 - val_loss: 1.5833 - val_accuracy: 0.5364 - val_auc_1: 0.7618\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.34873\n",
      "Epoch 20/300\n",
      "151/151 [==============================] - 24s 158ms/step - loss: 0.1497 - accuracy: 0.9517 - auc_1: 0.9957 - val_loss: 1.5733 - val_accuracy: 0.5364 - val_auc_1: 0.7624\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.34873\n",
      "Epoch 21/300\n",
      "151/151 [==============================] - 24s 158ms/step - loss: 0.1382 - accuracy: 0.9634 - auc_1: 0.9973 - val_loss: 1.5695 - val_accuracy: 0.5364 - val_auc_1: 0.7631\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.34873\n",
      "Epoch 22/300\n",
      "151/151 [==============================] - 24s 159ms/step - loss: 0.1374 - accuracy: 0.9601 - auc_1: 0.9973 - val_loss: 1.5946 - val_accuracy: 0.5298 - val_auc_1: 0.7623\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.34873\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.999999984016789e-13.\n",
      "Epoch 00022: early stopping\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (601, 512, 512, 3) \n",
      "masks : (601, 512, 512, 1)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (151, 512, 512, 3) \n",
      "masks : (151, 512, 512, 1)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data01/anaconda3/envs/jeon2/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "151/151 [==============================] - 36s 169ms/step - loss: 1.2535 - accuracy: 0.4659 - auc_2: 0.6948 - val_loss: 1.3168 - val_accuracy: 0.3775 - val_auc_2: 0.6300\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.31678, saving model to model/best_seg_2.h5\n",
      "Epoch 2/300\n",
      "151/151 [==============================] - 23s 155ms/step - loss: 1.0627 - accuracy: 0.5358 - auc_2: 0.7980 - val_loss: 1.2097 - val_accuracy: 0.4636 - val_auc_2: 0.7343\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.31678 to 1.20966, saving model to model/best_seg_2.h5\n",
      "Epoch 3/300\n",
      "151/151 [==============================] - 24s 157ms/step - loss: 0.8207 - accuracy: 0.6622 - auc_2: 0.8832 - val_loss: 1.9263 - val_accuracy: 0.2318 - val_auc_2: 0.5169\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.20966\n",
      "Epoch 4/300\n",
      "151/151 [==============================] - 24s 161ms/step - loss: 0.5808 - accuracy: 0.7870 - auc_2: 0.9441 - val_loss: 1.7423 - val_accuracy: 0.4834 - val_auc_2: 0.7428\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.20966\n",
      "Epoch 5/300\n",
      "151/151 [==============================] - 24s 161ms/step - loss: 0.3891 - accuracy: 0.8719 - auc_2: 0.9753 - val_loss: 1.6057 - val_accuracy: 0.4570 - val_auc_2: 0.7486\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.20966\n",
      "Epoch 6/300\n",
      "151/151 [==============================] - 24s 162ms/step - loss: 0.2803 - accuracy: 0.8985 - auc_2: 0.9861 - val_loss: 1.7280 - val_accuracy: 0.4172 - val_auc_2: 0.7224\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.20966\n",
      "Epoch 7/300\n",
      "151/151 [==============================] - 25s 163ms/step - loss: 0.2616 - accuracy: 0.9201 - auc_2: 0.9868 - val_loss: 1.7325 - val_accuracy: 0.4437 - val_auc_2: 0.7026\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.20966\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-07.\n",
      "Epoch 8/300\n",
      "151/151 [==============================] - 24s 160ms/step - loss: 0.2158 - accuracy: 0.9218 - auc_2: 0.9927 - val_loss: 1.4763 - val_accuracy: 0.5099 - val_auc_2: 0.7520\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.20966\n",
      "Epoch 9/300\n",
      "151/151 [==============================] - 24s 160ms/step - loss: 0.2069 - accuracy: 0.9434 - auc_2: 0.9931 - val_loss: 1.4646 - val_accuracy: 0.4901 - val_auc_2: 0.7579\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.20966\n",
      "Epoch 10/300\n",
      "151/151 [==============================] - 24s 160ms/step - loss: 0.1667 - accuracy: 0.9501 - auc_2: 0.9965 - val_loss: 1.4728 - val_accuracy: 0.4901 - val_auc_2: 0.7564\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.20966\n",
      "Epoch 11/300\n",
      "151/151 [==============================] - 24s 159ms/step - loss: 0.1447 - accuracy: 0.9617 - auc_2: 0.9975 - val_loss: 1.4727 - val_accuracy: 0.4901 - val_auc_2: 0.7581\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.20966\n",
      "Epoch 12/300\n",
      "151/151 [==============================] - 24s 161ms/step - loss: 0.1687 - accuracy: 0.9451 - auc_2: 0.9963 - val_loss: 1.4903 - val_accuracy: 0.4967 - val_auc_2: 0.7572\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.20966\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.999999762527296e-09.\n",
      "Epoch 13/300\n",
      "151/151 [==============================] - 25s 163ms/step - loss: 0.1586 - accuracy: 0.9551 - auc_2: 0.9963 - val_loss: 1.4862 - val_accuracy: 0.4901 - val_auc_2: 0.7573\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.20966\n",
      "Epoch 14/300\n",
      "151/151 [==============================] - 24s 162ms/step - loss: 0.1797 - accuracy: 0.9468 - auc_2: 0.9954 - val_loss: 1.4685 - val_accuracy: 0.4967 - val_auc_2: 0.7585\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.20966\n",
      "Epoch 15/300\n",
      "151/151 [==============================] - 24s 162ms/step - loss: 0.1486 - accuracy: 0.9634 - auc_2: 0.9968 - val_loss: 1.4687 - val_accuracy: 0.4967 - val_auc_2: 0.7580\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.20966\n",
      "Epoch 16/300\n",
      "151/151 [==============================] - 25s 162ms/step - loss: 0.1687 - accuracy: 0.9567 - auc_2: 0.9950 - val_loss: 1.4737 - val_accuracy: 0.4967 - val_auc_2: 0.7575\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.20966\n",
      "Epoch 17/300\n",
      "151/151 [==============================] - 24s 160ms/step - loss: 0.1441 - accuracy: 0.9684 - auc_2: 0.9974 - val_loss: 1.4703 - val_accuracy: 0.4834 - val_auc_2: 0.7578\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.20966\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.9999998868722744e-11.\n",
      "Epoch 18/300\n",
      "151/151 [==============================] - 24s 161ms/step - loss: 0.1520 - accuracy: 0.9567 - auc_2: 0.9951 - val_loss: 1.4847 - val_accuracy: 0.4967 - val_auc_2: 0.7579\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.20966\n",
      "Epoch 19/300\n",
      "151/151 [==============================] - 24s 161ms/step - loss: 0.1610 - accuracy: 0.9584 - auc_2: 0.9966 - val_loss: 1.4709 - val_accuracy: 0.4967 - val_auc_2: 0.7589\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.20966\n",
      "Epoch 20/300\n",
      "151/151 [==============================] - 24s 161ms/step - loss: 0.1756 - accuracy: 0.9517 - auc_2: 0.9952 - val_loss: 1.4869 - val_accuracy: 0.5033 - val_auc_2: 0.7561\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.20966\n",
      "Epoch 21/300\n",
      "151/151 [==============================] - 24s 162ms/step - loss: 0.1499 - accuracy: 0.9684 - auc_2: 0.9972 - val_loss: 1.4877 - val_accuracy: 0.4967 - val_auc_2: 0.7542\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.20966\n",
      "Epoch 22/300\n",
      "151/151 [==============================] - 24s 161ms/step - loss: 0.1738 - accuracy: 0.9567 - auc_2: 0.9948 - val_loss: 1.4840 - val_accuracy: 0.5099 - val_auc_2: 0.7556\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.20966\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.999999984016789e-13.\n",
      "Epoch 00022: early stopping\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (601, 512, 512, 3) \n",
      "masks : (601, 512, 512, 1)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (151, 512, 512, 3) \n",
      "masks : (151, 512, 512, 1)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data01/anaconda3/envs/jeon2/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "151/151 [==============================] - 37s 179ms/step - loss: 1.2548 - accuracy: 0.4809 - auc_3: 0.6935 - val_loss: 1.1843 - val_accuracy: 0.4901 - val_auc_3: 0.7400\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.18429, saving model to model/best_seg_3.h5\n",
      "Epoch 2/300\n",
      "151/151 [==============================] - 25s 164ms/step - loss: 1.1143 - accuracy: 0.5108 - auc_3: 0.7749 - val_loss: 2.1268 - val_accuracy: 0.1325 - val_auc_3: 0.4962\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.18429\n",
      "Epoch 3/300\n",
      "151/151 [==============================] - 25s 166ms/step - loss: 0.8541 - accuracy: 0.6606 - auc_3: 0.8745 - val_loss: 1.3370 - val_accuracy: 0.4702 - val_auc_3: 0.7338\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.18429\n",
      "Epoch 4/300\n",
      "151/151 [==============================] - 24s 161ms/step - loss: 0.6576 - accuracy: 0.7304 - auc_3: 0.9256 - val_loss: 1.1461 - val_accuracy: 0.5894 - val_auc_3: 0.7907\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.18429 to 1.14614, saving model to model/best_seg_3.h5\n",
      "Epoch 5/300\n",
      "151/151 [==============================] - 24s 161ms/step - loss: 0.4607 - accuracy: 0.8220 - auc_3: 0.9641 - val_loss: 2.3093 - val_accuracy: 0.2517 - val_auc_3: 0.5428\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.14614\n",
      "Epoch 6/300\n",
      "151/151 [==============================] - 24s 161ms/step - loss: 0.3046 - accuracy: 0.8985 - auc_3: 0.9855 - val_loss: 1.9643 - val_accuracy: 0.4967 - val_auc_3: 0.7311\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.14614\n",
      "Epoch 7/300\n",
      "151/151 [==============================] - 24s 162ms/step - loss: 0.2581 - accuracy: 0.9118 - auc_3: 0.9885 - val_loss: 2.1658 - val_accuracy: 0.4768 - val_auc_3: 0.7209\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.14614\n",
      "Epoch 8/300\n",
      "151/151 [==============================] - 25s 165ms/step - loss: 0.1720 - accuracy: 0.9468 - auc_3: 0.9954 - val_loss: 1.8361 - val_accuracy: 0.3974 - val_auc_3: 0.7010\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.14614\n",
      "Epoch 9/300\n",
      "151/151 [==============================] - 24s 162ms/step - loss: 0.1901 - accuracy: 0.9451 - auc_3: 0.9937 - val_loss: 1.7983 - val_accuracy: 0.5166 - val_auc_3: 0.7593\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.14614\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-07.\n",
      "Epoch 10/300\n",
      "151/151 [==============================] - 24s 158ms/step - loss: 0.2440 - accuracy: 0.9135 - auc_3: 0.9884 - val_loss: 1.6242 - val_accuracy: 0.5232 - val_auc_3: 0.7697\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.14614\n",
      "Epoch 11/300\n",
      "151/151 [==============================] - 24s 162ms/step - loss: 0.1591 - accuracy: 0.9484 - auc_3: 0.9955 - val_loss: 1.6435 - val_accuracy: 0.5166 - val_auc_3: 0.7671\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.14614\n",
      "Epoch 12/300\n",
      "151/151 [==============================] - 24s 159ms/step - loss: 0.1703 - accuracy: 0.9551 - auc_3: 0.9930 - val_loss: 1.6466 - val_accuracy: 0.5298 - val_auc_3: 0.7650\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.14614\n",
      "Epoch 13/300\n",
      "151/151 [==============================] - 24s 161ms/step - loss: 0.1268 - accuracy: 0.9651 - auc_3: 0.9971 - val_loss: 1.6523 - val_accuracy: 0.5033 - val_auc_3: 0.7638\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.14614\n",
      "Epoch 14/300\n",
      "151/151 [==============================] - 24s 159ms/step - loss: 0.1212 - accuracy: 0.9551 - auc_3: 0.9971 - val_loss: 1.6521 - val_accuracy: 0.5033 - val_auc_3: 0.7614\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.14614\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 3.999999762527296e-09.\n",
      "Epoch 15/300\n",
      "151/151 [==============================] - 24s 158ms/step - loss: 0.1824 - accuracy: 0.9501 - auc_3: 0.9927 - val_loss: 1.6475 - val_accuracy: 0.5099 - val_auc_3: 0.7633\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.14614\n",
      "Epoch 16/300\n",
      "151/151 [==============================] - 24s 159ms/step - loss: 0.1762 - accuracy: 0.9384 - auc_3: 0.9930 - val_loss: 1.6389 - val_accuracy: 0.4967 - val_auc_3: 0.7640\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.14614\n",
      "Epoch 17/300\n",
      "151/151 [==============================] - 24s 161ms/step - loss: 0.1451 - accuracy: 0.9584 - auc_3: 0.9952 - val_loss: 1.6466 - val_accuracy: 0.5099 - val_auc_3: 0.7660\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.14614\n",
      "Epoch 18/300\n",
      "151/151 [==============================] - 24s 162ms/step - loss: 0.1845 - accuracy: 0.9434 - auc_3: 0.9930 - val_loss: 1.6688 - val_accuracy: 0.5033 - val_auc_3: 0.7659\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.14614\n",
      "Epoch 19/300\n",
      "151/151 [==============================] - 24s 157ms/step - loss: 0.1303 - accuracy: 0.9651 - auc_3: 0.9964 - val_loss: 1.6311 - val_accuracy: 0.5099 - val_auc_3: 0.7630\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.14614\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.9999998868722744e-11.\n",
      "Epoch 20/300\n",
      "151/151 [==============================] - 24s 159ms/step - loss: 0.1279 - accuracy: 0.9567 - auc_3: 0.9976 - val_loss: 1.6394 - val_accuracy: 0.5166 - val_auc_3: 0.7632\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.14614\n",
      "Epoch 21/300\n",
      "151/151 [==============================] - 24s 159ms/step - loss: 0.1257 - accuracy: 0.9651 - auc_3: 0.9976 - val_loss: 1.6436 - val_accuracy: 0.5166 - val_auc_3: 0.7642\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.14614\n",
      "Epoch 22/300\n",
      "151/151 [==============================] - 24s 158ms/step - loss: 0.1433 - accuracy: 0.9651 - auc_3: 0.9966 - val_loss: 1.6332 - val_accuracy: 0.5232 - val_auc_3: 0.7641\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.14614\n",
      "Epoch 23/300\n",
      "151/151 [==============================] - 24s 158ms/step - loss: 0.1327 - accuracy: 0.9601 - auc_3: 0.9970 - val_loss: 1.6362 - val_accuracy: 0.5166 - val_auc_3: 0.7651\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.14614\n",
      "Epoch 24/300\n",
      "151/151 [==============================] - 24s 158ms/step - loss: 0.1672 - accuracy: 0.9434 - auc_3: 0.9952 - val_loss: 1.6536 - val_accuracy: 0.5033 - val_auc_3: 0.7652\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.14614\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 3.999999984016789e-13.\n",
      "Epoch 00024: early stopping\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (601, 512, 512, 3) \n",
      "masks : (601, 512, 512, 1)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (151, 512, 512, 3) \n",
      "masks : (151, 512, 512, 1)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data01/anaconda3/envs/jeon2/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "151/151 [==============================] - 37s 177ms/step - loss: 1.2325 - accuracy: 0.4576 - auc_4: 0.7065 - val_loss: 1.2560 - val_accuracy: 0.4172 - val_auc_4: 0.6821\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.25600, saving model to model/best_seg_4.h5\n",
      "Epoch 2/300\n",
      "151/151 [==============================] - 24s 156ms/step - loss: 1.0248 - accuracy: 0.5724 - auc_4: 0.8150 - val_loss: 1.2712 - val_accuracy: 0.4636 - val_auc_4: 0.7358\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.25600\n",
      "Epoch 3/300\n",
      "151/151 [==============================] - 24s 162ms/step - loss: 0.8454 - accuracy: 0.6356 - auc_4: 0.8761 - val_loss: 1.2494 - val_accuracy: 0.4768 - val_auc_4: 0.7713\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.25600 to 1.24944, saving model to model/best_seg_4.h5\n",
      "Epoch 4/300\n",
      "151/151 [==============================] - 24s 160ms/step - loss: 0.5400 - accuracy: 0.8053 - auc_4: 0.9506 - val_loss: 1.5166 - val_accuracy: 0.4437 - val_auc_4: 0.7240\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.24944\n",
      "Epoch 5/300\n",
      "151/151 [==============================] - 25s 166ms/step - loss: 0.3841 - accuracy: 0.8636 - auc_4: 0.9760 - val_loss: 1.4895 - val_accuracy: 0.4503 - val_auc_4: 0.7336\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24944\n",
      "Epoch 6/300\n",
      "151/151 [==============================] - 25s 163ms/step - loss: 0.3131 - accuracy: 0.8935 - auc_4: 0.9823 - val_loss: 1.4572 - val_accuracy: 0.4702 - val_auc_4: 0.7594\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.24944\n",
      "Epoch 7/300\n",
      "151/151 [==============================] - 25s 165ms/step - loss: 0.1994 - accuracy: 0.9268 - auc_4: 0.9937 - val_loss: 2.1525 - val_accuracy: 0.4834 - val_auc_4: 0.7561\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24944\n",
      "Epoch 8/300\n",
      "151/151 [==============================] - 25s 164ms/step - loss: 0.2010 - accuracy: 0.9301 - auc_4: 0.9927 - val_loss: 2.9905 - val_accuracy: 0.3510 - val_auc_4: 0.6047\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.24944\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-07.\n",
      "Epoch 9/300\n",
      "151/151 [==============================] - 24s 160ms/step - loss: 0.1807 - accuracy: 0.9434 - auc_4: 0.9946 - val_loss: 1.7345 - val_accuracy: 0.4437 - val_auc_4: 0.7259\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.24944\n",
      "Epoch 10/300\n",
      "151/151 [==============================] - 25s 163ms/step - loss: 0.1396 - accuracy: 0.9617 - auc_4: 0.9968 - val_loss: 1.6504 - val_accuracy: 0.4702 - val_auc_4: 0.7408\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.24944\n",
      "Epoch 11/300\n",
      "151/151 [==============================] - 24s 159ms/step - loss: 0.1367 - accuracy: 0.9617 - auc_4: 0.9974 - val_loss: 1.6356 - val_accuracy: 0.4967 - val_auc_4: 0.7440\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.24944\n",
      "Epoch 12/300\n",
      "151/151 [==============================] - 24s 160ms/step - loss: 0.0953 - accuracy: 0.9734 - auc_4: 0.9992 - val_loss: 1.6308 - val_accuracy: 0.4901 - val_auc_4: 0.7469\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.24944\n",
      "Epoch 13/300\n",
      "151/151 [==============================] - 24s 160ms/step - loss: 0.1350 - accuracy: 0.9634 - auc_4: 0.9960 - val_loss: 1.6350 - val_accuracy: 0.4901 - val_auc_4: 0.7445\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.24944\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.999999762527296e-09.\n",
      "Epoch 14/300\n",
      "151/151 [==============================] - 25s 164ms/step - loss: 0.1283 - accuracy: 0.9601 - auc_4: 0.9972 - val_loss: 1.6203 - val_accuracy: 0.4834 - val_auc_4: 0.7483\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.24944\n",
      "Epoch 15/300\n",
      "151/151 [==============================] - 24s 158ms/step - loss: 0.1074 - accuracy: 0.9717 - auc_4: 0.9981 - val_loss: 1.6245 - val_accuracy: 0.4768 - val_auc_4: 0.7491\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.24944\n",
      "Epoch 16/300\n",
      "151/151 [==============================] - 24s 159ms/step - loss: 0.1070 - accuracy: 0.9651 - auc_4: 0.9986 - val_loss: 1.6183 - val_accuracy: 0.4702 - val_auc_4: 0.7460\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.24944\n",
      "Epoch 17/300\n",
      "151/151 [==============================] - 24s 159ms/step - loss: 0.0995 - accuracy: 0.9667 - auc_4: 0.9988 - val_loss: 1.6291 - val_accuracy: 0.4768 - val_auc_4: 0.7456\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.24944\n",
      "Epoch 18/300\n",
      "151/151 [==============================] - 24s 159ms/step - loss: 0.0945 - accuracy: 0.9817 - auc_4: 0.9991 - val_loss: 1.6320 - val_accuracy: 0.4768 - val_auc_4: 0.7451\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.24944\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.9999998868722744e-11.\n",
      "Epoch 19/300\n",
      "151/151 [==============================] - 24s 160ms/step - loss: 0.1126 - accuracy: 0.9651 - auc_4: 0.9973 - val_loss: 1.6287 - val_accuracy: 0.4834 - val_auc_4: 0.7461\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.24944\n",
      "Epoch 20/300\n",
      "151/151 [==============================] - 24s 158ms/step - loss: 0.1130 - accuracy: 0.9700 - auc_4: 0.9969 - val_loss: 1.6090 - val_accuracy: 0.4834 - val_auc_4: 0.7465\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.24944\n",
      "Epoch 21/300\n",
      "151/151 [==============================] - 24s 159ms/step - loss: 0.1202 - accuracy: 0.9601 - auc_4: 0.9982 - val_loss: 1.6310 - val_accuracy: 0.4834 - val_auc_4: 0.7486\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.24944\n",
      "Epoch 22/300\n",
      "151/151 [==============================] - 24s 160ms/step - loss: 0.0983 - accuracy: 0.9800 - auc_4: 0.9981 - val_loss: 1.6266 - val_accuracy: 0.4702 - val_auc_4: 0.7462\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.24944\n",
      "Epoch 23/300\n",
      "151/151 [==============================] - 24s 160ms/step - loss: 0.1066 - accuracy: 0.9684 - auc_4: 0.9986 - val_loss: 1.6266 - val_accuracy: 0.4768 - val_auc_4: 0.7433\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.24944\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.999999984016789e-13.\n",
      "Epoch 00023: early stopping\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('all_filter_seg.csv')\n",
    "kf = StratifiedKFold(n_splits=5, random_state=333, shuffle=True)\n",
    "\n",
    "foldnum=0\n",
    "for train_index, test_index in kf.split(df,df['class']):\n",
    "    TV, test = df.iloc[train_index], df.iloc[test_index]\n",
    "    train,validation = train_test_split(TV,test_size=0.2,random_state=333)\n",
    "\n",
    "    imgs_train, imgs_mask_train = load_data(train.path)\n",
    "    imgs_val, imgs_mask_val = load_data(validation.path)\n",
    "\n",
    "    train_y = pd.get_dummies(train['class'])\n",
    "    val_y = pd.get_dummies(validation['class'])\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=5, verbose=1, min_delta=1e-8)\n",
    "\n",
    "    #reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=1, min_lr=0.001)\n",
    "    earlystopper = EarlyStopping(monitor='val_loss',patience=20, verbose=1)\n",
    "\n",
    "    batch_size=1\n",
    "    epochs=300\n",
    "    opt = Adam(lr=0.00004, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "    image_input = Input(shape=(input_size, input_size, 3), dtype='float32')\n",
    "\n",
    "    base_model = InceptionResNetV2(input_tensor=image_input, weights='imagenet', pooling='avg', include_top=False)\n",
    "    base_model.trainable = True\n",
    "\n",
    "    x = base_model.layers[-1].output\n",
    "#     x = tf.keras.layers.Flatten()(x)\n",
    "#     x = Dropout(0.5)(x)\n",
    "#     x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "#     x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "\n",
    "    output_layer = Dense(4, activation='softmax', name='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=image_input, outputs=output_layer)\n",
    "    \n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy',tf.keras.metrics.AUC()])\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(filepath= \"model/best_seg_{}.h5\".format(foldnum), \n",
    "                                       monitor='val_loss', \n",
    "                                       verbose=1, \n",
    "                                       save_best_only=True,\n",
    "                                       save_weights_only=False)\n",
    "\n",
    "    hist = model.fit(imgs_train, train_y,\n",
    "                        epochs=epochs,\n",
    "                        batch_size = 4,\n",
    "                        use_multiprocessing=True,\n",
    "                        validation_data=(imgs_val, val_y),\n",
    "                        workers=0,\n",
    "                        callbacks = [earlystopper, model_checkpoint,reduce_lr])\n",
    "    model.save(filepath=\"model/last_seg_{}.h5\".format(foldnum))\n",
    "\n",
    "    foldnum += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c53c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36891721",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_812 (Conv2D)             (None, 255, 255, 32) 864         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_812 (BatchN (None, 255, 255, 32) 96          conv2d_812[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_812 (Activation)     (None, 255, 255, 32) 0           batch_normalization_812[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_813 (Conv2D)             (None, 253, 253, 32) 9216        activation_812[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_813 (BatchN (None, 253, 253, 32) 96          conv2d_813[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_813 (Activation)     (None, 253, 253, 32) 0           batch_normalization_813[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_814 (Conv2D)             (None, 253, 253, 64) 18432       activation_813[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_814 (BatchN (None, 253, 253, 64) 192         conv2d_814[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_814 (Activation)     (None, 253, 253, 64) 0           batch_normalization_814[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 126, 126, 64) 0           activation_814[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_815 (Conv2D)             (None, 126, 126, 80) 5120        max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_815 (BatchN (None, 126, 126, 80) 240         conv2d_815[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_815 (Activation)     (None, 126, 126, 80) 0           batch_normalization_815[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_816 (Conv2D)             (None, 124, 124, 192 138240      activation_815[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_816 (BatchN (None, 124, 124, 192 576         conv2d_816[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_816 (Activation)     (None, 124, 124, 192 0           batch_normalization_816[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 61, 61, 192)  0           activation_816[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_820 (Conv2D)             (None, 61, 61, 64)   12288       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_820 (BatchN (None, 61, 61, 64)   192         conv2d_820[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_820 (Activation)     (None, 61, 61, 64)   0           batch_normalization_820[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_818 (Conv2D)             (None, 61, 61, 48)   9216        max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_821 (Conv2D)             (None, 61, 61, 96)   55296       activation_820[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_818 (BatchN (None, 61, 61, 48)   144         conv2d_818[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_821 (BatchN (None, 61, 61, 96)   288         conv2d_821[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_818 (Activation)     (None, 61, 61, 48)   0           batch_normalization_818[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_821 (Activation)     (None, 61, 61, 96)   0           batch_normalization_821[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 61, 61, 192)  0           max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_817 (Conv2D)             (None, 61, 61, 96)   18432       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_819 (Conv2D)             (None, 61, 61, 64)   76800       activation_818[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_822 (Conv2D)             (None, 61, 61, 96)   82944       activation_821[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_823 (Conv2D)             (None, 61, 61, 64)   12288       average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_817 (BatchN (None, 61, 61, 96)   288         conv2d_817[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_819 (BatchN (None, 61, 61, 64)   192         conv2d_819[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_822 (BatchN (None, 61, 61, 96)   288         conv2d_822[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_823 (BatchN (None, 61, 61, 64)   192         conv2d_823[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_817 (Activation)     (None, 61, 61, 96)   0           batch_normalization_817[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_819 (Activation)     (None, 61, 61, 64)   0           batch_normalization_819[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_822 (Activation)     (None, 61, 61, 96)   0           batch_normalization_822[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_823 (Activation)     (None, 61, 61, 64)   0           batch_normalization_823[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 61, 61, 320)  0           activation_817[0][0]             \n",
      "                                                                 activation_819[0][0]             \n",
      "                                                                 activation_822[0][0]             \n",
      "                                                                 activation_823[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_827 (Conv2D)             (None, 61, 61, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_827 (BatchN (None, 61, 61, 32)   96          conv2d_827[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_827 (Activation)     (None, 61, 61, 32)   0           batch_normalization_827[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_825 (Conv2D)             (None, 61, 61, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_828 (Conv2D)             (None, 61, 61, 48)   13824       activation_827[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_825 (BatchN (None, 61, 61, 32)   96          conv2d_825[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_828 (BatchN (None, 61, 61, 48)   144         conv2d_828[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_825 (Activation)     (None, 61, 61, 32)   0           batch_normalization_825[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_828 (Activation)     (None, 61, 61, 48)   0           batch_normalization_828[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_824 (Conv2D)             (None, 61, 61, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_826 (Conv2D)             (None, 61, 61, 32)   9216        activation_825[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_829 (Conv2D)             (None, 61, 61, 64)   27648       activation_828[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_824 (BatchN (None, 61, 61, 32)   96          conv2d_824[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_826 (BatchN (None, 61, 61, 32)   96          conv2d_826[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_829 (BatchN (None, 61, 61, 64)   192         conv2d_829[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_824 (Activation)     (None, 61, 61, 32)   0           batch_normalization_824[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_826 (Activation)     (None, 61, 61, 32)   0           batch_normalization_826[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_829 (Activation)     (None, 61, 61, 64)   0           batch_normalization_829[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 61, 61, 128)  0           activation_824[0][0]             \n",
      "                                                                 activation_826[0][0]             \n",
      "                                                                 activation_829[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 61, 61, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 61, 61, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 61, 61, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_833 (Conv2D)             (None, 61, 61, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_833 (BatchN (None, 61, 61, 32)   96          conv2d_833[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_833 (Activation)     (None, 61, 61, 32)   0           batch_normalization_833[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_831 (Conv2D)             (None, 61, 61, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_834 (Conv2D)             (None, 61, 61, 48)   13824       activation_833[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_831 (BatchN (None, 61, 61, 32)   96          conv2d_831[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_834 (BatchN (None, 61, 61, 48)   144         conv2d_834[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_831 (Activation)     (None, 61, 61, 32)   0           batch_normalization_831[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_834 (Activation)     (None, 61, 61, 48)   0           batch_normalization_834[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_830 (Conv2D)             (None, 61, 61, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_832 (Conv2D)             (None, 61, 61, 32)   9216        activation_831[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_835 (Conv2D)             (None, 61, 61, 64)   27648       activation_834[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_830 (BatchN (None, 61, 61, 32)   96          conv2d_830[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_832 (BatchN (None, 61, 61, 32)   96          conv2d_832[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_835 (BatchN (None, 61, 61, 64)   192         conv2d_835[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_830 (Activation)     (None, 61, 61, 32)   0           batch_normalization_830[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_832 (Activation)     (None, 61, 61, 32)   0           batch_normalization_832[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_835 (Activation)     (None, 61, 61, 64)   0           batch_normalization_835[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 61, 61, 128)  0           activation_830[0][0]             \n",
      "                                                                 activation_832[0][0]             \n",
      "                                                                 activation_835[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 61, 61, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 61, 61, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 61, 61, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_839 (Conv2D)             (None, 61, 61, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_839 (BatchN (None, 61, 61, 32)   96          conv2d_839[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_839 (Activation)     (None, 61, 61, 32)   0           batch_normalization_839[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_837 (Conv2D)             (None, 61, 61, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_840 (Conv2D)             (None, 61, 61, 48)   13824       activation_839[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_837 (BatchN (None, 61, 61, 32)   96          conv2d_837[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_840 (BatchN (None, 61, 61, 48)   144         conv2d_840[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_837 (Activation)     (None, 61, 61, 32)   0           batch_normalization_837[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_840 (Activation)     (None, 61, 61, 48)   0           batch_normalization_840[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_836 (Conv2D)             (None, 61, 61, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_838 (Conv2D)             (None, 61, 61, 32)   9216        activation_837[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_841 (Conv2D)             (None, 61, 61, 64)   27648       activation_840[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_836 (BatchN (None, 61, 61, 32)   96          conv2d_836[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_838 (BatchN (None, 61, 61, 32)   96          conv2d_838[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_841 (BatchN (None, 61, 61, 64)   192         conv2d_841[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_836 (Activation)     (None, 61, 61, 32)   0           batch_normalization_836[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_838 (Activation)     (None, 61, 61, 32)   0           batch_normalization_838[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_841 (Activation)     (None, 61, 61, 64)   0           batch_normalization_841[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 61, 61, 128)  0           activation_836[0][0]             \n",
      "                                                                 activation_838[0][0]             \n",
      "                                                                 activation_841[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 61, 61, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 61, 61, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 61, 61, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_845 (Conv2D)             (None, 61, 61, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_845 (BatchN (None, 61, 61, 32)   96          conv2d_845[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_845 (Activation)     (None, 61, 61, 32)   0           batch_normalization_845[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_843 (Conv2D)             (None, 61, 61, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_846 (Conv2D)             (None, 61, 61, 48)   13824       activation_845[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_843 (BatchN (None, 61, 61, 32)   96          conv2d_843[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_846 (BatchN (None, 61, 61, 48)   144         conv2d_846[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_843 (Activation)     (None, 61, 61, 32)   0           batch_normalization_843[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_846 (Activation)     (None, 61, 61, 48)   0           batch_normalization_846[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_842 (Conv2D)             (None, 61, 61, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_844 (Conv2D)             (None, 61, 61, 32)   9216        activation_843[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_847 (Conv2D)             (None, 61, 61, 64)   27648       activation_846[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_842 (BatchN (None, 61, 61, 32)   96          conv2d_842[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_844 (BatchN (None, 61, 61, 32)   96          conv2d_844[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_847 (BatchN (None, 61, 61, 64)   192         conv2d_847[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_842 (Activation)     (None, 61, 61, 32)   0           batch_normalization_842[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_844 (Activation)     (None, 61, 61, 32)   0           batch_normalization_844[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_847 (Activation)     (None, 61, 61, 64)   0           batch_normalization_847[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 61, 61, 128)  0           activation_842[0][0]             \n",
      "                                                                 activation_844[0][0]             \n",
      "                                                                 activation_847[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 61, 61, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 61, 61, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 61, 61, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_851 (Conv2D)             (None, 61, 61, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_851 (BatchN (None, 61, 61, 32)   96          conv2d_851[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_851 (Activation)     (None, 61, 61, 32)   0           batch_normalization_851[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_849 (Conv2D)             (None, 61, 61, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_852 (Conv2D)             (None, 61, 61, 48)   13824       activation_851[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_849 (BatchN (None, 61, 61, 32)   96          conv2d_849[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_852 (BatchN (None, 61, 61, 48)   144         conv2d_852[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_849 (Activation)     (None, 61, 61, 32)   0           batch_normalization_849[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_852 (Activation)     (None, 61, 61, 48)   0           batch_normalization_852[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_848 (Conv2D)             (None, 61, 61, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_850 (Conv2D)             (None, 61, 61, 32)   9216        activation_849[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_853 (Conv2D)             (None, 61, 61, 64)   27648       activation_852[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_848 (BatchN (None, 61, 61, 32)   96          conv2d_848[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_850 (BatchN (None, 61, 61, 32)   96          conv2d_850[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_853 (BatchN (None, 61, 61, 64)   192         conv2d_853[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_848 (Activation)     (None, 61, 61, 32)   0           batch_normalization_848[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_850 (Activation)     (None, 61, 61, 32)   0           batch_normalization_850[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_853 (Activation)     (None, 61, 61, 64)   0           batch_normalization_853[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 61, 61, 128)  0           activation_848[0][0]             \n",
      "                                                                 activation_850[0][0]             \n",
      "                                                                 activation_853[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 61, 61, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 61, 61, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 61, 61, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_857 (Conv2D)             (None, 61, 61, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_857 (BatchN (None, 61, 61, 32)   96          conv2d_857[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_857 (Activation)     (None, 61, 61, 32)   0           batch_normalization_857[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_855 (Conv2D)             (None, 61, 61, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_858 (Conv2D)             (None, 61, 61, 48)   13824       activation_857[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_855 (BatchN (None, 61, 61, 32)   96          conv2d_855[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_858 (BatchN (None, 61, 61, 48)   144         conv2d_858[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_855 (Activation)     (None, 61, 61, 32)   0           batch_normalization_855[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_858 (Activation)     (None, 61, 61, 48)   0           batch_normalization_858[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_854 (Conv2D)             (None, 61, 61, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_856 (Conv2D)             (None, 61, 61, 32)   9216        activation_855[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_859 (Conv2D)             (None, 61, 61, 64)   27648       activation_858[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_854 (BatchN (None, 61, 61, 32)   96          conv2d_854[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_856 (BatchN (None, 61, 61, 32)   96          conv2d_856[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_859 (BatchN (None, 61, 61, 64)   192         conv2d_859[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_854 (Activation)     (None, 61, 61, 32)   0           batch_normalization_854[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_856 (Activation)     (None, 61, 61, 32)   0           batch_normalization_856[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_859 (Activation)     (None, 61, 61, 64)   0           batch_normalization_859[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 61, 61, 128)  0           activation_854[0][0]             \n",
      "                                                                 activation_856[0][0]             \n",
      "                                                                 activation_859[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 61, 61, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 61, 61, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 61, 61, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_863 (Conv2D)             (None, 61, 61, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_863 (BatchN (None, 61, 61, 32)   96          conv2d_863[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_863 (Activation)     (None, 61, 61, 32)   0           batch_normalization_863[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_861 (Conv2D)             (None, 61, 61, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_864 (Conv2D)             (None, 61, 61, 48)   13824       activation_863[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_861 (BatchN (None, 61, 61, 32)   96          conv2d_861[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_864 (BatchN (None, 61, 61, 48)   144         conv2d_864[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_861 (Activation)     (None, 61, 61, 32)   0           batch_normalization_861[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_864 (Activation)     (None, 61, 61, 48)   0           batch_normalization_864[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_860 (Conv2D)             (None, 61, 61, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_862 (Conv2D)             (None, 61, 61, 32)   9216        activation_861[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_865 (Conv2D)             (None, 61, 61, 64)   27648       activation_864[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_860 (BatchN (None, 61, 61, 32)   96          conv2d_860[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_862 (BatchN (None, 61, 61, 32)   96          conv2d_862[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_865 (BatchN (None, 61, 61, 64)   192         conv2d_865[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_860 (Activation)     (None, 61, 61, 32)   0           batch_normalization_860[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_862 (Activation)     (None, 61, 61, 32)   0           batch_normalization_862[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_865 (Activation)     (None, 61, 61, 64)   0           batch_normalization_865[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 61, 61, 128)  0           activation_860[0][0]             \n",
      "                                                                 activation_862[0][0]             \n",
      "                                                                 activation_865[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 61, 61, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 61, 61, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 61, 61, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_869 (Conv2D)             (None, 61, 61, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_869 (BatchN (None, 61, 61, 32)   96          conv2d_869[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_869 (Activation)     (None, 61, 61, 32)   0           batch_normalization_869[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_867 (Conv2D)             (None, 61, 61, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_870 (Conv2D)             (None, 61, 61, 48)   13824       activation_869[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_867 (BatchN (None, 61, 61, 32)   96          conv2d_867[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_870 (BatchN (None, 61, 61, 48)   144         conv2d_870[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_867 (Activation)     (None, 61, 61, 32)   0           batch_normalization_867[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_870 (Activation)     (None, 61, 61, 48)   0           batch_normalization_870[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_866 (Conv2D)             (None, 61, 61, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_868 (Conv2D)             (None, 61, 61, 32)   9216        activation_867[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_871 (Conv2D)             (None, 61, 61, 64)   27648       activation_870[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_866 (BatchN (None, 61, 61, 32)   96          conv2d_866[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_868 (BatchN (None, 61, 61, 32)   96          conv2d_868[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_871 (BatchN (None, 61, 61, 64)   192         conv2d_871[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_866 (Activation)     (None, 61, 61, 32)   0           batch_normalization_866[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_868 (Activation)     (None, 61, 61, 32)   0           batch_normalization_868[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_871 (Activation)     (None, 61, 61, 64)   0           batch_normalization_871[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 61, 61, 128)  0           activation_866[0][0]             \n",
      "                                                                 activation_868[0][0]             \n",
      "                                                                 activation_871[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 61, 61, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 61, 61, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 61, 61, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_875 (Conv2D)             (None, 61, 61, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_875 (BatchN (None, 61, 61, 32)   96          conv2d_875[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_875 (Activation)     (None, 61, 61, 32)   0           batch_normalization_875[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_873 (Conv2D)             (None, 61, 61, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_876 (Conv2D)             (None, 61, 61, 48)   13824       activation_875[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_873 (BatchN (None, 61, 61, 32)   96          conv2d_873[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_876 (BatchN (None, 61, 61, 48)   144         conv2d_876[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_873 (Activation)     (None, 61, 61, 32)   0           batch_normalization_873[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_876 (Activation)     (None, 61, 61, 48)   0           batch_normalization_876[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_872 (Conv2D)             (None, 61, 61, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_874 (Conv2D)             (None, 61, 61, 32)   9216        activation_873[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_877 (Conv2D)             (None, 61, 61, 64)   27648       activation_876[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_872 (BatchN (None, 61, 61, 32)   96          conv2d_872[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_874 (BatchN (None, 61, 61, 32)   96          conv2d_874[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_877 (BatchN (None, 61, 61, 64)   192         conv2d_877[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_872 (Activation)     (None, 61, 61, 32)   0           batch_normalization_872[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_874 (Activation)     (None, 61, 61, 32)   0           batch_normalization_874[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_877 (Activation)     (None, 61, 61, 64)   0           batch_normalization_877[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 61, 61, 128)  0           activation_872[0][0]             \n",
      "                                                                 activation_874[0][0]             \n",
      "                                                                 activation_877[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 61, 61, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 61, 61, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 61, 61, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_881 (Conv2D)             (None, 61, 61, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_881 (BatchN (None, 61, 61, 32)   96          conv2d_881[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_881 (Activation)     (None, 61, 61, 32)   0           batch_normalization_881[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_879 (Conv2D)             (None, 61, 61, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_882 (Conv2D)             (None, 61, 61, 48)   13824       activation_881[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_879 (BatchN (None, 61, 61, 32)   96          conv2d_879[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_882 (BatchN (None, 61, 61, 48)   144         conv2d_882[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_879 (Activation)     (None, 61, 61, 32)   0           batch_normalization_879[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_882 (Activation)     (None, 61, 61, 48)   0           batch_normalization_882[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_878 (Conv2D)             (None, 61, 61, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_880 (Conv2D)             (None, 61, 61, 32)   9216        activation_879[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_883 (Conv2D)             (None, 61, 61, 64)   27648       activation_882[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_878 (BatchN (None, 61, 61, 32)   96          conv2d_878[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_880 (BatchN (None, 61, 61, 32)   96          conv2d_880[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_883 (BatchN (None, 61, 61, 64)   192         conv2d_883[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_878 (Activation)     (None, 61, 61, 32)   0           batch_normalization_878[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_880 (Activation)     (None, 61, 61, 32)   0           batch_normalization_880[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_883 (Activation)     (None, 61, 61, 64)   0           batch_normalization_883[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 61, 61, 128)  0           activation_878[0][0]             \n",
      "                                                                 activation_880[0][0]             \n",
      "                                                                 activation_883[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 61, 61, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 61, 61, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 61, 61, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_885 (Conv2D)             (None, 61, 61, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_885 (BatchN (None, 61, 61, 256)  768         conv2d_885[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_885 (Activation)     (None, 61, 61, 256)  0           batch_normalization_885[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_886 (Conv2D)             (None, 61, 61, 256)  589824      activation_885[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_886 (BatchN (None, 61, 61, 256)  768         conv2d_886[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_886 (Activation)     (None, 61, 61, 256)  0           batch_normalization_886[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_884 (Conv2D)             (None, 30, 30, 384)  1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_887 (Conv2D)             (None, 30, 30, 384)  884736      activation_886[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_884 (BatchN (None, 30, 30, 384)  1152        conv2d_884[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_887 (BatchN (None, 30, 30, 384)  1152        conv2d_887[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_884 (Activation)     (None, 30, 30, 384)  0           batch_normalization_884[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_887 (Activation)     (None, 30, 30, 384)  0           batch_normalization_887[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 30, 30, 320)  0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 30, 30, 1088) 0           activation_884[0][0]             \n",
      "                                                                 activation_887[0][0]             \n",
      "                                                                 max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_889 (Conv2D)             (None, 30, 30, 128)  139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_889 (BatchN (None, 30, 30, 128)  384         conv2d_889[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_889 (Activation)     (None, 30, 30, 128)  0           batch_normalization_889[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_890 (Conv2D)             (None, 30, 30, 160)  143360      activation_889[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_890 (BatchN (None, 30, 30, 160)  480         conv2d_890[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_890 (Activation)     (None, 30, 30, 160)  0           batch_normalization_890[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_888 (Conv2D)             (None, 30, 30, 192)  208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_891 (Conv2D)             (None, 30, 30, 192)  215040      activation_890[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_888 (BatchN (None, 30, 30, 192)  576         conv2d_888[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_891 (BatchN (None, 30, 30, 192)  576         conv2d_891[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_888 (Activation)     (None, 30, 30, 192)  0           batch_normalization_888[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_891 (Activation)     (None, 30, 30, 192)  0           batch_normalization_891[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 30, 30, 384)  0           activation_888[0][0]             \n",
      "                                                                 activation_891[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 30, 30, 1088) 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 30, 30, 1088) 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 30, 30, 1088) 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_893 (Conv2D)             (None, 30, 30, 128)  139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_893 (BatchN (None, 30, 30, 128)  384         conv2d_893[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_893 (Activation)     (None, 30, 30, 128)  0           batch_normalization_893[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_894 (Conv2D)             (None, 30, 30, 160)  143360      activation_893[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_894 (BatchN (None, 30, 30, 160)  480         conv2d_894[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_894 (Activation)     (None, 30, 30, 160)  0           batch_normalization_894[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_892 (Conv2D)             (None, 30, 30, 192)  208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_895 (Conv2D)             (None, 30, 30, 192)  215040      activation_894[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_892 (BatchN (None, 30, 30, 192)  576         conv2d_892[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_895 (BatchN (None, 30, 30, 192)  576         conv2d_895[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_892 (Activation)     (None, 30, 30, 192)  0           batch_normalization_892[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_895 (Activation)     (None, 30, 30, 192)  0           batch_normalization_895[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 30, 30, 384)  0           activation_892[0][0]             \n",
      "                                                                 activation_895[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 30, 30, 1088) 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 30, 30, 1088) 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 30, 30, 1088) 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_897 (Conv2D)             (None, 30, 30, 128)  139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_897 (BatchN (None, 30, 30, 128)  384         conv2d_897[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_897 (Activation)     (None, 30, 30, 128)  0           batch_normalization_897[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_898 (Conv2D)             (None, 30, 30, 160)  143360      activation_897[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_898 (BatchN (None, 30, 30, 160)  480         conv2d_898[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_898 (Activation)     (None, 30, 30, 160)  0           batch_normalization_898[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_896 (Conv2D)             (None, 30, 30, 192)  208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_899 (Conv2D)             (None, 30, 30, 192)  215040      activation_898[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_896 (BatchN (None, 30, 30, 192)  576         conv2d_896[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_899 (BatchN (None, 30, 30, 192)  576         conv2d_899[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_896 (Activation)     (None, 30, 30, 192)  0           batch_normalization_896[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_899 (Activation)     (None, 30, 30, 192)  0           batch_normalization_899[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 30, 30, 384)  0           activation_896[0][0]             \n",
      "                                                                 activation_899[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 30, 30, 1088) 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 30, 30, 1088) 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 30, 30, 1088) 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_901 (Conv2D)             (None, 30, 30, 128)  139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_901 (BatchN (None, 30, 30, 128)  384         conv2d_901[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_901 (Activation)     (None, 30, 30, 128)  0           batch_normalization_901[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_902 (Conv2D)             (None, 30, 30, 160)  143360      activation_901[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_902 (BatchN (None, 30, 30, 160)  480         conv2d_902[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_902 (Activation)     (None, 30, 30, 160)  0           batch_normalization_902[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_900 (Conv2D)             (None, 30, 30, 192)  208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_903 (Conv2D)             (None, 30, 30, 192)  215040      activation_902[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_900 (BatchN (None, 30, 30, 192)  576         conv2d_900[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_903 (BatchN (None, 30, 30, 192)  576         conv2d_903[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_900 (Activation)     (None, 30, 30, 192)  0           batch_normalization_900[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_903 (Activation)     (None, 30, 30, 192)  0           batch_normalization_903[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 30, 30, 384)  0           activation_900[0][0]             \n",
      "                                                                 activation_903[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 30, 30, 1088) 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 30, 30, 1088) 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 30, 30, 1088) 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_905 (Conv2D)             (None, 30, 30, 128)  139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_905 (BatchN (None, 30, 30, 128)  384         conv2d_905[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_905 (Activation)     (None, 30, 30, 128)  0           batch_normalization_905[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_906 (Conv2D)             (None, 30, 30, 160)  143360      activation_905[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_906 (BatchN (None, 30, 30, 160)  480         conv2d_906[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_906 (Activation)     (None, 30, 30, 160)  0           batch_normalization_906[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_904 (Conv2D)             (None, 30, 30, 192)  208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_907 (Conv2D)             (None, 30, 30, 192)  215040      activation_906[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_904 (BatchN (None, 30, 30, 192)  576         conv2d_904[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_907 (BatchN (None, 30, 30, 192)  576         conv2d_907[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_904 (Activation)     (None, 30, 30, 192)  0           batch_normalization_904[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_907 (Activation)     (None, 30, 30, 192)  0           batch_normalization_907[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 30, 30, 384)  0           activation_904[0][0]             \n",
      "                                                                 activation_907[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 30, 30, 1088) 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 30, 30, 1088) 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 30, 30, 1088) 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_909 (Conv2D)             (None, 30, 30, 128)  139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_909 (BatchN (None, 30, 30, 128)  384         conv2d_909[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_909 (Activation)     (None, 30, 30, 128)  0           batch_normalization_909[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_910 (Conv2D)             (None, 30, 30, 160)  143360      activation_909[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_910 (BatchN (None, 30, 30, 160)  480         conv2d_910[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_910 (Activation)     (None, 30, 30, 160)  0           batch_normalization_910[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_908 (Conv2D)             (None, 30, 30, 192)  208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_911 (Conv2D)             (None, 30, 30, 192)  215040      activation_910[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_908 (BatchN (None, 30, 30, 192)  576         conv2d_908[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_911 (BatchN (None, 30, 30, 192)  576         conv2d_911[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_908 (Activation)     (None, 30, 30, 192)  0           batch_normalization_908[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_911 (Activation)     (None, 30, 30, 192)  0           batch_normalization_911[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 30, 30, 384)  0           activation_908[0][0]             \n",
      "                                                                 activation_911[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 30, 30, 1088) 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 30, 30, 1088) 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 30, 30, 1088) 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_913 (Conv2D)             (None, 30, 30, 128)  139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_913 (BatchN (None, 30, 30, 128)  384         conv2d_913[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_913 (Activation)     (None, 30, 30, 128)  0           batch_normalization_913[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_914 (Conv2D)             (None, 30, 30, 160)  143360      activation_913[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_914 (BatchN (None, 30, 30, 160)  480         conv2d_914[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_914 (Activation)     (None, 30, 30, 160)  0           batch_normalization_914[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_912 (Conv2D)             (None, 30, 30, 192)  208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_915 (Conv2D)             (None, 30, 30, 192)  215040      activation_914[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_912 (BatchN (None, 30, 30, 192)  576         conv2d_912[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_915 (BatchN (None, 30, 30, 192)  576         conv2d_915[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_912 (Activation)     (None, 30, 30, 192)  0           batch_normalization_912[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_915 (Activation)     (None, 30, 30, 192)  0           batch_normalization_915[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 30, 30, 384)  0           activation_912[0][0]             \n",
      "                                                                 activation_915[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 30, 30, 1088) 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 30, 30, 1088) 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 30, 30, 1088) 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_917 (Conv2D)             (None, 30, 30, 128)  139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_917 (BatchN (None, 30, 30, 128)  384         conv2d_917[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_917 (Activation)     (None, 30, 30, 128)  0           batch_normalization_917[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_918 (Conv2D)             (None, 30, 30, 160)  143360      activation_917[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_918 (BatchN (None, 30, 30, 160)  480         conv2d_918[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_918 (Activation)     (None, 30, 30, 160)  0           batch_normalization_918[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_916 (Conv2D)             (None, 30, 30, 192)  208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_919 (Conv2D)             (None, 30, 30, 192)  215040      activation_918[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_916 (BatchN (None, 30, 30, 192)  576         conv2d_916[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_919 (BatchN (None, 30, 30, 192)  576         conv2d_919[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_916 (Activation)     (None, 30, 30, 192)  0           batch_normalization_916[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_919 (Activation)     (None, 30, 30, 192)  0           batch_normalization_919[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 30, 30, 384)  0           activation_916[0][0]             \n",
      "                                                                 activation_919[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 30, 30, 1088) 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 30, 30, 1088) 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 30, 30, 1088) 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_921 (Conv2D)             (None, 30, 30, 128)  139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_921 (BatchN (None, 30, 30, 128)  384         conv2d_921[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_921 (Activation)     (None, 30, 30, 128)  0           batch_normalization_921[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_922 (Conv2D)             (None, 30, 30, 160)  143360      activation_921[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_922 (BatchN (None, 30, 30, 160)  480         conv2d_922[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_922 (Activation)     (None, 30, 30, 160)  0           batch_normalization_922[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_920 (Conv2D)             (None, 30, 30, 192)  208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_923 (Conv2D)             (None, 30, 30, 192)  215040      activation_922[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_920 (BatchN (None, 30, 30, 192)  576         conv2d_920[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_923 (BatchN (None, 30, 30, 192)  576         conv2d_923[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_920 (Activation)     (None, 30, 30, 192)  0           batch_normalization_920[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_923 (Activation)     (None, 30, 30, 192)  0           batch_normalization_923[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 30, 30, 384)  0           activation_920[0][0]             \n",
      "                                                                 activation_923[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 30, 30, 1088) 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 30, 30, 1088) 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 30, 30, 1088) 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_925 (Conv2D)             (None, 30, 30, 128)  139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_925 (BatchN (None, 30, 30, 128)  384         conv2d_925[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_925 (Activation)     (None, 30, 30, 128)  0           batch_normalization_925[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_926 (Conv2D)             (None, 30, 30, 160)  143360      activation_925[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_926 (BatchN (None, 30, 30, 160)  480         conv2d_926[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_926 (Activation)     (None, 30, 30, 160)  0           batch_normalization_926[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_924 (Conv2D)             (None, 30, 30, 192)  208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_927 (Conv2D)             (None, 30, 30, 192)  215040      activation_926[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_924 (BatchN (None, 30, 30, 192)  576         conv2d_924[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_927 (BatchN (None, 30, 30, 192)  576         conv2d_927[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_924 (Activation)     (None, 30, 30, 192)  0           batch_normalization_924[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_927 (Activation)     (None, 30, 30, 192)  0           batch_normalization_927[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 30, 30, 384)  0           activation_924[0][0]             \n",
      "                                                                 activation_927[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 30, 30, 1088) 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 30, 30, 1088) 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 30, 30, 1088) 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_929 (Conv2D)             (None, 30, 30, 128)  139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_929 (BatchN (None, 30, 30, 128)  384         conv2d_929[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_929 (Activation)     (None, 30, 30, 128)  0           batch_normalization_929[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_930 (Conv2D)             (None, 30, 30, 160)  143360      activation_929[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_930 (BatchN (None, 30, 30, 160)  480         conv2d_930[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_930 (Activation)     (None, 30, 30, 160)  0           batch_normalization_930[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_928 (Conv2D)             (None, 30, 30, 192)  208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_931 (Conv2D)             (None, 30, 30, 192)  215040      activation_930[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_928 (BatchN (None, 30, 30, 192)  576         conv2d_928[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_931 (BatchN (None, 30, 30, 192)  576         conv2d_931[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_928 (Activation)     (None, 30, 30, 192)  0           batch_normalization_928[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_931 (Activation)     (None, 30, 30, 192)  0           batch_normalization_931[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 30, 30, 384)  0           activation_928[0][0]             \n",
      "                                                                 activation_931[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 30, 30, 1088) 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 30, 30, 1088) 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 30, 30, 1088) 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_933 (Conv2D)             (None, 30, 30, 128)  139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_933 (BatchN (None, 30, 30, 128)  384         conv2d_933[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_933 (Activation)     (None, 30, 30, 128)  0           batch_normalization_933[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_934 (Conv2D)             (None, 30, 30, 160)  143360      activation_933[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_934 (BatchN (None, 30, 30, 160)  480         conv2d_934[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_934 (Activation)     (None, 30, 30, 160)  0           batch_normalization_934[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_932 (Conv2D)             (None, 30, 30, 192)  208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_935 (Conv2D)             (None, 30, 30, 192)  215040      activation_934[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_932 (BatchN (None, 30, 30, 192)  576         conv2d_932[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_935 (BatchN (None, 30, 30, 192)  576         conv2d_935[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_932 (Activation)     (None, 30, 30, 192)  0           batch_normalization_932[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_935 (Activation)     (None, 30, 30, 192)  0           batch_normalization_935[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 30, 30, 384)  0           activation_932[0][0]             \n",
      "                                                                 activation_935[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 30, 30, 1088) 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 30, 30, 1088) 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 30, 30, 1088) 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_937 (Conv2D)             (None, 30, 30, 128)  139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_937 (BatchN (None, 30, 30, 128)  384         conv2d_937[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_937 (Activation)     (None, 30, 30, 128)  0           batch_normalization_937[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_938 (Conv2D)             (None, 30, 30, 160)  143360      activation_937[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_938 (BatchN (None, 30, 30, 160)  480         conv2d_938[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_938 (Activation)     (None, 30, 30, 160)  0           batch_normalization_938[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_936 (Conv2D)             (None, 30, 30, 192)  208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_939 (Conv2D)             (None, 30, 30, 192)  215040      activation_938[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_936 (BatchN (None, 30, 30, 192)  576         conv2d_936[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_939 (BatchN (None, 30, 30, 192)  576         conv2d_939[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_936 (Activation)     (None, 30, 30, 192)  0           batch_normalization_936[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_939 (Activation)     (None, 30, 30, 192)  0           batch_normalization_939[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 30, 30, 384)  0           activation_936[0][0]             \n",
      "                                                                 activation_939[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 30, 30, 1088) 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 30, 30, 1088) 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 30, 30, 1088) 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_941 (Conv2D)             (None, 30, 30, 128)  139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_941 (BatchN (None, 30, 30, 128)  384         conv2d_941[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_941 (Activation)     (None, 30, 30, 128)  0           batch_normalization_941[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_942 (Conv2D)             (None, 30, 30, 160)  143360      activation_941[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_942 (BatchN (None, 30, 30, 160)  480         conv2d_942[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_942 (Activation)     (None, 30, 30, 160)  0           batch_normalization_942[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_940 (Conv2D)             (None, 30, 30, 192)  208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_943 (Conv2D)             (None, 30, 30, 192)  215040      activation_942[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_940 (BatchN (None, 30, 30, 192)  576         conv2d_940[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_943 (BatchN (None, 30, 30, 192)  576         conv2d_943[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_940 (Activation)     (None, 30, 30, 192)  0           batch_normalization_940[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_943 (Activation)     (None, 30, 30, 192)  0           batch_normalization_943[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 30, 30, 384)  0           activation_940[0][0]             \n",
      "                                                                 activation_943[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 30, 30, 1088) 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 30, 30, 1088) 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 30, 30, 1088) 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_945 (Conv2D)             (None, 30, 30, 128)  139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_945 (BatchN (None, 30, 30, 128)  384         conv2d_945[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_945 (Activation)     (None, 30, 30, 128)  0           batch_normalization_945[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_946 (Conv2D)             (None, 30, 30, 160)  143360      activation_945[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_946 (BatchN (None, 30, 30, 160)  480         conv2d_946[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_946 (Activation)     (None, 30, 30, 160)  0           batch_normalization_946[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_944 (Conv2D)             (None, 30, 30, 192)  208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_947 (Conv2D)             (None, 30, 30, 192)  215040      activation_946[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_944 (BatchN (None, 30, 30, 192)  576         conv2d_944[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_947 (BatchN (None, 30, 30, 192)  576         conv2d_947[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_944 (Activation)     (None, 30, 30, 192)  0           batch_normalization_944[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_947 (Activation)     (None, 30, 30, 192)  0           batch_normalization_947[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 30, 30, 384)  0           activation_944[0][0]             \n",
      "                                                                 activation_947[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 30, 30, 1088) 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 30, 30, 1088) 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 30, 30, 1088) 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_949 (Conv2D)             (None, 30, 30, 128)  139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_949 (BatchN (None, 30, 30, 128)  384         conv2d_949[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_949 (Activation)     (None, 30, 30, 128)  0           batch_normalization_949[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_950 (Conv2D)             (None, 30, 30, 160)  143360      activation_949[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_950 (BatchN (None, 30, 30, 160)  480         conv2d_950[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_950 (Activation)     (None, 30, 30, 160)  0           batch_normalization_950[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_948 (Conv2D)             (None, 30, 30, 192)  208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_951 (Conv2D)             (None, 30, 30, 192)  215040      activation_950[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_948 (BatchN (None, 30, 30, 192)  576         conv2d_948[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_951 (BatchN (None, 30, 30, 192)  576         conv2d_951[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_948 (Activation)     (None, 30, 30, 192)  0           batch_normalization_948[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_951 (Activation)     (None, 30, 30, 192)  0           batch_normalization_951[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 30, 30, 384)  0           activation_948[0][0]             \n",
      "                                                                 activation_951[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 30, 30, 1088) 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 30, 30, 1088) 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 30, 30, 1088) 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_953 (Conv2D)             (None, 30, 30, 128)  139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_953 (BatchN (None, 30, 30, 128)  384         conv2d_953[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_953 (Activation)     (None, 30, 30, 128)  0           batch_normalization_953[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_954 (Conv2D)             (None, 30, 30, 160)  143360      activation_953[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_954 (BatchN (None, 30, 30, 160)  480         conv2d_954[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_954 (Activation)     (None, 30, 30, 160)  0           batch_normalization_954[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_952 (Conv2D)             (None, 30, 30, 192)  208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_955 (Conv2D)             (None, 30, 30, 192)  215040      activation_954[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_952 (BatchN (None, 30, 30, 192)  576         conv2d_952[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_955 (BatchN (None, 30, 30, 192)  576         conv2d_955[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_952 (Activation)     (None, 30, 30, 192)  0           batch_normalization_952[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_955 (Activation)     (None, 30, 30, 192)  0           batch_normalization_955[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 30, 30, 384)  0           activation_952[0][0]             \n",
      "                                                                 activation_955[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 30, 30, 1088) 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 30, 30, 1088) 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 30, 30, 1088) 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_957 (Conv2D)             (None, 30, 30, 128)  139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_957 (BatchN (None, 30, 30, 128)  384         conv2d_957[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_957 (Activation)     (None, 30, 30, 128)  0           batch_normalization_957[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_958 (Conv2D)             (None, 30, 30, 160)  143360      activation_957[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_958 (BatchN (None, 30, 30, 160)  480         conv2d_958[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_958 (Activation)     (None, 30, 30, 160)  0           batch_normalization_958[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_956 (Conv2D)             (None, 30, 30, 192)  208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_959 (Conv2D)             (None, 30, 30, 192)  215040      activation_958[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_956 (BatchN (None, 30, 30, 192)  576         conv2d_956[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_959 (BatchN (None, 30, 30, 192)  576         conv2d_959[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_956 (Activation)     (None, 30, 30, 192)  0           batch_normalization_956[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_959 (Activation)     (None, 30, 30, 192)  0           batch_normalization_959[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 30, 30, 384)  0           activation_956[0][0]             \n",
      "                                                                 activation_959[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 30, 30, 1088) 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 30, 30, 1088) 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 30, 30, 1088) 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_961 (Conv2D)             (None, 30, 30, 128)  139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_961 (BatchN (None, 30, 30, 128)  384         conv2d_961[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_961 (Activation)     (None, 30, 30, 128)  0           batch_normalization_961[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_962 (Conv2D)             (None, 30, 30, 160)  143360      activation_961[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_962 (BatchN (None, 30, 30, 160)  480         conv2d_962[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_962 (Activation)     (None, 30, 30, 160)  0           batch_normalization_962[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_960 (Conv2D)             (None, 30, 30, 192)  208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_963 (Conv2D)             (None, 30, 30, 192)  215040      activation_962[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_960 (BatchN (None, 30, 30, 192)  576         conv2d_960[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_963 (BatchN (None, 30, 30, 192)  576         conv2d_963[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_960 (Activation)     (None, 30, 30, 192)  0           batch_normalization_960[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_963 (Activation)     (None, 30, 30, 192)  0           batch_normalization_963[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 30, 30, 384)  0           activation_960[0][0]             \n",
      "                                                                 activation_963[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 30, 30, 1088) 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 30, 30, 1088) 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 30, 30, 1088) 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_965 (Conv2D)             (None, 30, 30, 128)  139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_965 (BatchN (None, 30, 30, 128)  384         conv2d_965[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_965 (Activation)     (None, 30, 30, 128)  0           batch_normalization_965[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_966 (Conv2D)             (None, 30, 30, 160)  143360      activation_965[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_966 (BatchN (None, 30, 30, 160)  480         conv2d_966[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_966 (Activation)     (None, 30, 30, 160)  0           batch_normalization_966[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_964 (Conv2D)             (None, 30, 30, 192)  208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_967 (Conv2D)             (None, 30, 30, 192)  215040      activation_966[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_964 (BatchN (None, 30, 30, 192)  576         conv2d_964[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_967 (BatchN (None, 30, 30, 192)  576         conv2d_967[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_964 (Activation)     (None, 30, 30, 192)  0           batch_normalization_964[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_967 (Activation)     (None, 30, 30, 192)  0           batch_normalization_967[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 30, 30, 384)  0           activation_964[0][0]             \n",
      "                                                                 activation_967[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 30, 30, 1088) 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 30, 30, 1088) 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 30, 30, 1088) 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_972 (Conv2D)             (None, 30, 30, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_972 (BatchN (None, 30, 30, 256)  768         conv2d_972[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_972 (Activation)     (None, 30, 30, 256)  0           batch_normalization_972[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_968 (Conv2D)             (None, 30, 30, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_970 (Conv2D)             (None, 30, 30, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_973 (Conv2D)             (None, 30, 30, 288)  663552      activation_972[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_968 (BatchN (None, 30, 30, 256)  768         conv2d_968[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_970 (BatchN (None, 30, 30, 256)  768         conv2d_970[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_973 (BatchN (None, 30, 30, 288)  864         conv2d_973[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_968 (Activation)     (None, 30, 30, 256)  0           batch_normalization_968[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_970 (Activation)     (None, 30, 30, 256)  0           batch_normalization_970[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_973 (Activation)     (None, 30, 30, 288)  0           batch_normalization_973[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_969 (Conv2D)             (None, 14, 14, 384)  884736      activation_968[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_971 (Conv2D)             (None, 14, 14, 288)  663552      activation_970[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_974 (Conv2D)             (None, 14, 14, 320)  829440      activation_973[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_969 (BatchN (None, 14, 14, 384)  1152        conv2d_969[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_971 (BatchN (None, 14, 14, 288)  864         conv2d_971[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_974 (BatchN (None, 14, 14, 320)  960         conv2d_974[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_969 (Activation)     (None, 14, 14, 384)  0           batch_normalization_969[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_971 (Activation)     (None, 14, 14, 288)  0           batch_normalization_971[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_974 (Activation)     (None, 14, 14, 320)  0           batch_normalization_974[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 14, 14, 1088) 0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, 14, 14, 2080) 0           activation_969[0][0]             \n",
      "                                                                 activation_971[0][0]             \n",
      "                                                                 activation_974[0][0]             \n",
      "                                                                 max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_976 (Conv2D)             (None, 14, 14, 192)  399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_976 (BatchN (None, 14, 14, 192)  576         conv2d_976[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_976 (Activation)     (None, 14, 14, 192)  0           batch_normalization_976[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_977 (Conv2D)             (None, 14, 14, 224)  129024      activation_976[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_977 (BatchN (None, 14, 14, 224)  672         conv2d_977[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_977 (Activation)     (None, 14, 14, 224)  0           batch_normalization_977[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_975 (Conv2D)             (None, 14, 14, 192)  399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_978 (Conv2D)             (None, 14, 14, 256)  172032      activation_977[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_975 (BatchN (None, 14, 14, 192)  576         conv2d_975[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_978 (BatchN (None, 14, 14, 256)  768         conv2d_978[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_975 (Activation)     (None, 14, 14, 192)  0           batch_normalization_975[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_978 (Activation)     (None, 14, 14, 256)  0           batch_normalization_978[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 14, 14, 448)  0           activation_975[0][0]             \n",
      "                                                                 activation_978[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 14, 14, 2080) 933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 14, 14, 2080) 0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 14, 14, 2080) 0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_980 (Conv2D)             (None, 14, 14, 192)  399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_980 (BatchN (None, 14, 14, 192)  576         conv2d_980[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_980 (Activation)     (None, 14, 14, 192)  0           batch_normalization_980[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_981 (Conv2D)             (None, 14, 14, 224)  129024      activation_980[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_981 (BatchN (None, 14, 14, 224)  672         conv2d_981[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_981 (Activation)     (None, 14, 14, 224)  0           batch_normalization_981[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_979 (Conv2D)             (None, 14, 14, 192)  399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_982 (Conv2D)             (None, 14, 14, 256)  172032      activation_981[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_979 (BatchN (None, 14, 14, 192)  576         conv2d_979[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_982 (BatchN (None, 14, 14, 256)  768         conv2d_982[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_979 (Activation)     (None, 14, 14, 192)  0           batch_normalization_979[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_982 (Activation)     (None, 14, 14, 256)  0           batch_normalization_982[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 14, 14, 448)  0           activation_979[0][0]             \n",
      "                                                                 activation_982[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 14, 14, 2080) 933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 14, 14, 2080) 0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 14, 14, 2080) 0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_984 (Conv2D)             (None, 14, 14, 192)  399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_984 (BatchN (None, 14, 14, 192)  576         conv2d_984[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_984 (Activation)     (None, 14, 14, 192)  0           batch_normalization_984[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_985 (Conv2D)             (None, 14, 14, 224)  129024      activation_984[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_985 (BatchN (None, 14, 14, 224)  672         conv2d_985[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_985 (Activation)     (None, 14, 14, 224)  0           batch_normalization_985[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_983 (Conv2D)             (None, 14, 14, 192)  399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_986 (Conv2D)             (None, 14, 14, 256)  172032      activation_985[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_983 (BatchN (None, 14, 14, 192)  576         conv2d_983[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_986 (BatchN (None, 14, 14, 256)  768         conv2d_986[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_983 (Activation)     (None, 14, 14, 192)  0           batch_normalization_983[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_986 (Activation)     (None, 14, 14, 256)  0           batch_normalization_986[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 14, 14, 448)  0           activation_983[0][0]             \n",
      "                                                                 activation_986[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 14, 14, 2080) 933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 14, 14, 2080) 0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 14, 14, 2080) 0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_988 (Conv2D)             (None, 14, 14, 192)  399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_988 (BatchN (None, 14, 14, 192)  576         conv2d_988[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_988 (Activation)     (None, 14, 14, 192)  0           batch_normalization_988[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_989 (Conv2D)             (None, 14, 14, 224)  129024      activation_988[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_989 (BatchN (None, 14, 14, 224)  672         conv2d_989[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_989 (Activation)     (None, 14, 14, 224)  0           batch_normalization_989[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_987 (Conv2D)             (None, 14, 14, 192)  399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_990 (Conv2D)             (None, 14, 14, 256)  172032      activation_989[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_987 (BatchN (None, 14, 14, 192)  576         conv2d_987[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_990 (BatchN (None, 14, 14, 256)  768         conv2d_990[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_987 (Activation)     (None, 14, 14, 192)  0           batch_normalization_987[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_990 (Activation)     (None, 14, 14, 256)  0           batch_normalization_990[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 14, 14, 448)  0           activation_987[0][0]             \n",
      "                                                                 activation_990[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 14, 14, 2080) 933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 14, 14, 2080) 0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 14, 14, 2080) 0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_992 (Conv2D)             (None, 14, 14, 192)  399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_992 (BatchN (None, 14, 14, 192)  576         conv2d_992[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_992 (Activation)     (None, 14, 14, 192)  0           batch_normalization_992[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_993 (Conv2D)             (None, 14, 14, 224)  129024      activation_992[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_993 (BatchN (None, 14, 14, 224)  672         conv2d_993[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_993 (Activation)     (None, 14, 14, 224)  0           batch_normalization_993[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_991 (Conv2D)             (None, 14, 14, 192)  399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_994 (Conv2D)             (None, 14, 14, 256)  172032      activation_993[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_991 (BatchN (None, 14, 14, 192)  576         conv2d_991[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_994 (BatchN (None, 14, 14, 256)  768         conv2d_994[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_991 (Activation)     (None, 14, 14, 192)  0           batch_normalization_991[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_994 (Activation)     (None, 14, 14, 256)  0           batch_normalization_994[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 14, 14, 448)  0           activation_991[0][0]             \n",
      "                                                                 activation_994[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 14, 14, 2080) 933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 14, 14, 2080) 0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 14, 14, 2080) 0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_996 (Conv2D)             (None, 14, 14, 192)  399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_996 (BatchN (None, 14, 14, 192)  576         conv2d_996[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_996 (Activation)     (None, 14, 14, 192)  0           batch_normalization_996[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_997 (Conv2D)             (None, 14, 14, 224)  129024      activation_996[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_997 (BatchN (None, 14, 14, 224)  672         conv2d_997[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_997 (Activation)     (None, 14, 14, 224)  0           batch_normalization_997[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_995 (Conv2D)             (None, 14, 14, 192)  399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_998 (Conv2D)             (None, 14, 14, 256)  172032      activation_997[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_995 (BatchN (None, 14, 14, 192)  576         conv2d_995[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_998 (BatchN (None, 14, 14, 256)  768         conv2d_998[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_995 (Activation)     (None, 14, 14, 192)  0           batch_normalization_995[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_998 (Activation)     (None, 14, 14, 256)  0           batch_normalization_998[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 14, 14, 448)  0           activation_995[0][0]             \n",
      "                                                                 activation_998[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 14, 14, 2080) 933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 14, 14, 2080) 0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 14, 14, 2080) 0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1000 (Conv2D)            (None, 14, 14, 192)  399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1000 (Batch (None, 14, 14, 192)  576         conv2d_1000[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1000 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1000[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1001 (Conv2D)            (None, 14, 14, 224)  129024      activation_1000[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1001 (Batch (None, 14, 14, 224)  672         conv2d_1001[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1001 (Activation)    (None, 14, 14, 224)  0           batch_normalization_1001[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_999 (Conv2D)             (None, 14, 14, 192)  399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1002 (Conv2D)            (None, 14, 14, 256)  172032      activation_1001[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_999 (BatchN (None, 14, 14, 192)  576         conv2d_999[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1002 (Batch (None, 14, 14, 256)  768         conv2d_1002[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_999 (Activation)     (None, 14, 14, 192)  0           batch_normalization_999[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1002 (Activation)    (None, 14, 14, 256)  0           batch_normalization_1002[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 14, 14, 448)  0           activation_999[0][0]             \n",
      "                                                                 activation_1002[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 14, 14, 2080) 933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 14, 14, 2080) 0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 14, 14, 2080) 0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1004 (Conv2D)            (None, 14, 14, 192)  399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1004 (Batch (None, 14, 14, 192)  576         conv2d_1004[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1004 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1004[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1005 (Conv2D)            (None, 14, 14, 224)  129024      activation_1004[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1005 (Batch (None, 14, 14, 224)  672         conv2d_1005[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1005 (Activation)    (None, 14, 14, 224)  0           batch_normalization_1005[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1003 (Conv2D)            (None, 14, 14, 192)  399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1006 (Conv2D)            (None, 14, 14, 256)  172032      activation_1005[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1003 (Batch (None, 14, 14, 192)  576         conv2d_1003[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1006 (Batch (None, 14, 14, 256)  768         conv2d_1006[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1003 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1003[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1006 (Activation)    (None, 14, 14, 256)  0           batch_normalization_1006[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 14, 14, 448)  0           activation_1003[0][0]            \n",
      "                                                                 activation_1006[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 14, 14, 2080) 933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 14, 14, 2080) 0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 14, 14, 2080) 0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1008 (Conv2D)            (None, 14, 14, 192)  399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1008 (Batch (None, 14, 14, 192)  576         conv2d_1008[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1008 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1008[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1009 (Conv2D)            (None, 14, 14, 224)  129024      activation_1008[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1009 (Batch (None, 14, 14, 224)  672         conv2d_1009[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1009 (Activation)    (None, 14, 14, 224)  0           batch_normalization_1009[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1007 (Conv2D)            (None, 14, 14, 192)  399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1010 (Conv2D)            (None, 14, 14, 256)  172032      activation_1009[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1007 (Batch (None, 14, 14, 192)  576         conv2d_1007[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1010 (Batch (None, 14, 14, 256)  768         conv2d_1010[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1007 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1007[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1010 (Activation)    (None, 14, 14, 256)  0           batch_normalization_1010[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, 14, 14, 448)  0           activation_1007[0][0]            \n",
      "                                                                 activation_1010[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, 14, 14, 2080) 933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, 14, 14, 2080) 0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, 14, 14, 2080) 0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1012 (Conv2D)            (None, 14, 14, 192)  399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1012 (Batch (None, 14, 14, 192)  576         conv2d_1012[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1012 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1012[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1013 (Conv2D)            (None, 14, 14, 224)  129024      activation_1012[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1013 (Batch (None, 14, 14, 224)  672         conv2d_1013[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1013 (Activation)    (None, 14, 14, 224)  0           batch_normalization_1013[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1011 (Conv2D)            (None, 14, 14, 192)  399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1014 (Conv2D)            (None, 14, 14, 256)  172032      activation_1013[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1011 (Batch (None, 14, 14, 192)  576         conv2d_1011[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1014 (Batch (None, 14, 14, 256)  768         conv2d_1014[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1011 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1011[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1014 (Activation)    (None, 14, 14, 256)  0           batch_normalization_1014[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, 14, 14, 448)  0           activation_1011[0][0]            \n",
      "                                                                 activation_1014[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, 14, 14, 2080) 933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, 14, 14, 2080) 0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b (Conv2D)                (None, 14, 14, 1536) 3194880     block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_bn (BatchNormalization) (None, 14, 14, 1536) 4608        conv_7b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_ac (Activation)         (None, 14, 14, 1536) 0           conv_7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 1536)         0           conv_7b_ac[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Dense)                 (None, 4)            6148        global_average_pooling2d_4[0][0] \n",
      "==================================================================================================\n",
      "Total params: 54,342,884\n",
      "Trainable params: 54,282,340\n",
      "Non-trainable params: 60,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3be1f171",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: conv2d_1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3198485/2338296846.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv2d_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data01/anaconda3/envs/jeon2/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m   2566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2567\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2568\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such layer: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2569\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Provide either a layer name or layer index.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: conv2d_1."
     ]
    }
   ],
   "source": [
    "base_model.get_layer('conv2d_1').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfef7c6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefc8a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacebf2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T02:39:31.545740Z",
     "start_time": "2022-11-16T02:39:31.545740Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss','validation_loss'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','validation_accuracy'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018c7434",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.basename(list(test['path'])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad407f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276b48be",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "for i in enumerate(range(5)):\n",
    "    img, label = train_generator.next()\n",
    "    n_img = len(label)\n",
    "    \n",
    "    base = img[0] # keras는 RGB, openCV는 BGR이라 변경함\n",
    "    for idx in range(n_img - 1):\n",
    "        img2 = img[idx + 1]\n",
    "        base = np.hstack((base, img2))\n",
    "    images.append(base)\n",
    "img = images[0]\n",
    "for idx in range(len(images) - 1):\n",
    "    img = np.vstack((img, images[idx + 1]))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow((img*255).astype(np.uint8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3175fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dbbe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_input = Input(shape=(input_size, input_size,1), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a10fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d266d1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = Conv2D(3, (3, 3), activation=None, padding='same')(mask_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066d188",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
